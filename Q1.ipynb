{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Q1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWS-AEODiATe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "9c262214-decc-4cee-a1d5-71d44e6e5809"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from io import StringIO\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njt7AfSTiATp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetClass(Dataset):\n",
        "    \n",
        "    def __init__(self, folder, filename, label_dict):\n",
        "        \n",
        "        self.data = []\n",
        "        self.filename = filename\n",
        "        tar = tarfile.open(folder + '/' + filename)\n",
        "        for file in tar.getmembers():\n",
        "            f = tar.extractfile(file)\n",
        "            if f != None:\n",
        "                content = pd.read_csv(StringIO(f.read().decode()), sep=' ', header=None).values.ravel()\n",
        "                self.data.append(content)\n",
        "            \n",
        "        self.y = torch.tensor(label_dict[self.filename[:-7]], dtype=torch.long)\n",
        "    \n",
        "    def __getitem__(self, idx):     \n",
        "        \n",
        "        return torch.tensor(self.data[idx], dtype=torch.float), self.y\n",
        "      \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWUBsi9EiATu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_loader(directory, label_dict, train_fraction=0.8, num_workers=2, batch_size=32):\n",
        "\n",
        "    all_files = list(filter(lambda x: x.endswith('.tar.gz'), os.listdir(directory)))\n",
        "    files = [file for file in all_files if file[:-7] in label_dict.keys()]\n",
        "    \n",
        "    datasets = list(map(lambda x : DatasetClass(directory, x, label_dict), files))\n",
        "    dataset = ConcatDataset(datasets)\n",
        "    N = dataset.cumulative_sizes[-1]\n",
        "    \n",
        "    train_size = int(N*train_fraction)\n",
        "    test_size = N - train_size\n",
        "\n",
        "    train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    \n",
        "    return trainloader, testloader, train_size, test_size"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9FTc7eJiATx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict = {'tallbuilding': 0, 'opencountry':1, 'mountain': 2, 'highway': 3, 'coast': 4}\n",
        "# trainloader, testloader = train_test_loader('Data_Set_1(Colored_Images)', label_dict, train_fraction=0.8, num_workers=0)\n",
        "trainloader, testloader, train_size, test_size = train_test_loader('/content/drive/My Drive/Data_Set_1(Colored_Images)', label_dict, train_fraction=0.8, num_workers=0)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwjmJE-siAT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_features, h_layer_sizes):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(n_features, h_layer_sizes[0])\n",
        "        self.fc2 = nn.Linear(h_layer_sizes[0], h_layer_sizes[1])\n",
        "        self.fc3 = nn.Linear(h_layer_sizes[1], h_layer_sizes[2])\n",
        "        self.out = nn.Linear(h_layer_sizes[2], n_features)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = torch.tanh(self.fc1(x)) # Hidden Layer 1 (Tanh)\n",
        "        x = self.fc2(x)    # Hidden Layer 2 (Linear)\n",
        "        x = torch.tanh(self.fc3(x)) # Hidden Layer 3 (Tanh)\n",
        "        x = self.out(x) # Output Layer (Linear)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def get_z(self, x):\n",
        "        \n",
        "        z = torch.tanh(self.fc1(x))\n",
        "        z = self.fc2(z)\n",
        "        \n",
        "        return z"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS8b-mcViAT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e85f527-7218-4cc7-eb8a-755f52d363ba"
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr4qrfn9iAUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ae1 = AutoEncoder(828, [500, 350, 500])\n",
        "ae1 = ae1.to(device)\n",
        "optimizer1 = optim.SGD(ae1.parameters(), lr=0.0001, momentum=0.9)"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1O6lPmZiAUH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "93216195-5276-465d-c42b-485ff1b9ed1b"
      },
      "source": [
        "old_loss = np.inf\n",
        "losses = []\n",
        "max_epoch = 500\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for data in trainloader:\n",
        "        \n",
        "        X, _ = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        optimizer1.zero_grad()\n",
        "        \n",
        "        # Reconstructed Representation of X (forward)\n",
        "        X_hat = ae1(X)\n",
        "        \n",
        "        # Calculate Loss (MSE)\n",
        "        loss = criterion(X_hat, X)\n",
        "        \n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update Parameters\n",
        "        optimizer1.step()\n",
        "        \n",
        "        running_loss += loss.item()*len(X)/train_size\n",
        "    \n",
        "    print('Epoch', epoch+1, ': Loss =', running_loss)\n",
        "    losses.append(running_loss)\n",
        "    print(abs(running_loss-old_loss)/running_loss)\n",
        "    \n",
        "    if abs(running_loss-old_loss)/running_loss < 1e-4:\n",
        "        print('Converged')\n",
        "        break\n",
        "    \n",
        "    old_loss = running_loss\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : Loss = 1.9474741653962573\n",
            "inf\n",
            "Epoch 2 : Loss = 1.9238737957044079\n",
            "0.012267109071574194\n",
            "Epoch 3 : Loss = 1.9002036289735273\n",
            "0.01245664747186433\n",
            "Epoch 4 : Loss = 1.8769811337644404\n",
            "0.012372258192341175\n",
            "Epoch 5 : Loss = 1.8537627946246753\n",
            "0.01252497849621912\n",
            "Epoch 6 : Loss = 1.8300247869708315\n",
            "0.012971413186777877\n",
            "Epoch 7 : Loss = 1.8054557063362815\n",
            "0.013608243363891083\n",
            "Epoch 8 : Loss = 1.7796280356970704\n",
            "0.014512960079938582\n",
            "Epoch 9 : Loss = 1.7523625167933379\n",
            "0.015559291323821462\n",
            "Epoch 10 : Loss = 1.723361633040689\n",
            "0.016828089471552173\n",
            "Epoch 11 : Loss = 1.6924726312810718\n",
            "0.018250813152728182\n",
            "Epoch 12 : Loss = 1.6596073074774305\n",
            "0.019803072483210504\n",
            "Epoch 13 : Loss = 1.6246520443396137\n",
            "0.021515538209921917\n",
            "Epoch 14 : Loss = 1.5876750512556599\n",
            "0.02329002591223532\n",
            "Epoch 15 : Loss = 1.5486139790578326\n",
            "0.02522324654565743\n",
            "Epoch 16 : Loss = 1.5077093975110485\n",
            "0.02713028227741372\n",
            "Epoch 17 : Loss = 1.46491970799186\n",
            "0.02920958007851864\n",
            "Epoch 18 : Loss = 1.4205408177592538\n",
            "0.031240841289312\n",
            "Epoch 19 : Loss = 1.374836946075613\n",
            "0.03324312153095663\n",
            "Epoch 20 : Loss = 1.3280223960226232\n",
            "0.035251325725528075\n",
            "Epoch 21 : Loss = 1.2803197909485207\n",
            "0.03725835171130347\n",
            "Epoch 22 : Loss = 1.2321569486097854\n",
            "0.039088236602549925\n",
            "Epoch 23 : Loss = 1.1837379498915237\n",
            "0.04090347760051013\n",
            "Epoch 24 : Loss = 1.1353258328004319\n",
            "0.042641606217729514\n",
            "Epoch 25 : Loss = 1.087346301837401\n",
            "0.04412534523909716\n",
            "Epoch 26 : Loss = 1.0399380380457102\n",
            "0.04558758508418654\n",
            "Epoch 27 : Loss = 0.9933879104527558\n",
            "0.046859969910181695\n",
            "Epoch 28 : Loss = 0.9478937482292001\n",
            "0.04799500187499407\n",
            "Epoch 29 : Loss = 0.9036739753051237\n",
            "0.048933325660004426\n",
            "Epoch 30 : Loss = 0.8608804846351799\n",
            "0.04970897985691789\n",
            "Epoch 31 : Loss = 0.8195477967912501\n",
            "0.05043352932648751\n",
            "Epoch 32 : Loss = 0.7799466171047905\n",
            "0.05077421815541889\n",
            "Epoch 33 : Loss = 0.7419877092946662\n",
            "0.051158405098391854\n",
            "Epoch 34 : Loss = 0.7058221806179394\n",
            "0.05123886677103887\n",
            "Epoch 35 : Loss = 0.671407402916388\n",
            "0.051257667925709766\n",
            "Epoch 36 : Loss = 0.6387868035923352\n",
            "0.05106648907053944\n",
            "Epoch 37 : Loss = 0.6079382408748972\n",
            "0.05074292196694705\n",
            "Epoch 38 : Loss = 0.578877730803056\n",
            "0.050201464878475446\n",
            "Epoch 39 : Loss = 0.551464170217514\n",
            "0.04971050172621238\n",
            "Epoch 40 : Loss = 0.5257615399631587\n",
            "0.04888647856622685\n",
            "Epoch 41 : Loss = 0.5016503151167524\n",
            "0.04806380883224343\n",
            "Epoch 42 : Loss = 0.479121704670516\n",
            "0.04702064261882883\n",
            "Epoch 43 : Loss = 0.45804090052843094\n",
            "0.04602384659921123\n",
            "Epoch 44 : Loss = 0.43838786875659774\n",
            "0.04483023635570759\n",
            "Epoch 45 : Loss = 0.420103903521191\n",
            "0.04352248356217542\n",
            "Epoch 46 : Loss = 0.40309188244017685\n",
            "0.042203829504155035\n",
            "Epoch 47 : Loss = 0.3872830881313844\n",
            "0.04081973830840084\n",
            "Epoch 48 : Loss = 0.3725991012020545\n",
            "0.03940961446755353\n",
            "Epoch 49 : Loss = 0.3590032647956501\n",
            "0.037871066198084107\n",
            "Epoch 50 : Loss = 0.3464228443124078\n",
            "0.03631521618677422\n",
            "Epoch 51 : Loss = 0.33475748178633774\n",
            "0.03484720479978866\n",
            "Epoch 52 : Loss = 0.32400122284889227\n",
            "0.0331982047563505\n",
            "Epoch 53 : Loss = 0.31402765485373413\n",
            "0.03176015819308515\n",
            "Epoch 54 : Loss = 0.3048433681780641\n",
            "0.030127887414973416\n",
            "Epoch 55 : Loss = 0.2963694036006928\n",
            "0.028592575597947145\n",
            "Epoch 56 : Loss = 0.2885448648170992\n",
            "0.027117234571314902\n",
            "Epoch 57 : Loss = 0.28134312074292783\n",
            "0.025597725848615322\n",
            "Epoch 58 : Loss = 0.27469832619482826\n",
            "0.024189424959898707\n",
            "Epoch 59 : Loss = 0.2685975852337751\n",
            "0.0227133127639378\n",
            "Epoch 60 : Loss = 0.2629603811285713\n",
            "0.021437465526213832\n",
            "Epoch 61 : Loss = 0.2577933858741413\n",
            "0.020043164555636005\n",
            "Epoch 62 : Loss = 0.25301262194460084\n",
            "0.018895357444211825\n",
            "Epoch 63 : Loss = 0.24865415421399206\n",
            "0.017528232111730054\n",
            "Epoch 64 : Loss = 0.24462736736644397\n",
            "0.016460900883244572\n",
            "Epoch 65 : Loss = 0.24091704392975033\n",
            "0.015400834146776036\n",
            "Epoch 66 : Loss = 0.2375306514176456\n",
            "0.014256654843885838\n",
            "Epoch 67 : Loss = 0.23440638184547427\n",
            "0.013328432219182961\n",
            "Epoch 68 : Loss = 0.2315374328331514\n",
            "0.012390864739310956\n",
            "Epoch 69 : Loss = 0.22890574044801967\n",
            "0.011496838742361433\n",
            "Epoch 70 : Loss = 0.2264867282726548\n",
            "0.010680591281502134\n",
            "Epoch 71 : Loss = 0.22427300058982588\n",
            "0.009870682948936995\n",
            "Epoch 72 : Loss = 0.22223187745972114\n",
            "0.009184655025356052\n",
            "Epoch 73 : Loss = 0.22036469253626736\n",
            "0.00847315829937902\n",
            "Epoch 74 : Loss = 0.2186462638730353\n",
            "0.007859400992234384\n",
            "Epoch 75 : Loss = 0.21707258000969892\n",
            "0.0072495746043376545\n",
            "Epoch 76 : Loss = 0.2156322622163729\n",
            "0.006679509728839869\n",
            "Epoch 77 : Loss = 0.21430281651290983\n",
            "0.006203584838946765\n",
            "Epoch 78 : Loss = 0.21308452636003491\n",
            "0.005717403199969824\n",
            "Epoch 79 : Loss = 0.21197278255766083\n",
            "0.005244747882062008\n",
            "Epoch 80 : Loss = 0.21094316548921846\n",
            "0.004881016486381486\n",
            "Epoch 81 : Loss = 0.21000441841103815\n",
            "0.0044701301300381175\n",
            "Epoch 82 : Loss = 0.20914197916334326\n",
            "0.004123702238761478\n",
            "Epoch 83 : Loss = 0.2083548781546679\n",
            "0.0037776941708610365\n",
            "Epoch 84 : Loss = 0.2076259455220266\n",
            "0.003510797414112125\n",
            "Epoch 85 : Loss = 0.20695980604399336\n",
            "0.0032186900962384605\n",
            "Epoch 86 : Loss = 0.20634718645702707\n",
            "0.002968877829084775\n",
            "Epoch 87 : Loss = 0.2057864032685757\n",
            "0.0027250740551575028\n",
            "Epoch 88 : Loss = 0.205269265581261\n",
            "0.002519313769893058\n",
            "Epoch 89 : Loss = 0.20479511977596715\n",
            "0.0023152202348011327\n",
            "Epoch 90 : Loss = 0.20436274158683684\n",
            "0.002115738836604821\n",
            "Epoch 91 : Loss = 0.2039660381322557\n",
            "0.001944948571898613\n",
            "Epoch 92 : Loss = 0.20359522646123712\n",
            "0.0018213180999563968\n",
            "Epoch 93 : Loss = 0.2032609741118821\n",
            "0.0016444492151800856\n",
            "Epoch 94 : Loss = 0.20295028185302566\n",
            "0.0015308786763914793\n",
            "Epoch 95 : Loss = 0.202667661011219\n",
            "0.0013945038907367585\n",
            "Epoch 96 : Loss = 0.2024063322354446\n",
            "0.0012911096846041827\n",
            "Epoch 97 : Loss = 0.20216931944543667\n",
            "0.0011723479638654868\n",
            "Epoch 98 : Loss = 0.20194560594179412\n",
            "0.0011077908954703305\n",
            "Epoch 99 : Loss = 0.2017441249706529\n",
            "0.0009986956059837464\n",
            "Epoch 100 : Loss = 0.20155697756192903\n",
            "0.0009285087075011198\n",
            "Epoch 101 : Loss = 0.2013852261006832\n",
            "0.0008528503533816794\n",
            "Epoch 102 : Loss = 0.20122772082686427\n",
            "0.0007827215513436096\n",
            "Epoch 103 : Loss = 0.201083013957197\n",
            "0.0007196374612630371\n",
            "Epoch 104 : Loss = 0.20094914327968255\n",
            "0.00066619183007971\n",
            "Epoch 105 : Loss = 0.20082500001246276\n",
            "0.0006181663996618499\n",
            "Epoch 106 : Loss = 0.20071258192712613\n",
            "0.0005600948593120383\n",
            "Epoch 107 : Loss = 0.20060808787291703\n",
            "0.0005208865470832263\n",
            "Epoch 108 : Loss = 0.200510576706041\n",
            "0.0004863143305352506\n",
            "Epoch 109 : Loss = 0.20042285763404588\n",
            "0.0004376699994732404\n",
            "Epoch 110 : Loss = 0.20034052397717128\n",
            "0.00041096856112836236\n",
            "Epoch 111 : Loss = 0.2002640678123994\n",
            "0.0003817767491046604\n",
            "Epoch 112 : Loss = 0.2001948211003434\n",
            "0.0003458966204789288\n",
            "Epoch 113 : Loss = 0.20012955028902402\n",
            "0.0003261427971287391\n",
            "Epoch 114 : Loss = 0.2000694579698823\n",
            "0.00030035728467245966\n",
            "Epoch 115 : Loss = 0.20001462101936338\n",
            "0.00027416470975693007\n",
            "Epoch 116 : Loss = 0.19996308704668833\n",
            "0.0002577174289323295\n",
            "Epoch 117 : Loss = 0.19991649179296062\n",
            "0.00023307358642513248\n",
            "Epoch 118 : Loss = 0.199871402233839\n",
            "0.00022559284929044463\n",
            "Epoch 119 : Loss = 0.199830164624886\n",
            "0.00020636328369347248\n",
            "Epoch 120 : Loss = 0.19979278675534512\n",
            "0.00018708317826638884\n",
            "Epoch 121 : Loss = 0.19975749640302232\n",
            "0.00017666597228272658\n",
            "Epoch 122 : Loss = 0.1997233544560996\n",
            "0.00017094619212510182\n",
            "Epoch 123 : Loss = 0.19969316605817183\n",
            "0.00015117391608166782\n",
            "Epoch 124 : Loss = 0.19966434043916792\n",
            "0.0001443703915306606\n",
            "Epoch 125 : Loss = 0.1996379609812389\n",
            "0.00013213648245736243\n",
            "Epoch 126 : Loss = 0.19961261546069928\n",
            "0.00012697354063081004\n",
            "Epoch 127 : Loss = 0.1995892829515718\n",
            "0.00011690261512256938\n",
            "Epoch 128 : Loss = 0.19956759702075616\n",
            "0.00010866458853731068\n",
            "Epoch 129 : Loss = 0.19954689321192823\n",
            "0.00010375410258050813\n",
            "Epoch 130 : Loss = 0.19952762634916743\n",
            "9.65623814272256e-05\n",
            "Converged\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_MgLSBL3Qfe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6bf9cb66-4832-4e11-99c2-87926f5e773d"
      },
      "source": [
        "plt.plot(losses)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Iter Number')\n",
        "plt.title('Convergence monitor plot')\n",
        "plt.show()"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV9bnH8c+TfQHCFlnCkiC4AApowAXcLQWtYjfrvrbUqq29tYtdbbX33l6rdrFu1AVbW6xaF9pq3euGCkFAFgEhrAEl7DshyXP/mIke4kkIkJM5J/m+X6/zysz8ZuY8ZyDnm9l+Y+6OiIhIfWlRFyAiIslJASEiInEpIEREJC4FhIiIxKWAEBGRuBQQIiISlwJCpA0wswvN7PkI3//nZvZwVO8v+0cBIfvFzC4wszIz22pmq83sWTMbFXVdEp+7/8XdR9eNm5mbWf8oa2qImS01s9OjrkMUELIfzOw7wG+B/wG6AX2Au4BxUdYVy8wyoq6htdK2bTsUELJPzKwAuAm4xt2fcPdt7r7b3f/h7t8L58k2s9+a2arw9Vszyw7bTjazlWZ2vZmtCfc+Lg/bjjGzD80sPeb9Pm9m74XDaWZ2g5ktNrN1ZvaomXUO24rDv4qvNLPlwMtmlm5mt5nZWjNbYmbXhvNk1H0WM7s/rKHCzH5Z995mdpmZvWFmt5rZhnD5sTF1dTazB8PPt8HMnopp+5yZzTSzjWY2xcyObGR7upldbWYfmNkWM7vZzA4Ol9scfsasmPm/ZmaLzGy9mU02s5711nVVuK6NZnanmVns5wmHXwsXmRXuAX6lieu+xsw+AD6I8znqtv/4cJusNrPvNvK5zzazuWGd/zGzw8Ppfyb4g+MfYW3fb2gd0gLcXS+9mvwCxgDVQEYj89wEvA0cBBQCU4Cbw7aTw+VvAjKBM4DtQKewfTHwmZh1PQbcEA5fF663F5AN3AtMCtuKAQf+BOQDucBVwLxw/k7Ai+E8GeEyT4bryA9rnQp8PWy7DNgNfA1IB74BrAIsbP8X8LdwvZnASeH0YcAa4JhwuUuBpUB2A9vKgaeBDsAgYBfwEtAPKAjrvzSc91RgLXBU+PnvAF6rt65/Ah0JvmQrgTExn+eNevP2jxlvyrpfADoDuXE+R932nxRuzyPC9z89bP858HA4fAiwDfhMuO2+DywCssL2pXXL6RXx73vUBeiVWi/gQuDDvcyzGDgjZvyzwNJw+GRgBzEBE36hHhsO/xJ4IBxuH36R9A3H3wdOi1muR/glnhHzBdUvpv1lwi/8cPz0cJ4MgkNju2K/7IDzgVfC4cuARTFteeGy3cP3rSUMtXqf/W7CMIyZtoAwQOLM78DImPHpwA9ixm8DfhsO3w/cEtPWLvz8xTHrGhXT/iifhOtlNB4QTVn3qY38m9dt/8Nipt0C3B8OxwbET4FHY+ZLAyqAk8NxBUSSvHSISfbVOqDrXo5D9wSWxYwvC6d9vA53r44Z307whQTwV+AL4SGpLwDvunvduvoCT4aHJTYSBEYNwZd9nRX16ljRQFtfgr9eV8es716CPYk6H9YNuPv2cLAd0BtY7+4b4nz2vsD1desM19u73uev76OY4R1xxuu2zR7b1d23Evx7FMWrmT236940Zd0r6i8UR+w89f/dG3qv2nC5ojjzSoQUELKv3iL4y/ucRuZZRfBFWadPOG2v3H0ewZfHWOACgsCoswIY6+4dY1457l4Ru4qY4dUEh5fq9K63rl1A15h1dXD3QU0ocwXQ2cw6NtD23/VqzHP3SU1Y797ssV3NLB/oQvDXd0usuyldP8du44b+3eu/l4XL1b2XuphOEgoI2Sfuvgn4GXCnmZ1jZnlmlmlmY83slnC2ScBPzKzQzLqG8+/LNfB/JTjfcCLBOYg69wD/bWZ9AcL1N3bl1KPAdWZWFH6Z/yDmc6wGngduM7MO4Qnwg83spL0VFy77LHCXmXUKP/+JYfMfgavCE+5mZvlmdqaZtW/6x2/QJOByMxsa7mH9D/COuy/dj3V9RHCeo7nX/dPw/8Qg4HKC8zT1PQqcaWanmVkmcD1BWE9poDaJiAJC9pm73wZ8B/gJwYnIFcC1QN2VPL8EyoD3gNnAu+G0ppoEnAS87O5rY6b/DpgMPG9mWwhOWB/TyHr+SBAC7wEzgGcITpDXhO2XAFkEJ4I3AI8TnF9oiosJjtHPJziH8m0Ady8jOLH9h3CdiwiO/x8wd3+R4Pj93wn2jg4GztvP1f0ceCg8DHZuM677VYLP/BJwq7t/6uY8d18AXERwInwtcBZwlrtXhbP8L8EfGBsbuxJKEq/uigyRVi+8TPUed++715lln5hZMbAEyKx3fklSmPYgpNUys1wzO8PMMsysCLiR4NJWEWkCBYS0Zgb8guBQzwyCq55+FmlFIilEh5hERCQu7UGIiEhcrarTra5du3pxcXHUZYiIpIzp06evdffCeG0JCwgz603QL043ghtfJrj77+rNYwSXLtb1x3OZu78btl1KcBklwC/d/aG9vWdxcTFlZWXN9yFERFo5M1vWUFsi9yCqgevd/d3wJqHpZvZCeKdsnbHAgPB1DEE/NsdY0EPnjUApQbhMN7PJDXRtICIiCZCwcxDuvrpub8DdtxBcQVK/r5VxwJ888DbQ0cx6EHTu9oK71/V38wJBL6IiItJCWuQkdXgTzTDgnXpNRezZudfKcFpD0+Ote7wFTzYrq6ysbK6SRUTavIQHhJm1I7h9/9vuvrm51+/uE9y91N1LCwvjnmcREZH9kNCACDvi+jvwF3d/Is4sFezZ+2OvcFpD00VEpIUkLCDCK5TuB95399sbmG0ycEnY6+WxwKawp8zngNFhT5mdgNHhNBERaSGJvIppJEGPl7PNbGY47UcEfcTj7vcQ9K55BkHvj9sJugfG3deb2c3AtHC5m9x9fQJrFRGRehIWEO7+BkFfOI3N48A1DbQ9ADyQgNLqvw93vrKIkw89iMFFBYl+OxGRlNHmu9rYtGM3f31nOZdPnMbKDdv3voCISBvR5gOiY14WE68Ywc7dNVz24DQ2bd8ddUkiIkmhzQcEwCHd2jPh4lKWr9vO1/5cxs7dNXtfSESklVNAhI47uAu3njuEqUvWc/1js6itVTfoItK2tareXA/U2UN6snrjDv732fkUdczlR2ccHnVJIiKRUUDUM/7EflRs3MGE18rpUZDD5SNLoi5JRCQSCoh6zIwbzxrE6k07uemf8+hRkMOYwT2iLktEpMXpHEQc6WnG788bxtDeHbnukZlMX6Z79ESk7VFANCA3K537LimlR0EOVz5UxuLKrVGXJCLSohQQjejSLpuHrhhBuhmXPTiVyi27oi5JRKTFKCD2om+XfO6/bDiVW3Zx5UPT2F5VHXVJIiItQgHRBEN7d+SO849iTsUmrv3rDKpraqMuSUQk4RQQTfSZgd24adxgXp6/hp8+PZegn0ERkdZLl7nug4uO7UvFxh3c/Z/F9OqUyzWn9I+6JBGRhFFA7KPvjT6U1Rt38OvnFtC9Qw5fPLpX1CWJiCSEAmIfpaUZt3xpCB9t3sUP/v4e3TrkMGpA16jLEhFpdjoHsR+yMtK45+KjObiwHdf89V2Wr9NzJESk9VFA7KeC3EwmXHI07s5VD09nR5W6CBeR1kUBcQD6dsnnd+cN4/0PN/Pjp2bryiYRaVUSFhBm9oCZrTGzOQ20f8/MZoavOWZWY2adw7alZjY7bCtLVI3N4ZTDDuK60wbwxLsVPPz2sqjLERFpNoncg5gIjGmo0d1/7e5D3X0o8EPgVXeP7RXvlLC9NIE1NotvnTqAUw87iJv+OU8d+4lIq5GwgHD314CmflueD0xKVC2JlpZm/ObcofTsmMs3Hn6XNVt2Rl2SiMgBi/wchJnlEexp/D1msgPPm9l0MxsfTWX7piAvk3suOprNO3dz/aN6ZKmIpL7IAwI4C3iz3uGlUe5+FDAWuMbMTmxoYTMbb2ZlZlZWWVmZ6FobdXiPDvzsc4N4/YO13P/GkkhrERE5UMkQEOdR7/CSu1eEP9cATwIjGlrY3Se4e6m7lxYWFia00KY4f0RvPjuoG7c8N585FZuiLkdEZL9FGhBmVgCcBDwdMy3fzNrXDQOjgbhXQiUjM+NXXziSLvnZfOuRGezcrfsjRCQ1JfIy10nAW8ChZrbSzK40s6vM7KqY2T4PPO/u22KmdQPeMLNZwFTgX+7+70TVmQid8rO49ctDKK/cxq3PLYi6HBGR/ZKwvpjc/fwmzDOR4HLY2GnlwJDEVNVyRg3oykXH9uH+N5fw2cHdGV7cOeqSRET2STKcg2i1fjj2cHp1yuW7j83Sk+hEJOUoIBIoPzuDX39pCMvWbed3L34QdTkiIvtEAZFgx/brwvkjenPfG0t0VZOIpBQFRAu4YczhdMrL4odPzNbzrEUkZSggWkBBXia/OHsQsys2MXHK0qjLERFpEgVECznjiO6cfGghv33xA9ZsVl9NIpL8FBAtxMz4+VmDqKqu5X+fnR91OSIie6WAaEHFXfMZf2I/npxRwdQl6hZcRJKbAqKFXX3KwfQsyOHGyXOpUY+vIpLEFBAtLC8rgx+deTjvr97M49NXRF2OiEiDFBAROPOIHhzdtxO/fm4hW3fpDmsRSU4KiAiYGT8583DWbt3FPf9ZHHU5IiJxKSAiMqxPJ8YN7ckfXy+nYuOOqMsREfkUBUSEvj/mMNzhjpfUT5OIJB8FRISKOuZywTF9eGz6Ssort0ZdjojIHhQQEbvmlP5kpafxG/X2KiJJRgERscL22Vw+sph/zFrFvFWboy5HRORjCogk8PUTD6Z9Tga3v6DHk4pI8lBAJIGCvEy+fmI/Xnx/De8u3xB1OSIigAIiaVw+soQu+Vnc+pz2IkQkOSQsIMzsATNbY2ZzGmg/2cw2mdnM8PWzmLYxZrbAzBaZ2Q2JqjGZ5GdncPUp/ZmyeB1vLlobdTkiIgndg5gIjNnLPK+7+9DwdROAmaUDdwJjgYHA+WY2MIF1Jo0Lj+lDj4Icfv3cAtzVkZ+IRCthAeHurwH706f1CGCRu5e7exXwCDCuWYtLUjmZ6Vx7an9mrtjIm4vWRV2OiLRxUZ+DOM7MZpnZs2Y2KJxWBMR2c7oynBaXmY03szIzK6usrExkrS3iS0f34qD22dz5yqKoSxGRNi7KgHgX6OvuQ4A7gKf2ZyXuPsHdS929tLCwsFkLjEJ2RjrjT+zHW+XrmL5MVzSJSHQiCwh33+zuW8PhZ4BMM+sKVAC9Y2btFU5rMy44pg+d8jK5S3sRIhKhyALCzLqbmYXDI8Ja1gHTgAFmVmJmWcB5wOSo6oxCXlYGV4ws4aX5a3R3tYhEJpGXuU4C3gIONbOVZnalmV1lZleFs3wJmGNms4DfA+d5oBq4FngOeB941N3nJqrOZHXJccW0y87grv9oL0JEopGRqBW7+/l7af8D8IcG2p4BnklEXamiIC+Ti4/ryz2vLuY7lVvpV9gu6pJEpI2J+iomacQVI0vISk/jnlf11DkRaXkKiCRW2D6b80f04Yl3K/TUORFpcQqIJDf+xH4A/PG18ogrEZG2RgGR5Hp2zOWcYUX8bdoKNm6virocEWlDFBAp4KsnlLBjdw1/eWd51KWISBuigEgBh3XvwImHFDJxylJ2VddEXY6ItBEKiBTxtRNKqNyyi6dnroq6FBFpIxQQKWJU/64c1r09971erq7ARaRFKCBShJnxtRP6sfCjrby6MPV7rRWR5KeASCFnDelJtw7Z3Pf6kqhLEZE2QAGRQrIy0rjs+BLeWLSWuas2RV2OiLRyCogUc8ExfcjPSud+7UWISIIpIFJMQW4m5w7vzeRZq1i9Sd1viEjiKCBS0BUjS6h156Epy6IuRURaMQVECurdOY/PDurOpKnL2V5VHXU5ItJKKSBS1JWjSti0Yzd/f7dNPY1VRFqQAiJFHd23E0f2KuDBN5dQW6sb50Sk+SkgUpSZceWoEsort/HqB7pxTkSanwIihY0d3INuHbJ54A1d8ioizS9hAWFmD5jZGjOb00D7hWb2npnNNrMpZjYkpm1pOH2mmZUlqsZUl5WRxiXHFfP6B2tZ+NGWqMsRkVYmkXsQE4ExjbQvAU5y9yOAm4EJ9dpPcfeh7l6aoPpahQtG9CE7I017ESLS7BIWEO7+GrC+kfYp7r4hHH0b6JWoWlqzTvlZfOGoXjwxo4J1W3dFXY6ItCLJcg7iSuDZmHEHnjez6WY2vrEFzWy8mZWZWVllZds8WXvFyGKqqmuZNFVPnBOR5hN5QJjZKQQB8YOYyaPc/ShgLHCNmZ3Y0PLuPsHdS929tLCwMMHVJqcB3dpz4iGF/OmtZVRV10Zdjoi0EpEGhJkdCdwHjHP3dXXT3b0i/LkGeBIYEU2FqeOKkcWs2bKLf83WE+dEpHlEFhBm1gd4ArjY3RfGTM83s/Z1w8BoIO6VUPKJkw4ppP9B7bj/jSV64pyINItEXuY6CXgLONTMVprZlWZ2lZldFc7yM6ALcFe9y1m7AW+Y2SxgKvAvd/93oupsLcyMy0cWM6diM9OWbtj7AiIie2Gt6a/N0tJSLytru7dN7Kiq4bhfvcSxJV245+Kjoy5HRFKAmU1v6HaCyE9SS/PJzUrnghF9eH7eh6xYvz3qckQkxSkgWplLjismzYyJU5ZGXYqIpDgFRCvTvSCHM4/swd+mrWDLzt1RlyMiKUwB0QpdMbKErbuqeaxsZdSliEgKU0C0QkN6d6S0bycmTllKjZ4VISL7SQHRSl0xqoTl67fz4vsfRV2KiKSoJgVEePNaWjh8iJmdbWaZiS1NDsTogd0o6pirXl5FZL81dQ/iNSDHzIqA54GLCbrzliSVkZ7GZccX886S9cyp2BR1OSKSgpoaEObu24EvAHe5+5eBQYkrS5rDucN7k5eVzgNvai9CRPZdkwPCzI4DLgT+FU5LT0xJ0lwKcjM5t7Q3/5i1ijVbdkZdjoikmKYGxLeBHwJPuvtcM+sHvJK4sqS5XHp8MdW1zsNvLYu6FBFJMU0KCHd/1d3Pdvf/C09Wr3X3byW4NmkGJV3zOe2wg3j4neXs3F0TdTkikkKaehXTX82sQ9j99hxgnpl9L7GlSXO5YlQJ67dV8fTMiqhLEZEU0tRDTAPdfTNwDsGjQUsIrmSSFHBcvy4c1r09D7yxVM+KEJEma2pAZIb3PZwDTHb33QTPjZYUYGZcOaqEBR9tYcridXtfQESEpgfEvcBSIB94zcz6ApsTVZQ0v7OG9KRruyzu141zItJETT1J/Xt3L3L3MzywDDglwbVJM8rJTOfCY/ry8vw1lFdujbocEUkBTT1JXWBmt5tZWfi6jWBvQlLIRcf2JSs9jQffXBp1KSKSApp6iOkBYAtwbvjaDDyYqKIkMQrbZ3P20J48Pn0lm7brWREi0rimBsTB7n6ju5eHr18A/fa2kJk9YGZrzGxOA+1mZr83s0Vm9p6ZHRXTdqmZfRC+Lm1inbIXV4wsYcfuGh6ZtjzqUkQkyTU1IHaY2ai6ETMbCexownITgTGNtI8FBoSv8cDd4fo7AzcCxwAjgBvNrFMTa5VGDOzZgeP6deGhKUuprqmNuhwRSWJNDYirgDvNbKmZLQX+AHx9bwu5+2vA+kZmGQf8KTzx/TbQ0cx6AJ8FXnD39e6+AXiBxoNG9sEVo0pYtWkn/577YdSliEgSa+pVTLPcfQhwJHCkuw8DTm2G9y8CVsSMrwynNTT9U8xsfN3J88rKymYoqfU77bCD6NslT5e8ikij9umJcu6+ObyjGuA7Cahnn7n7BHcvdffSwsLCqMtJCWlpxuXHFzNj+UbeXb4h6nJEJEkdyCNHrRnevwLoHTPeK5zW0HRpJl8u7U37nAxd8ioiDTqQgGiOrjYmA5eEVzMdC2xy99XAc8BoM+sUnpweHU6TZpKfncF5w3vzzOzVrNrYlOsNRKStaTQgzGyLmW2O89oC9Nzbys1sEvAWcKiZrTSzK83sKjO7KpzlGaAcWAT8EbgawN3XAzcD08LXTeE0aUaXHl+Mu/MnPStCROLIaKzR3dsfyMrd/fy9tDtwTQNtDxDcoCcJ0qtTHmMGd2fS1OV867T+5GU1+t9BRNqYAznEJK3AlaNK2LRjN49MXbH3mUWkTVFAtHFH9+3MiJLOTHitnKpq3TgnIp9QQAjXntKfDzfv5Il3V0ZdiogkEQWEcMKArhxRVMDdry5W9xsi8jEFhGBmXHNKf5at286/Zq+OuhwRSRIKCAFg9MBuDDioHXe9spjaWj1NVkQUEBJKSzOuPuVgFny0hRff/yjqckQkCSgg5GNnHdmTPp3zuPOVRQS3qIhIW6aAkI9lpKdx1UkHM2vlJt5YtDbqckQkYgoI2cMXjy6iW4ds/vDyoqhLEZGIKSBkD9kZ6Xz9xIN5Z8l6pizWXoRIW6aAkE+54Jg+dO+Qw+3PL9S5CJE2TAEhn5KTmc61p/anbNkGXl2op/SJtFUKCInr3NLe9OqUy23aixBpsxQQEldWRhrXnTaA2RWbeH6e7osQaYsUENKgzw8rol/XfG5/fqHurhZpgxQQ0qCM9DS+/ZlDWPDRFv6pPppE2hwFhDTqc0f04NBu7fntCwvV06tIG6OAkEalpRnfGX0I5Wu38cSMiqjLEZEWpICQvRo9sBtH9irgNy8sZEdVTdTliEgLSWhAmNkYM1tgZovM7IY47b8xs5nha6GZbYxpq4lpm5zIOqVxZsaPzzic1Zt2cv8b5VGXIyItJCNRKzazdOBO4DPASmCamU1293l187j7f8XM/01gWMwqdrj70ETVJ/vmmH5dGDOoO3f9ZzHnDu/NQe1zoi5JRBIskXsQI4BF7l7u7lXAI8C4RuY/H5iUwHrkAN0w9jB219Ry23MLoy5FRFpAIgOiCFgRM74ynPYpZtYXKAFejpmcY2ZlZva2mZ3T0JuY2fhwvrLKSnULkUjFXfO59LhiHp2+gnmrNkddjogkWLKcpD4PeNzdY8+A9nX3UuAC4LdmdnC8Bd19gruXuntpYWFhS9Tapn3z1AEU5Gbyy3/NUxccIq1cIgOiAugdM94rnBbPedQ7vOTuFeHPcuA/7Hl+QiJSkJfJt08bwJTF63h5/pqoyxGRBEpkQEwDBphZiZllEYTAp65GMrPDgE7AWzHTOplZdjjcFRgJzKu/rETjwmP70q9rPv/9zPvs1s1zIq1WwgLC3auBa4HngPeBR919rpndZGZnx8x6HvCI73m84nCgzMxmAa8Av4q9+kmilZmexo/OOJzyym08NGVp1OWISIJYazqOXFpa6mVlZVGX0Sa4O5dPnMbUJet58Tsn0bNjbtQlich+MLPp4fneT0mWk9SSYsyMm8cNptadn0+eG3U5IpIACgjZb70753HdaYfw/LyPeEHPjBBpdRQQckC+ekIJh3Zrz41Pz2HbruqoyxGRZqSAkAOSmZ7G/3xhMKs27eQ3L+gOa5HWRAEhB+zovp05f0QfHpyylLmrNkVdjog0EwWENIsbxhxGp7xMfvTkHGr0eFKRVkEBIc2iIC+Tn35uILNWbFSX4CKthAJCms3ZQ3oyemA3bn1+IR98tCXqckTkACkgpNmYGf/9+SPIz0rnu4/N0jOsRVKcAkKaVWH7bH55zhHMWrmJO15eFHU5InIAFBDS7M48sgdfGFbEHS9/wNvl66IuR0T2kwJCEuLmcwZT3CWf6x6Zwbqtu6IuR0T2gwJCEiI/O4M7LhjGhu27+e5js6jVpa8iKUcBIQkzqGcBPznzcF5ZUMn9byyJuhwR2UcKCEmoi4/ty5hB3fm/f89n5oqNUZcjIvtAASEJZWb835eOpFuHHL456V02bd8ddUki0kQKCEm4gtxM7rhgGB9u2sk3H5mhrjhEUoQCQlrEUX06cdO4wby2sJJb/j0/6nJEpAkyoi5A2o7zR/Rh3qrN3PtaOYf1aM/nh/WKuiQRaURC9yDMbIyZLTCzRWZ2Q5z2y8ys0sxmhq+vxrRdamYfhK9LE1mntJyfnTWQY/t15gePz+Yd3UQnktQSFhBmlg7cCYwFBgLnm9nAOLP+zd2Hhq/7wmU7AzcCxwAjgBvNrFOiapWWk5mexr0XldK7cy7j/zydxZVboy5JRBqQyD2IEcAidy939yrgEWBcE5f9LPCCu6939w3AC8CYBNUpLawgL5MHLxtBRppx2YNTWbN5Z9QliUgciQyIImBFzPjKcFp9XzSz98zscTPrvY/LYmbjzazMzMoqKyubo25pAX265HH/ZcNZt7WKi++fqstfRZJQ1Fcx/QModvcjCfYSHtrXFbj7BHcvdffSwsLCZi9QEmdo745MuLiUJWu3cfnEqWyvqo66JBGJkciAqAB6x4z3Cqd9zN3XuXtdT273AUc3dVlpHUYN6Mrvzx/KzBUbuWLiNHZU1URdkoiEEhkQ04ABZlZiZlnAecDk2BnMrEfM6NnA++Hwc8BoM+sUnpweHU6TVmjM4B785itDmbpkPVc+pJAQSRYJCwh3rwauJfhifx941N3nmtlNZnZ2ONu3zGyumc0CvgVcFi67HriZIGSmATeF06SVGje0iNvOHcJb5eu4fOJUtu7S4SaRqJl76+n2oLS01MvKyqIuQw7AUzMquP6xWQwuKuChy4fTMS8r6pJEWjUzm+7upfHaoj5JLbKHc4YVcfeFR/H+qs185d63qdi4I+qSRNosBYQkndGDuvPg5cNZtXEH4/7wproJF4mIAkKS0sj+XXni6uPJzUrjK/e+xT/fWxV1SSJtjgJCktaAbu156uqRHFFUwLV/ncEdL31AazpnJpLsFBCS1Lq0y+YvXzuGzw8r4rYXFvLNSTPYslN3XYu0BAWEJL3sjHRuP3cI3x9zKM/O+ZDP3fEGs3ReQiThFBCSEsyMq0/uz9/GH0t1jfPFu6cw4bXF1OrpdCIJo4CQlFJa3JlnvnUCpx/ejf95Zj6XT5ym3mBFEkQBISmnIC+Tuy86il+eM5i3y9dx2u2v8vDby7Q3IdLMFBCSksyMi47ty7PXncARRQX85Kk5fPnet1jw4ZaoSxNpNRQQktL6FbbjL189htu+PITyyq2c+fvXueXf89WXk0gzUEBIyjMzvnh0L/i4O5YAAA0ESURBVF66/mTOGVbEXf9ZzEm3vMJDU5ZSVV0bdXkiKUsBIa1G5/wsbv3yEJ68+ngGdGvHjZPncvrtr/L0zAqdnxDZDwoIaXWG9enEpK8dy8TLh5OfncF1j8zkjN+/zlMzKthdoz0KkaZSd9/SqtXWOpNnreLOVxbxwZqtFHXM5YpRJZw3vDf52RlRlycSuca6+1ZASJtQW+u8smAN975WztQl6+mQk8FXhvfmK8P70P+gdlGXJxIZBYRIjBnLN/DH18t5fu5HVNc6w4s78ZXhfTjjiO7kZWmvQtoWBYRIHJVbdvHEuyv527QVlK/dRvvsDD4zsBtnHNGDEw7pSnZGetQliiScAkKkEe7OtKUbeKxsBc/N/ZDNO6tpn53B6QO7MXZwd0b276rzFdJqRRYQZjYG+B2QDtzn7r+q1/4d4KtANVAJXOHuy8K2GmB2OOtydz97b++ngJADVVVdy5uL1/LMe6t5ft5HbNqxm8x0o7RvZ046tJCTDinksO7tMbOoSxVpFpEEhJmlAwuBzwArgWnA+e4+L2aeU4B33H27mX0DONndvxK2bXX3fTp7qICQ5rS7ppZpS9bz6geVvLqgkvlhNx5d22VR2rczw0s6M6K4M4f3aE9Guq4Yl9TUWEAkcr95BLDI3cvDIh4BxgEfB4S7vxIz/9vARQmsR2SfZKancXz/rhzfvys/HHs4H27ayWsLK3m7fB1Tl67n33M/BKBddgaDenZgcFHBxz/7dc1XaEjKS2RAFAErYsZXAsc0Mv+VwLMx4zlmVkZw+OlX7v5UvIXMbDwwHqBPnz4HVLBIY7oX5HDu8N6cO7w3AKs37WDqkvWULd3A7IpNPPz2MnaFXXtkZ6RxeI8ODOrZgUO7t6ekaz4lXfPpWZBLWpoOT0lqSIozb2Z2EVAKnBQzua+7V5hZP+BlM5vt7ovrL+vuE4AJEBxiapGCRYAeBbmMG1rEuKFFAFTX1FK+dhtzKjYxd9Vm5lRsYvLMVWyJ6TgwOyONkq759CsMAqNP5zx6dsylR0EuPTvm6DJbSSqJ/N9YAfSOGe8VTtuDmZ0O/Bg4yd131U1394rwZ7mZ/QcYBnwqIESSRUZ6God0a88h3drzhaOCae7Omi27KK/cxpK121iydivllduYv3rLx/dhxOqYl0nPglx6dsylW4dsurTLpmu7LLrkZ9OlXdbHwwW5mdoTkYRLZEBMAwaYWQlBMJwHXBA7g5kNA+4Fxrj7mpjpnYDt7r7LzLoCI4FbElirSEKYGd065NCtQw7HHdxlj7bdNbV8tHknqzbuZNXGHazatCP4uXEnKzdsZ8byDazfXkW860gy0ozO+Vl0zs+iQ24mHXIy6ZCTEQ5n0D4nkw65GXTIyaR9Tib52enkZWWQm5lOblb4ykwnXSEjjUhYQLh7tZldCzxHcJnrA+4+18xuAsrcfTLwa6Ad8Fh42WDd5ayHA/eaWS1Bh4K/ir36SaQ1yExPo1enPHp1ymtwnppaZ/22KtZt28W6rVWs3Rr8rBtft62KzTt2U7FxB/N37mbzjt1s2VUdN1Tiyc5IIzcrnbzMdHKy0snLSicvM4OsjDSyMtLITDeyMtLJSk8jK8PCn3Vt4XDMz4z0NNLTID0tjXQz0tOCV0aakRb+TI99NTBPmhkZ6UF7WpphQJoZZkHomoXje0wHw0irmwc+nl/2j26UE2llamudbVXVbN5ZzeYdQWhs313DjqoatlfVsGN3DTuqqmOGa+oNV1NVXUtVTS27q52qmtqPx6uqPxmuSaEu1OtCIy0MkbpAiQ0ZLCZs+GQ48EnI1E2zT41bA+2fDqiP59nLsrHL1y8ldv2d87J49Krj9rod4onqMlcRiUBamtE+PLRU1DE3Ye9TU+vsrqllV3Utu8PwqKl1qmudmnqv6tpaat2prnFq/NPtNbV7Tq+udWrrfrrjHpzPqXVwgmF3gjbYY55gOjgx02Lmqd9W63y8LvaYLxiPjcFP/p72PcY//ll/epxl6+ap9wNv5P0anCccaJ+TmK9yBYSI7Jfg0FA6OZnqs6q10p08IiISlwJCRETiUkCIiEhcCggREYlLASEiInEpIEREJC4FhIiIxKWAEBGRuFpVVxtmVgks28/FuwJrm7GclqTao5HKtUNq16/am09fdy+M19CqAuJAmFlZQ/2RJDvVHo1Urh1Su37V3jJ0iElEROJSQIiISFwKiE9MiLqAA6Dao5HKtUNq16/aW4DOQYiISFzagxARkbgUECIiElebDwgzG2NmC8xskZndEHU9jTGz3mb2ipnNM7O5ZnZdOL2zmb1gZh+EPztFXWtDzCzdzGaY2T/D8RIzeyfc/n8zs6yoa2yImXU0s8fNbL6ZvW9mx6XKtjez/wr/z8wxs0lmlpOs297MHjCzNWY2J2Za3O1sgd+Hn+E9Mzsquso/rjVe/b8O/9+8Z2ZPmlnHmLYfhvUvMLPPRlN1fG06IMwsHbgTGAsMBM43s4HRVtWoauB6dx8IHAtcE9Z7A/CSuw8AXgrHk9V1wPsx4/8H/Mbd+wMbgCsjqappfgf8290PA4YQfI6k3/ZmVgR8Cyh198FAOnAeybvtJwJj6k1raDuPBQaEr/HA3S1UY2Mm8un6XwAGu/uRwELghwDh7+95wKBwmbvC76Wk0KYDAhgBLHL3cnevAh4BxkVcU4PcfbW7vxsObyH4gioiqPmhcLaHgHOiqbBxZtYLOBO4Lxw34FTg8XCWZK69ADgRuB/A3avcfSMpsu0JHi+ca2YZQB6wmiTd9u7+GrC+3uSGtvM44E8eeBvoaGY9WqbS+OLV7+7Pu3t1OPo20CscHgc84u673H0JsIjgeykptPWAKAJWxIyvDKclPTMrBoYB7wDd3H112PQh0C2isvbmt8D3gdpwvAuwMeYXJ5m3fwlQCTwYHiK7z8zySYFt7+4VwK3AcoJg2ARMJ3W2PTS8nVPxd/gK4NlwOKnrb+sBkZLMrB3wd+Db7r45ts2D65aT7tplM/scsMbdp0ddy37KAI4C7nb3YcA26h1OSuJt34ngL9USoCeQz6cPgaSMZN3OTWFmPyY4VPyXqGtpirYeEBVA75jxXuG0pGVmmQTh8Bd3fyKc/FHdbnX4c01U9TViJHC2mS0lOJR3KsEx/Y7hYQ9I7u2/Eljp7u+E448TBEYqbPvTgSXuXunuu4EnCP49UmXbQ8PbOWV+h83sMuBzwIX+yQ1oSV1/Ww+IacCA8GqOLIKTRZMjrqlB4TH7+4H33f32mKbJwKXh8KXA0y1d2964+w/dvZe7FxNs55fd/ULgFeBL4WxJWTuAu38IrDCzQ8NJpwHzSIFtT3Bo6Vgzywv/D9XVnhLbPtTQdp4MXBJezXQssCnmUFTSMLMxBIdXz3b37TFNk4HzzCzbzEoITrZPjaLGuNy9Tb+AMwiuKlgM/DjqevZS6yiCXev3gJnh6wyCY/kvAR8ALwKdo651L5/jZOCf4XA/gl+IRcBjQHbU9TVS91CgLNz+TwGdUmXbA78A5gNzgD8D2cm67YFJBOdKdhPsuV3Z0HYGjOBKxMXAbIIrtZKx/kUE5xrqfm/viZn/x2H9C4CxUdcf+1JXGyIiEldbP8QkIiINUECIiEhcCggREYlLASEiInEpIEREJC4FhLQ5ZrY1/FlsZhc0w/qWmtnfY8a/ZGYTD3S94bp+bmbfbY51iewrBYS0ZcXAPgVEzJ3H9R2dbD0BhzeP6Xdc9pv+80hb9ivgBDObGT4vIT3st39a2G//1wHM7GQze93MJhPcgRzPbQQ3PO2h/h5A+DyG4vA138wmmtlCM/uLmZ1uZm+GzzyI7dFziJm9FU7/Wsy6vhdT6y/CacXhcwX+RHBTXGw3DiL7pKG/hkTaghuA77r75wDMbDxBVw3DzSwbeNPMng/nPYqgP/8lDazrUeBqM+u/D+/fH/gyQe+e0wj2ZkYBZwM/4pMurY8keP5HPjDDzP4FDCbolmEEwd3Ek83sRIJuNQYAl3rQ/bXIflNAiHxiNHCkmdX1T1RA8GVbBUxtJBwAaoBfEzwI5tlG5ou1xN1nA5jZXIIH4riZzSY4/FXnaXffAewws1cIQmFUWO+McJ52Ya3LgWUKB2kOCgiRTxjwTXd/bo+JZicTdO+9N38mCIg5MdOq2fNQbk7M8K6Y4dqY8Vr2/N2s3x+Oh7X+r7vfW6/W4ibWKrJXOgchbdkWoH3M+HPAN8Iu1TGzQ8KHAjWJB11p/wb4r5jJSwkOTxE+L7lkP+ocZ8EzpLsQdHQ4Laz1ivDZIJhZkZkdtB/rFmmQ9iCkLXsPqDGzWQTPEf4dwaGdd8NusSvZ98dw3g/8JGb87wTdUc8lePrfwv2s8xWgK3Czu68CVpnZ4cBbQalsBS4iONQl0izUm6uIiMSlQ0wiIhKXAkJEROJSQIiISFwKCBERiUsBISIicSkgREQkLgWEiIjE9f8W4c7eCNh/3wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1w7UZJRiAUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FinalNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_sizes, num_classes):\n",
        "        super(FinalNet, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
        "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
        "        # self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
        "        #self.fc4 = nn.Linear(hidden_sizes[2], hidden_sizes[3])\n",
        "        self.out = nn.Linear(hidden_sizes[1], num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        # x = torch.tanh(self.fc3(x))\n",
        "        #x = torch.tanh(self.fc4(x))\n",
        "        x = self.out(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            y_score = self.forward(X)\n",
        "            y_pred = torch.argmax(y_score, axis=1)\n",
        "            \n",
        "        return y_pred\n",
        "            \n",
        "    \n",
        "classifier = FinalNet(350, [200, 50], 5)"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VqwlpwniAUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(classifier.parameters(), lr=0.000001, momentum=0.9)\n",
        "classifier = classifier.to(device)"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYJn45PGiAUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4714a059-1581-485e-a75c-2d8339131af6"
      },
      "source": [
        "old_loss = np.inf\n",
        "\n",
        "max_epoch = 5000\n",
        "# losses= []\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for data in trainloader:\n",
        "        \n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # extracting encoder features from AE1 to use as input to the MLFFNN\n",
        "        with torch.no_grad():\n",
        "            Z = ae1.get_z(X)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward\n",
        "        y_hat = classifier(Z)\n",
        "        \n",
        "        # Calculate Loss (Cross Entropy)\n",
        "        loss = criterion(y_hat, y)\n",
        "        \n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update Parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()*len(X)/train_size\n",
        "    \n",
        "    print('Epoch', epoch+1, ': Loss =', running_loss)\n",
        "    print(abs(running_loss-old_loss)/running_loss)\n",
        "    losses.append(running_loss)\n",
        "\n",
        "    if abs(running_loss-old_loss)/running_loss < 1e-10:\n",
        "        print('Converged')\n",
        "        break\n",
        "    \n",
        "    old_loss = running_loss\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : Loss = 0.9606887928464194\n",
            "inf\n",
            "Epoch 2 : Loss = 0.960336762395772\n",
            "0.00036656979554665624\n",
            "Epoch 3 : Loss = 0.9599651748483832\n",
            "0.00038708440381449415\n",
            "Epoch 4 : Loss = 0.9597038518298755\n",
            "0.00027229547741150414\n",
            "Epoch 5 : Loss = 0.9595532620495016\n",
            "0.00015693738568738953\n",
            "Epoch 6 : Loss = 0.9593770111149005\n",
            "0.00018371394411081457\n",
            "Epoch 7 : Loss = 0.9592653052373361\n",
            "0.00011644940868233982\n",
            "Epoch 8 : Loss = 0.9591273787346754\n",
            "0.00014380415544253957\n",
            "Epoch 9 : Loss = 0.9589805738492447\n",
            "0.0001530843162352696\n",
            "Epoch 10 : Loss = 0.9589083127000116\n",
            "7.535772531747222e-05\n",
            "Epoch 11 : Loss = 0.9588954231955786\n",
            "1.3442033532766498e-05\n",
            "Epoch 12 : Loss = 0.9588286768306387\n",
            "6.961239953794498e-05\n",
            "Epoch 13 : Loss = 0.9587970782410015\n",
            "3.295649345862046e-05\n",
            "Epoch 14 : Loss = 0.9587709903717043\n",
            "2.7209698206480235e-05\n",
            "Epoch 15 : Loss = 0.9587859077887101\n",
            "1.55586527550985e-05\n",
            "Epoch 16 : Loss = 0.9587264237078756\n",
            "6.204489556509148e-05\n",
            "Epoch 17 : Loss = 0.9586998237804932\n",
            "2.7745835268349362e-05\n",
            "Epoch 18 : Loss = 0.9587464576417749\n",
            "4.8640452238415954e-05\n",
            "Epoch 19 : Loss = 0.9586703858592295\n",
            "7.935134293028904e-05\n",
            "Epoch 20 : Loss = 0.95866896212101\n",
            "1.4851197605067676e-06\n",
            "Epoch 21 : Loss = 0.958641134879806\n",
            "2.9027797985720164e-05\n",
            "Epoch 22 : Loss = 0.9586675234816291\n",
            "2.7526333349959222e-05\n",
            "Epoch 23 : Loss = 0.9586252963001078\n",
            "4.404972587749093e-05\n",
            "Epoch 24 : Loss = 0.9586305401541974\n",
            "5.470151293809151e-06\n",
            "Epoch 25 : Loss = 0.9587013030594049\n",
            "7.381121208634969e-05\n",
            "Epoch 26 : Loss = 0.958605465563861\n",
            "9.997595359797965e-05\n",
            "Epoch 27 : Loss = 0.9586616375229575\n",
            "5.859414510599785e-05\n",
            "Epoch 28 : Loss = 0.9586047489534725\n",
            "5.934517802791375e-05\n",
            "Epoch 29 : Loss = 0.9586845270612024\n",
            "8.32162254402103e-05\n",
            "Epoch 30 : Loss = 0.9586349793455821\n",
            "5.1685695481510026e-05\n",
            "Epoch 31 : Loss = 0.958607722412456\n",
            "2.843387601501057e-05\n",
            "Epoch 32 : Loss = 0.9586310535669325\n",
            "2.4337991545016718e-05\n",
            "Epoch 33 : Loss = 0.9586869708516381\n",
            "5.832694759165332e-05\n",
            "Epoch 34 : Loss = 0.9586260169744493\n",
            "6.358462644403322e-05\n",
            "Epoch 35 : Loss = 0.9585958082567562\n",
            "3.1513509064929995e-05\n",
            "Epoch 36 : Loss = 0.9586305645379152\n",
            "3.6256178808322335e-05\n",
            "Epoch 37 : Loss = 0.958641850135543\n",
            "1.177248586243961e-05\n",
            "Epoch 38 : Loss = 0.9585979364135044\n",
            "4.581036571276252e-05\n",
            "Epoch 39 : Loss = 0.9586127346212214\n",
            "1.5437107376671822e-05\n",
            "Epoch 40 : Loss = 0.9586055332964117\n",
            "7.512292136399182e-06\n",
            "Epoch 41 : Loss = 0.9586149156093599\n",
            "9.787363826015647e-06\n",
            "Epoch 42 : Loss = 0.9586171927777204\n",
            "2.3754720629872136e-06\n",
            "Epoch 43 : Loss = 0.9586271752010691\n",
            "1.0413248869786245e-05\n",
            "Epoch 44 : Loss = 0.9586369246244427\n",
            "1.0170089554433484e-05\n",
            "Epoch 45 : Loss = 0.9586443386294624\n",
            "7.733843221032082e-06\n",
            "Epoch 46 : Loss = 0.9586130800572308\n",
            "3.2608121964873704e-05\n",
            "Epoch 47 : Loss = 0.9586320140145044\n",
            "1.9751017070984245e-05\n",
            "Epoch 48 : Loss = 0.9586096717552706\n",
            "2.330694117961446e-05\n",
            "Epoch 49 : Loss = 0.9586525437506762\n",
            "4.472109909385137e-05\n",
            "Epoch 50 : Loss = 0.9585944183848123\n",
            "6.06360362100306e-05\n",
            "Epoch 51 : Loss = 0.9586004587736996\n",
            "6.301258080998025e-06\n",
            "Epoch 52 : Loss = 0.9586292654275896\n",
            "3.0049837751611466e-05\n",
            "Epoch 53 : Loss = 0.9586196595972237\n",
            "1.0020481292806779e-05\n",
            "Epoch 54 : Loss = 0.9585925855419855\n",
            "2.824354751603532e-05\n",
            "Epoch 55 : Loss = 0.9586479243907061\n",
            "5.7725935990355636e-05\n",
            "Epoch 56 : Loss = 0.9586407108740371\n",
            "7.5247343318169585e-06\n",
            "Epoch 57 : Loss = 0.9586063813079485\n",
            "3.581195239048987e-05\n",
            "Epoch 58 : Loss = 0.9586307311599906\n",
            "2.5400658721501246e-05\n",
            "Epoch 59 : Loss = 0.95860280231996\n",
            "2.9134945112902476e-05\n",
            "Epoch 60 : Loss = 0.9586412283507262\n",
            "4.0083849546417334e-05\n",
            "Epoch 61 : Loss = 0.9586242125792936\n",
            "1.7750199931582257e-05\n",
            "Epoch 62 : Loss = 0.9586163420568814\n",
            "8.210294428486275e-06\n",
            "Epoch 63 : Loss = 0.9586215019226075\n",
            "5.382589182263952e-06\n",
            "Epoch 64 : Loss = 0.9586052352731878\n",
            "1.6969080515345804e-05\n",
            "Epoch 65 : Loss = 0.958611633289944\n",
            "6.674253195033405e-06\n",
            "Epoch 66 : Loss = 0.9586126452142543\n",
            "1.0556133546605771e-06\n",
            "Epoch 67 : Loss = 0.9586069651625374\n",
            "5.925318637652333e-06\n",
            "Epoch 68 : Loss = 0.9586042883721266\n",
            "2.7923830961754504e-06\n",
            "Epoch 69 : Loss = 0.9586254805326463\n",
            "2.2106819555725996e-05\n",
            "Epoch 70 : Loss = 0.9586071521043777\n",
            "1.9119853454366834e-05\n",
            "Epoch 71 : Loss = 0.9586213678121568\n",
            "1.4829324962248572e-05\n",
            "Epoch 72 : Loss = 0.9586247151548211\n",
            "3.4918176126223872e-06\n",
            "Epoch 73 : Loss = 0.9586138955571435\n",
            "1.1286710663922758e-05\n",
            "Epoch 74 : Loss = 0.9586387263102967\n",
            "2.5902096871000845e-05\n",
            "Epoch 75 : Loss = 0.9585872468623249\n",
            "5.3703455935070816e-05\n",
            "Epoch 76 : Loss = 0.9586101797494022\n",
            "2.392305815417755e-05\n",
            "Epoch 77 : Loss = 0.9585836583917792\n",
            "2.7667233204808523e-05\n",
            "Epoch 78 : Loss = 0.9585829214616254\n",
            "7.687703768651044e-07\n",
            "Epoch 79 : Loss = 0.9586318216540591\n",
            "5.101039974802815e-05\n",
            "Epoch 80 : Loss = 0.9586038291454316\n",
            "2.9201331954265424e-05\n",
            "Epoch 81 : Loss = 0.9586130123246802\n",
            "9.579652195951848e-06\n",
            "Epoch 82 : Loss = 0.9586407528682187\n",
            "2.893737143501526e-05\n",
            "Epoch 83 : Loss = 0.9586060439998455\n",
            "3.620764608198807e-05\n",
            "Epoch 84 : Loss = 0.9585936950011686\n",
            "1.2882411746765909e-05\n",
            "Epoch 85 : Loss = 0.9585920734839003\n",
            "1.6915613149744103e-06\n",
            "Epoch 86 : Loss = 0.9586224190213464\n",
            "3.1655359653547904e-05\n",
            "Epoch 87 : Loss = 0.9585836746475914\n",
            "4.041835343085167e-05\n",
            "Epoch 88 : Loss = 0.9585907919840382\n",
            "7.424791168741774e-06\n",
            "Epoch 89 : Loss = 0.9586228050968861\n",
            "3.339490013980536e-05\n",
            "Epoch 90 : Loss = 0.9586532305587421\n",
            "3.1737713790637075e-05\n",
            "Epoch 91 : Loss = 0.9586087898774583\n",
            "4.635955955443675e-05\n",
            "Epoch 92 : Loss = 0.9586109424179251\n",
            "2.245478714576891e-06\n",
            "Epoch 93 : Loss = 0.9586043642325832\n",
            "6.862252653266416e-06\n",
            "Epoch 94 : Loss = 0.9585834402929652\n",
            "2.1827979431463175e-05\n",
            "Epoch 95 : Loss = 0.9585792476480658\n",
            "4.373811460718577e-06\n",
            "Epoch 96 : Loss = 0.9586054127324709\n",
            "2.7294947490995066e-05\n",
            "Epoch 97 : Loss = 0.9585914733734998\n",
            "1.45415011068664e-05\n",
            "Epoch 98 : Loss = 0.9586297964507885\n",
            "3.9976931064075845e-05\n",
            "Epoch 99 : Loss = 0.9585835811766713\n",
            "4.821204433781328e-05\n",
            "Epoch 100 : Loss = 0.9586103192784571\n",
            "2.7892566195091988e-05\n",
            "Epoch 101 : Loss = 0.9585963663729756\n",
            "1.455555849251203e-05\n",
            "Epoch 102 : Loss = 0.9586592628197235\n",
            "6.560876130570244e-05\n",
            "Epoch 103 : Loss = 0.9586192951960999\n",
            "4.169290543582824e-05\n",
            "Epoch 104 : Loss = 0.9586762501434847\n",
            "5.9409990991489844e-05\n",
            "Epoch 105 : Loss = 0.958589479327202\n",
            "9.051926622814915e-05\n",
            "Epoch 106 : Loss = 0.958579969677058\n",
            "9.920560041647417e-06\n",
            "Epoch 107 : Loss = 0.9585982005704532\n",
            "1.9018284599631598e-05\n",
            "Epoch 108 : Loss = 0.9586125138131059\n",
            "1.4931207809638834e-05\n",
            "Epoch 109 : Loss = 0.9585980339483783\n",
            "1.5105251851954836e-05\n",
            "Epoch 110 : Loss = 0.9586483443325219\n",
            "5.248054142171735e-05\n",
            "Epoch 111 : Loss = 0.9586615697904065\n",
            "1.3795752642422293e-05\n",
            "Epoch 112 : Loss = 0.9586012593724511\n",
            "6.291502057370823e-05\n",
            "Epoch 113 : Loss = 0.9586305591193113\n",
            "3.0564169461784084e-05\n",
            "Epoch 114 : Loss = 0.9586172781207346\n",
            "1.3854328395484545e-05\n",
            "Epoch 115 : Loss = 0.958633463491093\n",
            "1.6883794458279813e-05\n",
            "Epoch 116 : Loss = 0.9586193751205101\n",
            "1.4696521840224454e-05\n",
            "Epoch 117 : Loss = 0.958597334948453\n",
            "2.2992106543126283e-05\n",
            "Epoch 118 : Loss = 0.958606808023019\n",
            "9.882127360996823e-06\n",
            "Epoch 119 : Loss = 0.9586075354706155\n",
            "7.5885862522084e-07\n",
            "Epoch 120 : Loss = 0.9586270912127062\n",
            "2.039973861570325e-05\n",
            "Epoch 121 : Loss = 0.9586072956973857\n",
            "2.0650286524364914e-05\n",
            "Epoch 122 : Loss = 0.9586171263998206\n",
            "1.0255087421394867e-05\n",
            "Epoch 123 : Loss = 0.9585940824313599\n",
            "2.4039339364788375e-05\n",
            "Epoch 124 : Loss = 0.9586341191421855\n",
            "4.1764329086750724e-05\n",
            "Epoch 125 : Loss = 0.9585758596658704\n",
            "6.0777116101599774e-05\n",
            "Epoch 126 : Loss = 0.9586317471482537\n",
            "5.829921922524604e-05\n",
            "Epoch 127 : Loss = 0.958619314161214\n",
            "1.2969681349011483e-05\n",
            "Epoch 128 : Loss = 0.9585957987741991\n",
            "2.4531076648802146e-05\n",
            "Epoch 129 : Loss = 0.9585805264386265\n",
            "1.5932240590549564e-05\n",
            "Epoch 130 : Loss = 0.9585938264023172\n",
            "1.3874451644051203e-05\n",
            "Epoch 131 : Loss = 0.9585950564254413\n",
            "1.2831519585748263e-06\n",
            "Epoch 132 : Loss = 0.9585774120959368\n",
            "1.8406786224894593e-05\n",
            "Epoch 133 : Loss = 0.9585964896462181\n",
            "1.990154406713902e-05\n",
            "Epoch 134 : Loss = 0.9585930054838007\n",
            "3.63466288355396e-06\n",
            "Epoch 135 : Loss = 0.9586014124480158\n",
            "8.770031116106772e-06\n",
            "Epoch 136 : Loss = 0.9585801457816905\n",
            "2.2185590238727758e-05\n",
            "Epoch 137 : Loss = 0.9585691514340317\n",
            "1.14695404524388e-05\n",
            "Epoch 138 : Loss = 0.9586429528214716\n",
            "7.698527092150597e-05\n",
            "Epoch 139 : Loss = 0.9586224921725015\n",
            "2.134380231756336e-05\n",
            "Epoch 140 : Loss = 0.9585908678444945\n",
            "3.299043321586597e-05\n",
            "Epoch 141 : Loss = 0.9586630111390895\n",
            "7.52540713020808e-05\n",
            "Epoch 142 : Loss = 0.9585920314897192\n",
            "7.404573273992166e-05\n",
            "Epoch 143 : Loss = 0.9585783495144409\n",
            "1.4273194554436433e-05\n",
            "Epoch 144 : Loss = 0.9585856212811036\n",
            "7.585933380672154e-06\n",
            "Epoch 145 : Loss = 0.9586269191720271\n",
            "4.308025374378401e-05\n",
            "Epoch 146 : Loss = 0.9585913758386266\n",
            "3.707871184362101e-05\n",
            "Epoch 147 : Loss = 0.9586236382072625\n",
            "3.3654885348105504e-05\n",
            "Epoch 148 : Loss = 0.9586025882850995\n",
            "2.195896654177126e-05\n",
            "Epoch 149 : Loss = 0.9585817876187236\n",
            "2.1699417456656164e-05\n",
            "Epoch 150 : Loss = 0.9586167958649718\n",
            "3.651954190585476e-05\n",
            "Epoch 151 : Loss = 0.9585946920243179\n",
            "2.305858861710676e-05\n",
            "Epoch 152 : Loss = 0.9585799276828769\n",
            "1.540230607235442e-05\n",
            "Epoch 153 : Loss = 0.9585902555422348\n",
            "1.0774008287823943e-05\n",
            "Epoch 154 : Loss = 0.9585954533381894\n",
            "5.422303993355266e-06\n",
            "Epoch 155 : Loss = 0.9585933536291124\n",
            "2.1904064628690043e-06\n",
            "Epoch 156 : Loss = 0.9586289850148287\n",
            "3.716910950260128e-05\n",
            "Epoch 157 : Loss = 0.9586109139702539\n",
            "1.8851281903319698e-05\n",
            "Epoch 158 : Loss = 0.9586122726852244\n",
            "1.4173769825918307e-06\n",
            "Epoch 159 : Loss = 0.9586152705279264\n",
            "3.1272636626343123e-06\n",
            "Epoch 160 : Loss = 0.9586035812442957\n",
            "1.2194074651315601e-05\n",
            "Epoch 161 : Loss = 0.9585884199901059\n",
            "1.5816229232064573e-05\n",
            "Epoch 162 : Loss = 0.9585716629570182\n",
            "1.74812522998909e-05\n",
            "Epoch 163 : Loss = 0.9585814448920162\n",
            "1.0204594560154327e-05\n",
            "Epoch 164 : Loss = 0.958595939657905\n",
            "1.5120829631247565e-05\n",
            "Epoch 165 : Loss = 0.9585945687510753\n",
            "1.4301216326617377e-06\n",
            "Epoch 166 : Loss = 0.9585806050083854\n",
            "1.4567103295182091e-05\n",
            "Epoch 167 : Loss = 0.9585861523043026\n",
            "5.786956032944343e-06\n",
            "Epoch 168 : Loss = 0.9585717686197974\n",
            "1.5005328735934234e-05\n",
            "Epoch 169 : Loss = 0.9585799791596152\n",
            "8.565315358462023e-06\n",
            "Epoch 170 : Loss = 0.9585745578462426\n",
            "5.655599064560394e-06\n",
            "Epoch 171 : Loss = 0.9586128687316718\n",
            "3.996491876847004e-05\n",
            "Epoch 172 : Loss = 0.9586097923192113\n",
            "3.209243724825239e-06\n",
            "Epoch 173 : Loss = 0.9585986625064502\n",
            "1.161050311918663e-05\n",
            "Epoch 174 : Loss = 0.9586164450103586\n",
            "1.8550176142856652e-05\n",
            "Epoch 175 : Loss = 0.9585833833976223\n",
            "3.449007494697309e-05\n",
            "Epoch 176 : Loss = 0.9585899466818029\n",
            "6.846810988683961e-06\n",
            "Epoch 177 : Loss = 0.9585954953323712\n",
            "5.7883127923728e-06\n",
            "Epoch 178 : Loss = 0.9586042775349185\n",
            "9.161447276117877e-06\n",
            "Epoch 179 : Loss = 0.9586323201656342\n",
            "2.925274907360417e-05\n",
            "Epoch 180 : Loss = 0.9585821533744986\n",
            "5.233436796101602e-05\n",
            "Epoch 181 : Loss = 0.9586218758062883\n",
            "4.143701786100459e-05\n",
            "Epoch 182 : Loss = 0.9586869667876851\n",
            "6.789596985430475e-05\n",
            "Epoch 183 : Loss = 0.9585874175483532\n",
            "0.00010384993325540155\n",
            "Epoch 184 : Loss = 0.9586189009926535\n",
            "3.284250317583019e-05\n",
            "Epoch 185 : Loss = 0.9585920775478538\n",
            "2.7982126524837317e-05\n",
            "Epoch 186 : Loss = 0.9585950008847496\n",
            "3.0496058221448313e-06\n",
            "Epoch 187 : Loss = 0.9586314328692178\n",
            "3.800416220360141e-05\n",
            "Epoch 188 : Loss = 0.9586108326911925\n",
            "2.1489615308712673e-05\n",
            "Epoch 189 : Loss = 0.9585951160300862\n",
            "1.6395515524243518e-05\n",
            "Epoch 190 : Loss = 0.9586303924972361\n",
            "3.679881988517286e-05\n",
            "Epoch 191 : Loss = 0.9585796486247669\n",
            "5.2936521802943874e-05\n",
            "Epoch 192 : Loss = 0.9586264938116075\n",
            "4.8866985361894546e-05\n",
            "Epoch 193 : Loss = 0.9586297680031169\n",
            "3.415491171625974e-06\n",
            "Epoch 194 : Loss = 0.9585997746749356\n",
            "3.1288686867772555e-05\n",
            "Epoch 195 : Loss = 0.9585700969804417\n",
            "3.096038003626362e-05\n",
            "Epoch 196 : Loss = 0.9586111198772084\n",
            "4.279409649652025e-05\n",
            "Epoch 197 : Loss = 0.9585709653117439\n",
            "4.189002892593198e-05\n",
            "Epoch 198 : Loss = 0.9585934918035159\n",
            "2.349952504857187e-05\n",
            "Epoch 199 : Loss = 0.9585560831156644\n",
            "3.902608153079823e-05\n",
            "Epoch 200 : Loss = 0.9586087451739744\n",
            "5.493592518858895e-05\n",
            "Epoch 201 : Loss = 0.9585892178795554\n",
            "2.0370867995160275e-05\n",
            "Epoch 202 : Loss = 0.9585728509859602\n",
            "1.7074230277180512e-05\n",
            "Epoch 203 : Loss = 0.9586096690459687\n",
            "3.840777033375732e-05\n",
            "Epoch 204 : Loss = 0.9586508030241186\n",
            "4.290819766719743e-05\n",
            "Epoch 205 : Loss = 0.9585932872512124\n",
            "6.000018325934114e-05\n",
            "Epoch 206 : Loss = 0.9585864123972979\n",
            "7.1718666419354135e-06\n",
            "Epoch 207 : Loss = 0.958616695620797\n",
            "3.159054462269834e-05\n",
            "Epoch 208 : Loss = 0.9586270722475917\n",
            "1.0824466672297158e-05\n",
            "Epoch 209 : Loss = 0.958579510450363\n",
            "4.961695582904759e-05\n",
            "Epoch 210 : Loss = 0.9585756334391509\n",
            "4.044554312603878e-06\n",
            "Epoch 211 : Loss = 0.9585883102633737\n",
            "1.3224471952205838e-05\n",
            "Epoch 212 : Loss = 0.9585952812975103\n",
            "7.2721348337632595e-06\n",
            "Epoch 213 : Loss = 0.9586171250451693\n",
            "2.2786727973363073e-05\n",
            "Epoch 214 : Loss = 0.9586238102479412\n",
            "6.973749974129646e-06\n",
            "Epoch 215 : Loss = 0.9585886475714772\n",
            "3.668171593003506e-05\n",
            "Epoch 216 : Loss = 0.958594487472014\n",
            "6.092149092386429e-06\n",
            "Epoch 217 : Loss = 0.9586506445299494\n",
            "5.857927312291649e-05\n",
            "Epoch 218 : Loss = 0.9585830176418477\n",
            "7.054880678781002e-05\n",
            "Epoch 219 : Loss = 0.9585815139792181\n",
            "1.5686330350662704e-06\n",
            "Epoch 220 : Loss = 0.9586925791068512\n",
            "0.00011585061786607278\n",
            "Epoch 221 : Loss = 0.9585861739787189\n",
            "0.00011100215194077733\n",
            "Epoch 222 : Loss = 0.958576195619323\n",
            "1.0409563101587494e-05\n",
            "Epoch 223 : Loss = 0.9586318609389393\n",
            "5.8067462479073157e-05\n",
            "Epoch 224 : Loss = 0.9586152705279265\n",
            "1.7306641697482806e-05\n",
            "Epoch 225 : Loss = 0.9586282643404873\n",
            "1.355458945262013e-05\n",
            "Epoch 226 : Loss = 0.9585914544083851\n",
            "3.840002112778875e-05\n",
            "Epoch 227 : Loss = 0.9586010331457309\n",
            "9.992412916890625e-06\n",
            "Epoch 228 : Loss = 0.9586242139339449\n",
            "2.4181308876951036e-05\n",
            "Epoch 229 : Loss = 0.9586009518666699\n",
            "2.4266684932546082e-05\n",
            "Epoch 230 : Loss = 0.9586052501743488\n",
            "4.483918357545283e-06\n",
            "Epoch 231 : Loss = 0.9586015695875341\n",
            "3.839537646858879e-06\n",
            "Epoch 232 : Loss = 0.9586189037019557\n",
            "1.8082383264797538e-05\n",
            "Epoch 233 : Loss = 0.958589644594626\n",
            "3.052307887388261e-05\n",
            "Epoch 234 : Loss = 0.9586164409464057\n",
            "2.795315272629483e-05\n",
            "Epoch 235 : Loss = 0.9586400321938775\n",
            "2.460907815185381e-05\n",
            "Epoch 236 : Loss = 0.9586278985847128\n",
            "1.265726689433679e-05\n",
            "Epoch 237 : Loss = 0.9585626504637978\n",
            "6.80687077504395e-05\n",
            "Epoch 238 : Loss = 0.9585790187120437\n",
            "1.7075533603681598e-05\n",
            "Epoch 239 : Loss = 0.9586012200875718\n",
            "2.3160178667496273e-05\n",
            "Epoch 240 : Loss = 0.9585724540732123\n",
            "3.0009222815846638e-05\n",
            "Epoch 241 : Loss = 0.9585747881369157\n",
            "2.434931246052913e-06\n",
            "Epoch 242 : Loss = 0.9585831043395129\n",
            "8.67551551824508e-06\n",
            "Epoch 243 : Loss = 0.9585690525445069\n",
            "1.465913693825198e-05\n",
            "Epoch 244 : Loss = 0.9586120843887331\n",
            "4.48897368675576e-05\n",
            "Epoch 245 : Loss = 0.9585907337340439\n",
            "2.2272961690391685e-05\n",
            "Epoch 246 : Loss = 0.9586010859771207\n",
            "1.079932333502412e-05\n",
            "Epoch 247 : Loss = 0.958598881959915\n",
            "2.2992069437064317e-06\n",
            "Epoch 248 : Loss = 0.9585948315533724\n",
            "4.225358211088014e-06\n",
            "Epoch 249 : Loss = 0.9585905901410364\n",
            "4.424633810968842e-06\n",
            "Epoch 250 : Loss = 0.9585720923813911\n",
            "1.9297202362107836e-05\n",
            "Epoch 251 : Loss = 0.9586509127508512\n",
            "8.222009535670172e-05\n",
            "Epoch 252 : Loss = 0.9585792503573677\n",
            "7.475896589336246e-05\n",
            "Epoch 253 : Loss = 0.9585703895850615\n",
            "9.243736717189838e-06\n",
            "Epoch 254 : Loss = 0.9586155048825526\n",
            "4.7062974948136516e-05\n",
            "Epoch 255 : Loss = 0.9585898234085605\n",
            "2.679088945557558e-05\n",
            "Epoch 256 : Loss = 0.9585957662625746\n",
            "6.199541269922907e-06\n",
            "Epoch 257 : Loss = 0.958595099774274\n",
            "6.952761397446154e-07\n",
            "Epoch 258 : Loss = 0.9585714137012308\n",
            "2.470976361771976e-05\n",
            "Epoch 259 : Loss = 0.9586041461337693\n",
            "3.414593257347817e-05\n",
            "Epoch 260 : Loss = 0.9585800103165887\n",
            "2.517871948181548e-05\n",
            "Epoch 261 : Loss = 0.9585939293557946\n",
            "1.4520266381452776e-05\n",
            "Epoch 262 : Loss = 0.9586251052943144\n",
            "3.252151268278727e-05\n",
            "Epoch 263 : Loss = 0.958597355268218\n",
            "2.89485736049072e-05\n",
            "Epoch 264 : Loss = 0.9585786773399874\n",
            "1.9485023683665052e-05\n",
            "Epoch 265 : Loss = 0.9585731801661577\n",
            "5.734746124172766e-06\n",
            "Epoch 266 : Loss = 0.958567264405164\n",
            "6.171461527319587e-06\n",
            "Epoch 267 : Loss = 0.958566876974973\n",
            "4.041764850697573e-07\n",
            "Epoch 268 : Loss = 0.9586187844926658\n",
            "5.41482375814975e-05\n",
            "Epoch 269 : Loss = 0.958565350283276\n",
            "5.574394001823216e-05\n",
            "Epoch 270 : Loss = 0.9585705426606267\n",
            "5.416792108200896e-06\n",
            "Epoch 271 : Loss = 0.9586184742775832\n",
            "5.0000723168420386e-05\n",
            "Epoch 272 : Loss = 0.9585566317493264\n",
            "6.451630108066306e-05\n",
            "Epoch 273 : Loss = 0.9586050280115819\n",
            "5.04861343737042e-05\n",
            "Epoch 274 : Loss = 0.9586010751399126\n",
            "4.12358359679977e-06\n",
            "Epoch 275 : Loss = 0.9585734727707773\n",
            "2.87952566175784e-05\n",
            "Epoch 276 : Loss = 0.958638918670741\n",
            "6.82696046332648e-05\n",
            "Epoch 277 : Loss = 0.9586378092115576\n",
            "1.1573288396846568e-06\n",
            "Epoch 278 : Loss = 0.9585712823000824\n",
            "6.940215370901697e-05\n",
            "Epoch 279 : Loss = 0.9586111009120943\n",
            "4.153781650773655e-05\n",
            "Epoch 280 : Loss = 0.9586024243723263\n",
            "9.051239124159886e-06\n",
            "Epoch 281 : Loss = 0.9586630734530361\n",
            "6.326422951845036e-05\n",
            "Epoch 282 : Loss = 0.9585520421916788\n",
            "0.0001158322725008198\n",
            "Epoch 283 : Loss = 0.958560902963985\n",
            "9.243828199981695e-06\n",
            "Epoch 284 : Loss = 0.9586265520616012\n",
            "6.848245281231816e-05\n",
            "Epoch 285 : Loss = 0.9585571858015927\n",
            "7.236528089925316e-05\n",
            "Epoch 286 : Loss = 0.958568360317837\n",
            "1.1657505825273183e-05\n",
            "Epoch 287 : Loss = 0.9585721397941761\n",
            "3.942818888860964e-06\n",
            "Epoch 288 : Loss = 0.9585571072318338\n",
            "1.568249009771154e-05\n",
            "Epoch 289 : Loss = 0.9585900564085353\n",
            "3.4372541715004725e-05\n",
            "Epoch 290 : Loss = 0.958595017140562\n",
            "5.1750029344007e-06\n",
            "Epoch 291 : Loss = 0.9586001512679186\n",
            "5.355859113841886e-06\n",
            "Epoch 292 : Loss = 0.9585898545655335\n",
            "1.0741509871119595e-05\n",
            "Epoch 293 : Loss = 0.9585671560330827\n",
            "2.3679647594721515e-05\n",
            "Epoch 294 : Loss = 0.9585657661611384\n",
            "1.4499494905592055e-06\n",
            "Epoch 295 : Loss = 0.9585873145948758\n",
            "2.2479364591287797e-05\n",
            "Epoch 296 : Loss = 0.9585639265450564\n",
            "2.4399050675400712e-05\n",
            "Epoch 297 : Loss = 0.9585838873278008\n",
            "2.082319868738729e-05\n",
            "Epoch 298 : Loss = 0.9585812918164512\n",
            "2.7076590912744428e-06\n",
            "Epoch 299 : Loss = 0.9586007838899439\n",
            "2.033388019308004e-05\n",
            "Epoch 300 : Loss = 0.958597176454284\n",
            "3.763244612509189e-06\n",
            "Epoch 301 : Loss = 0.9585824039849369\n",
            "1.5410745373274234e-05\n",
            "Epoch 302 : Loss = 0.9585939821871844\n",
            "1.2078317267432766e-05\n",
            "Epoch 303 : Loss = 0.9585696770386262\n",
            "2.5355640951747037e-05\n",
            "Epoch 304 : Loss = 0.9585899602283131\n",
            "2.115940133788975e-05\n",
            "Epoch 305 : Loss = 0.9585676057772203\n",
            "2.332068281678593e-05\n",
            "Epoch 306 : Loss = 0.9585903300480408\n",
            "2.3705925365810648e-05\n",
            "Epoch 307 : Loss = 0.9586051946336572\n",
            "1.5506473050224518e-05\n",
            "Epoch 308 : Loss = 0.958579014648091\n",
            "2.7311244212674886e-05\n",
            "Epoch 309 : Loss = 0.9585633074695413\n",
            "1.6386167118341936e-05\n",
            "Epoch 310 : Loss = 0.9585940499197355\n",
            "3.2070353656755813e-05\n",
            "Epoch 311 : Loss = 0.9585772319273516\n",
            "1.7544744256172455e-05\n",
            "Epoch 312 : Loss = 0.9585624621673062\n",
            "1.5408239554818018e-05\n",
            "Epoch 313 : Loss = 0.958567806265571\n",
            "5.575086321356008e-06\n",
            "Epoch 314 : Loss = 0.9585743668404489\n",
            "6.844095883281451e-06\n",
            "Epoch 315 : Loss = 0.9585933021523735\n",
            "1.9753227862142507e-05\n",
            "Epoch 316 : Loss = 0.9585718349976974\n",
            "2.2394935770415226e-05\n",
            "Epoch 317 : Loss = 0.9585855129090224\n",
            "1.4268848361265941e-05\n",
            "Epoch 318 : Loss = 0.958587555722757\n",
            "2.1310664032925817e-06\n",
            "Epoch 319 : Loss = 0.9585555940866471\n",
            "3.334353928663957e-05\n",
            "Epoch 320 : Loss = 0.9585738872939893\n",
            "1.9083773911040816e-05\n",
            "Epoch 321 : Loss = 0.9585767794739117\n",
            "3.0171604240504214e-06\n",
            "Epoch 322 : Loss = 0.9585816778919916\n",
            "5.110068544806749e-06\n",
            "Epoch 323 : Loss = 0.9585902270945637\n",
            "8.918516307021774e-06\n",
            "Epoch 324 : Loss = 0.9585659585215828\n",
            "2.531758275487779e-05\n",
            "Epoch 325 : Loss = 0.9585679214109075\n",
            "2.0477310797734767e-06\n",
            "Epoch 326 : Loss = 0.9585766142064875\n",
            "9.068441114870133e-06\n",
            "Epoch 327 : Loss = 0.9585837437347933\n",
            "7.437564377995125e-06\n",
            "Epoch 328 : Loss = 0.958613636818799\n",
            "3.118366238237112e-05\n",
            "Epoch 329 : Loss = 0.9585734334858982\n",
            "4.194079607920865e-05\n",
            "Epoch 330 : Loss = 0.9586232196200974\n",
            "5.193503889775294e-05\n",
            "Epoch 331 : Loss = 0.9585523618893189\n",
            "7.392160678511818e-05\n",
            "Epoch 332 : Loss = 0.9586059139533474\n",
            "5.586452498254428e-05\n",
            "Epoch 333 : Loss = 0.9585574635050512\n",
            "5.054516827712366e-05\n",
            "Epoch 334 : Loss = 0.9585867686705154\n",
            "3.057121840396499e-05\n",
            "Epoch 335 : Loss = 0.9585639157078483\n",
            "2.38408334516271e-05\n",
            "Epoch 336 : Loss = 0.9585844115777448\n",
            "2.1381392863214885e-05\n",
            "Epoch 337 : Loss = 0.9585871208797799\n",
            "2.8263492969504112e-06\n",
            "Epoch 338 : Loss = 0.958573801950975\n",
            "1.3894526199082323e-05\n",
            "Epoch 339 : Loss = 0.9586036381396383\n",
            "3.112463533027174e-05\n",
            "Epoch 340 : Loss = 0.9585635215044022\n",
            "4.1850784362433816e-05\n",
            "Epoch 341 : Loss = 0.958550797267394\n",
            "1.3274452480169737e-05\n",
            "Epoch 342 : Loss = 0.9585595036094838\n",
            "9.08273514272397e-06\n",
            "Epoch 343 : Loss = 0.9585742747241802\n",
            "1.5409462871970215e-05\n",
            "Epoch 344 : Loss = 0.9585513296452435\n",
            "2.3937245953468514e-05\n",
            "Epoch 345 : Loss = 0.9585851457985964\n",
            "3.527715143633806e-05\n",
            "Epoch 346 : Loss = 0.9586001864888452\n",
            "1.5690264263148318e-05\n",
            "Epoch 347 : Loss = 0.9585534916682676\n",
            "4.871383911631358e-05\n",
            "Epoch 348 : Loss = 0.9585867646065626\n",
            "3.4710408617597825e-05\n",
            "Epoch 349 : Loss = 0.9586090052669698\n",
            "2.320097170487319e-05\n",
            "Epoch 350 : Loss = 0.9585749195380646\n",
            "3.555875311405114e-05\n",
            "Epoch 351 : Loss = 0.9585942165418105\n",
            "2.0130523857672392e-05\n",
            "Epoch 352 : Loss = 0.9586094401099468\n",
            "1.5880886938133368e-05\n",
            "Epoch 353 : Loss = 0.9585704573176125\n",
            "4.066763380478138e-05\n",
            "Epoch 354 : Loss = 0.9585714733058754\n",
            "1.0598982874596408e-06\n",
            "Epoch 355 : Loss = 0.9585890458388762\n",
            "1.8331664728488915e-05\n",
            "Epoch 356 : Loss = 0.9585515761917287\n",
            "3.9089860241348435e-05\n",
            "Epoch 357 : Loss = 0.9586014639247543\n",
            "5.204220408902572e-05\n",
            "Epoch 358 : Loss = 0.9585981355472043\n",
            "3.4721302145199256e-06\n",
            "Epoch 359 : Loss = 0.9585652270100332\n",
            "3.433103584795393e-05\n",
            "Epoch 360 : Loss = 0.9585746784101833\n",
            "9.859847503742481e-06\n",
            "Epoch 361 : Loss = 0.9585636041381144\n",
            "1.1552986177563152e-05\n",
            "Epoch 362 : Loss = 0.9586281884800306\n",
            "6.737162822079596e-05\n",
            "Epoch 363 : Loss = 0.9585723023522984\n",
            "5.8301421389994624e-05\n",
            "Epoch 364 : Loss = 0.9586191597309978\n",
            "4.8880077373489756e-05\n",
            "Epoch 365 : Loss = 0.9585904018445449\n",
            "3.0000181931207798e-05\n",
            "Epoch 366 : Loss = 0.9585676558993081\n",
            "2.372909736395044e-05\n",
            "Epoch 367 : Loss = 0.9585739577358421\n",
            "6.574178740286815e-06\n",
            "Epoch 368 : Loss = 0.9585600346326827\n",
            "1.4525019462898848e-05\n",
            "Epoch 369 : Loss = 0.9585712904279882\n",
            "1.1742262070513698e-05\n",
            "Epoch 370 : Loss = 0.9585806348107077\n",
            "9.74814468407731e-06\n",
            "Epoch 371 : Loss = 0.9585754993287\n",
            "5.357410043592699e-06\n",
            "Epoch 372 : Loss = 0.9585502432151274\n",
            "2.6348241786379244e-05\n",
            "Epoch 373 : Loss = 0.9585690796375276\n",
            "1.965056332436181e-05\n",
            "Epoch 374 : Loss = 0.9585983563553203\n",
            "3.054117253450074e-05\n",
            "Epoch 375 : Loss = 0.9585762321949004\n",
            "2.3080230530286595e-05\n",
            "Epoch 376 : Loss = 0.9585646770217203\n",
            "1.2054661993158323e-05\n",
            "Epoch 377 : Loss = 0.9585831368511374\n",
            "1.9257410971885235e-05\n",
            "Epoch 378 : Loss = 0.9586108096621253\n",
            "2.886761833791099e-05\n",
            "Epoch 379 : Loss = 0.9586032859303735\n",
            "7.848639642970665e-06\n",
            "Epoch 380 : Loss = 0.9586067782206968\n",
            "3.6430895365171992e-06\n",
            "Epoch 381 : Loss = 0.9585793844678184\n",
            "2.8577448380679852e-05\n",
            "Epoch 382 : Loss = 0.9585906673561443\n",
            "1.1770288101153339e-05\n",
            "Epoch 383 : Loss = 0.9585811549966987\n",
            "9.92337414103084e-06\n",
            "Epoch 384 : Loss = 0.9585666954517367\n",
            "1.508454761744869e-05\n",
            "Epoch 385 : Loss = 0.9585679498585786\n",
            "1.308625895681334e-06\n",
            "Epoch 386 : Loss = 0.958583881909197\n",
            "1.6620403199986535e-05\n",
            "Epoch 387 : Loss = 0.9585576870224694\n",
            "2.7327397278491738e-05\n",
            "Epoch 388 : Loss = 0.9585467387329449\n",
            "1.1421758670721746e-05\n",
            "Epoch 389 : Loss = 0.9585518498312344\n",
            "5.332104142712386e-06\n",
            "Epoch 390 : Loss = 0.9585869285193357\n",
            "3.659416486666267e-05\n",
            "Epoch 391 : Loss = 0.9585606360977345\n",
            "2.742906459029314e-05\n",
            "Epoch 392 : Loss = 0.958591497757218\n",
            "3.21947978421699e-05\n",
            "Epoch 393 : Loss = 0.9585859301415355\n",
            "5.808155020246365e-06\n",
            "Epoch 394 : Loss = 0.9585746337066997\n",
            "1.1784616907804494e-05\n",
            "Epoch 395 : Loss = 0.9585779932412236\n",
            "3.504706500246429e-06\n",
            "Epoch 396 : Loss = 0.9585528265346182\n",
            "2.6254897913602703e-05\n",
            "Epoch 397 : Loss = 0.9586208584633742\n",
            "7.09685462770887e-05\n",
            "Epoch 398 : Loss = 0.9585818214849992\n",
            "4.072367898085665e-05\n",
            "Epoch 399 : Loss = 0.9586277956312352\n",
            "4.7958286256252376e-05\n",
            "Epoch 400 : Loss = 0.9585875665599647\n",
            "4.196702802532252e-05\n",
            "Epoch 401 : Loss = 0.9585753313519738\n",
            "1.2763950407129012e-05\n",
            "Epoch 402 : Loss = 0.958554358644919\n",
            "2.187951769835995e-05\n",
            "Epoch 403 : Loss = 0.9586090933192858\n",
            "5.7098012889968255e-05\n",
            "Epoch 404 : Loss = 0.9585852880369531\n",
            "2.483376558120402e-05\n",
            "Epoch 405 : Loss = 0.9586085352030667\n",
            "2.4250948390154695e-05\n",
            "Epoch 406 : Loss = 0.9585675285621121\n",
            "4.277908413613103e-05\n",
            "Epoch 407 : Loss = 0.9585672481493519\n",
            "2.9253321639710313e-07\n",
            "Epoch 408 : Loss = 0.9585530920462173\n",
            "1.4768199332997213e-05\n",
            "Epoch 409 : Loss = 0.9585908759724011\n",
            "3.941611289120762e-05\n",
            "Epoch 410 : Loss = 0.9585577344352547\n",
            "3.4574377688291196e-05\n",
            "Epoch 411 : Loss = 0.9585658758878708\n",
            "8.493367874724086e-06\n",
            "Epoch 412 : Loss = 0.9585889957167886\n",
            "2.4118604554286266e-05\n",
            "Epoch 413 : Loss = 0.9585724066604266\n",
            "1.7306002391328048e-05\n",
            "Epoch 414 : Loss = 0.9585637897253035\n",
            "8.989422733750738e-06\n",
            "Epoch 415 : Loss = 0.9585535932670939\n",
            "1.063733763169316e-05\n",
            "Epoch 416 : Loss = 0.9585583359003066\n",
            "4.947673015906844e-06\n",
            "Epoch 417 : Loss = 0.9585487598722632\n",
            "9.990131378072174e-06\n",
            "Epoch 418 : Loss = 0.9585786326365036\n",
            "3.1163603301084016e-05\n",
            "Epoch 419 : Loss = 0.9586097909645603\n",
            "3.250366139639341e-05\n",
            "Epoch 420 : Loss = 0.9585677073760466\n",
            "4.390257275509741e-05\n",
            "Epoch 421 : Loss = 0.9585753150961618\n",
            "7.936486570642687e-06\n",
            "Epoch 422 : Loss = 0.9585698653351176\n",
            "5.685303952584722e-06\n",
            "Epoch 423 : Loss = 0.9585750712589787\n",
            "5.430898442069298e-06\n",
            "Epoch 424 : Loss = 0.9585914300246673\n",
            "1.706542034096503e-05\n",
            "Epoch 425 : Loss = 0.9585508338429714\n",
            "4.235162107489267e-05\n",
            "Epoch 426 : Loss = 0.958625851707025\n",
            "7.825562383909498e-05\n",
            "Epoch 427 : Loss = 0.9585984416983344\n",
            "2.8593838147693904e-05\n",
            "Epoch 428 : Loss = 0.9585728211836383\n",
            "2.6727770837991233e-05\n",
            "Epoch 429 : Loss = 0.9585926817222079\n",
            "2.0718433332846393e-05\n",
            "Epoch 430 : Loss = 0.9586248573931782\n",
            "3.356440292790175e-05\n",
            "Epoch 431 : Loss = 0.958545822988857\n",
            "8.245240073622306e-05\n",
            "Epoch 432 : Loss = 0.9585676017132672\n",
            "2.2720071459946853e-05\n",
            "Epoch 433 : Loss = 0.9585515003312718\n",
            "1.67976180620507e-05\n",
            "Epoch 434 : Loss = 0.9585676843469794\n",
            "1.688353986041356e-05\n",
            "Epoch 435 : Loss = 0.9585470719770954\n",
            "2.1503763859418224e-05\n",
            "Epoch 436 : Loss = 0.9586243683641603\n",
            "8.063261233050715e-05\n",
            "Epoch 437 : Loss = 0.9585562375458804\n",
            "7.107649568310526e-05\n",
            "Epoch 438 : Loss = 0.9585445726459677\n",
            "1.2169387053610789e-05\n",
            "Epoch 439 : Loss = 0.9585695402188736\n",
            "2.60466996481349e-05\n",
            "Epoch 440 : Loss = 0.9585555141622372\n",
            "1.4632492776104015e-05\n",
            "Epoch 441 : Loss = 0.9585567387667568\n",
            "1.277550373548007e-06\n",
            "Epoch 442 : Loss = 0.9585765220902184\n",
            "2.063823075740721e-05\n",
            "Epoch 443 : Loss = 0.9585657864809037\n",
            "1.1199658350055362e-05\n",
            "Epoch 444 : Loss = 0.9585535241798921\n",
            "1.2792505272025246e-05\n",
            "Epoch 445 : Loss = 0.9585760100321337\n",
            "2.345755788397243e-05\n",
            "Epoch 446 : Loss = 0.9585769068111072\n",
            "9.35531585575239e-07\n",
            "Epoch 447 : Loss = 0.9585795090957124\n",
            "2.7147300568748552e-06\n",
            "Epoch 448 : Loss = 0.9585692503235557\n",
            "1.0702171129843183e-05\n",
            "Epoch 449 : Loss = 0.9585580893538214\n",
            "1.1643498561288755e-05\n",
            "Epoch 450 : Loss = 0.9585994847796182\n",
            "4.318323393044453e-05\n",
            "Epoch 451 : Loss = 0.9585942327976226\n",
            "5.478837464218462e-06\n",
            "Epoch 452 : Loss = 0.9585706388408486\n",
            "2.4613686063358654e-05\n",
            "Epoch 453 : Loss = 0.9585863406007941\n",
            "1.6380120684416842e-05\n",
            "Epoch 454 : Loss = 0.9586018933491275\n",
            "1.622440811074074e-05\n",
            "Epoch 455 : Loss = 0.95859232544899\n",
            "9.981198350431953e-06\n",
            "Epoch 456 : Loss = 0.9585662186145787\n",
            "2.7235295699258403e-05\n",
            "Epoch 457 : Loss = 0.9585745442997324\n",
            "8.685485342013678e-06\n",
            "Epoch 458 : Loss = 0.9585538669065996\n",
            "2.1571446161453283e-05\n",
            "Epoch 459 : Loss = 0.9585483900525351\n",
            "5.713695960816215e-06\n",
            "Epoch 460 : Loss = 0.9585639035159891\n",
            "1.61840680595852e-05\n",
            "Epoch 461 : Loss = 0.9585373753851113\n",
            "2.7675635357588974e-05\n",
            "Epoch 462 : Loss = 0.958569663492116\n",
            "3.3683631179295505e-05\n",
            "Epoch 463 : Loss = 0.9585486365990202\n",
            "2.193617756361699e-05\n",
            "Epoch 464 : Loss = 0.9585551646622744\n",
            "6.810315665541618e-06\n",
            "Epoch 465 : Loss = 0.9585819285024295\n",
            "2.792024276621811e-05\n",
            "Epoch 466 : Loss = 0.9585569040341809\n",
            "2.6106398215143237e-05\n",
            "Epoch 467 : Loss = 0.9585314867171373\n",
            "2.6516934911228216e-05\n",
            "Epoch 468 : Loss = 0.9585643437775702\n",
            "3.427736556879741e-05\n",
            "Epoch 469 : Loss = 0.9585624093359172\n",
            "2.018065421857453e-06\n",
            "Epoch 470 : Loss = 0.9585751823403621\n",
            "1.3324989714134954e-05\n",
            "Epoch 471 : Loss = 0.958622461015528\n",
            "4.931939015466671e-05\n",
            "Epoch 472 : Loss = 0.9585607702081854\n",
            "6.435774262818095e-05\n",
            "Epoch 473 : Loss = 0.9585711820559066\n",
            "1.0861840952576496e-05\n",
            "Epoch 474 : Loss = 0.9585506333546207\n",
            "2.1437262227941958e-05\n",
            "Epoch 475 : Loss = 0.958556519313292\n",
            "6.1404398726164514e-06\n",
            "Epoch 476 : Loss = 0.958557825196873\n",
            "1.3623419961966852e-06\n",
            "Epoch 477 : Loss = 0.9585718349976973\n",
            "1.4615285274113461e-05\n",
            "Epoch 478 : Loss = 0.9585871655832638\n",
            "1.599289675159297e-05\n",
            "Epoch 479 : Loss = 0.9585865302519366\n",
            "6.627793184695763e-07\n",
            "Epoch 480 : Loss = 0.9585463865236802\n",
            "4.187979718126652e-05\n",
            "Epoch 481 : Loss = 0.9585467224771327\n",
            "3.504820835789841e-07\n",
            "Epoch 482 : Loss = 0.9585550115867093\n",
            "8.64750533503459e-06\n",
            "Epoch 483 : Loss = 0.9585514488545333\n",
            "3.71678763858943e-06\n",
            "Epoch 484 : Loss = 0.9585938711058012\n",
            "4.4254665658356906e-05\n",
            "Epoch 485 : Loss = 0.958551669662649\n",
            "4.40262580388576e-05\n",
            "Epoch 486 : Loss = 0.9585581543770705\n",
            "6.765071468881178e-06\n",
            "Epoch 487 : Loss = 0.9585489292036401\n",
            "9.624102796762821e-06\n",
            "Epoch 488 : Loss = 0.9585921628908677\n",
            "4.510123168251484e-05\n",
            "Epoch 489 : Loss = 0.9585514163429087\n",
            "4.250846356723745e-05\n",
            "Epoch 490 : Loss = 0.9585736854509873\n",
            "2.3231503656485406e-05\n",
            "Epoch 491 : Loss = 0.9586169882254169\n",
            "4.517213335610194e-05\n",
            "Epoch 492 : Loss = 0.9586073173718019\n",
            "1.0088441262301828e-05\n",
            "Epoch 493 : Loss = 0.9585447094657205\n",
            "6.53155825317493e-05\n",
            "Epoch 494 : Loss = 0.958618699149652\n",
            "7.718364350414562e-05\n",
            "Epoch 495 : Loss = 0.9585830406709149\n",
            "3.719915461068664e-05\n",
            "Epoch 496 : Loss = 0.9585659558122805\n",
            "1.7823352196885394e-05\n",
            "Epoch 497 : Loss = 0.9586169665510008\n",
            "5.321284777986007e-05\n",
            "Epoch 498 : Loss = 0.9585438357158139\n",
            "7.629367845476193e-05\n",
            "Epoch 499 : Loss = 0.9585399993441321\n",
            "4.002307347007675e-06\n",
            "Epoch 500 : Loss = 0.9585763500495387\n",
            "3.7921554610282956e-05\n",
            "Epoch 501 : Loss = 0.9585522304881703\n",
            "2.516249047389077e-05\n",
            "Epoch 502 : Loss = 0.9586039971221574\n",
            "5.4002105293221444e-05\n",
            "Epoch 503 : Loss = 0.9585571641271764\n",
            "4.885780080067253e-05\n",
            "Epoch 504 : Loss = 0.9585952758789059\n",
            "3.9757917328119355e-05\n",
            "Epoch 505 : Loss = 0.9585939821871845\n",
            "1.3495721290299856e-06\n",
            "Epoch 506 : Loss = 0.9586815088987349\n",
            "9.1299050558489e-05\n",
            "Epoch 507 : Loss = 0.9585700685327704\n",
            "0.00011625688055869529\n",
            "Epoch 508 : Loss = 0.9585408256812529\n",
            "3.0507674513210857e-05\n",
            "Epoch 509 : Loss = 0.9585604979233308\n",
            "2.05226922249589e-05\n",
            "Epoch 510 : Loss = 0.9585835974324832\n",
            "2.4097542681034475e-05\n",
            "Epoch 511 : Loss = 0.9586049060929908\n",
            "2.2228824797468894e-05\n",
            "Epoch 512 : Loss = 0.9585573280399498\n",
            "4.963506266056701e-05\n",
            "Epoch 513 : Loss = 0.9585466208783062\n",
            "1.1170204359720889e-05\n",
            "Epoch 514 : Loss = 0.9585609029639851\n",
            "1.4899507829625728e-05\n",
            "Epoch 515 : Loss = 0.9585856483741236\n",
            "2.5814500958258787e-05\n",
            "Epoch 516 : Loss = 0.9585526219823145\n",
            "3.4454437922075385e-05\n",
            "Epoch 517 : Loss = 0.958531149409034\n",
            "2.2401539369685655e-05\n",
            "Epoch 518 : Loss = 0.958642450245944\n",
            "0.00011610255406639608\n",
            "Epoch 519 : Loss = 0.9585675773295486\n",
            "7.810916847823536e-05\n",
            "Epoch 520 : Loss = 0.9585562429644845\n",
            "1.182441317059368e-05\n",
            "Epoch 521 : Loss = 0.9585621221499009\n",
            "6.133337924103246e-06\n",
            "Epoch 522 : Loss = 0.9585621573708276\n",
            "3.674349801926215e-08\n",
            "Epoch 523 : Loss = 0.9585902040654961\n",
            "2.925827381663592e-05\n",
            "Epoch 524 : Loss = 0.9585318944670943\n",
            "6.083219425288351e-05\n",
            "Epoch 525 : Loss = 0.9586030597036536\n",
            "7.423848259075726e-05\n",
            "Epoch 526 : Loss = 0.9585469595410608\n",
            "5.8526253757646286e-05\n",
            "Epoch 527 : Loss = 0.9585615288127554\n",
            "1.519909912571298e-05\n",
            "Epoch 528 : Loss = 0.9585282152349298\n",
            "3.47549266636658e-05\n",
            "Epoch 529 : Loss = 0.9585622359405868\n",
            "3.549138948037373e-05\n",
            "Epoch 530 : Loss = 0.9585945037278262\n",
            "3.36615608726428e-05\n",
            "Epoch 531 : Loss = 0.9585408988324081\n",
            "5.5923430584290824e-05\n",
            "Epoch 532 : Loss = 0.9585483710874211\n",
            "7.795386480586984e-06\n",
            "Epoch 533 : Loss = 0.9585517346858979\n",
            "3.509042188484307e-06\n",
            "Epoch 534 : Loss = 0.9585192772475158\n",
            "3.386206115259249e-05\n",
            "Epoch 535 : Loss = 0.9585653258995576\n",
            "4.803913807178992e-05\n",
            "Epoch 536 : Loss = 0.9585837003859604\n",
            "1.9168369330139744e-05\n",
            "Epoch 537 : Loss = 0.9585480175235056\n",
            "3.722595196326312e-05\n",
            "Epoch 538 : Loss = 0.9585530879822642\n",
            "5.289700510288183e-06\n",
            "Epoch 539 : Loss = 0.9585675962946631\n",
            "1.5135408765110041e-05\n",
            "Epoch 540 : Loss = 0.9585864476182243\n",
            "1.9665752220891155e-05\n",
            "Epoch 541 : Loss = 0.9585382694547828\n",
            "5.026211782748764e-05\n",
            "Epoch 542 : Loss = 0.9585646052252162\n",
            "2.7474173665363003e-05\n",
            "Epoch 543 : Loss = 0.9585699872537091\n",
            "5.6146432336071685e-06\n",
            "Epoch 544 : Loss = 0.9585474865003065\n",
            "2.3473801475136144e-05\n",
            "Epoch 545 : Loss = 0.9585784700783816\n",
            "3.2322422255674856e-05\n",
            "Epoch 546 : Loss = 0.9585927169431341\n",
            "1.4862271015285142e-05\n",
            "Epoch 547 : Loss = 0.9585794237526982\n",
            "1.3867594177870191e-05\n",
            "Epoch 548 : Loss = 0.9585523849183863\n",
            "2.820798814681239e-05\n",
            "Epoch 549 : Loss = 0.9585673307830638\n",
            "1.559187779247574e-05\n",
            "Epoch 550 : Loss = 0.9585516588254411\n",
            "1.6349622347789082e-05\n",
            "Epoch 551 : Loss = 0.9586043384942142\n",
            "5.4954548667954246e-05\n",
            "Epoch 552 : Loss = 0.9585581963712521\n",
            "4.813700736882154e-05\n",
            "Epoch 553 : Loss = 0.9585902894085105\n",
            "3.347940993465269e-05\n",
            "Epoch 554 : Loss = 0.9585851119323209\n",
            "5.401164826385991e-06\n",
            "Epoch 555 : Loss = 0.9585737206719137\n",
            "1.1883551740999967e-05\n",
            "Epoch 556 : Loss = 0.9585293436592275\n",
            "4.629697878294901e-05\n",
            "Epoch 557 : Loss = 0.9585699669339439\n",
            "4.237903973391759e-05\n",
            "Epoch 558 : Loss = 0.9585526707497508\n",
            "1.8044062387908887e-05\n",
            "Epoch 559 : Loss = 0.9585564800284125\n",
            "3.973974138293009e-06\n",
            "Epoch 560 : Loss = 0.9585476490584287\n",
            "9.212864892533276e-06\n",
            "Epoch 561 : Loss = 0.9585455209016803\n",
            "2.220193722652083e-06\n",
            "Epoch 562 : Loss = 0.9585587341677058\n",
            "1.3784513722999553e-05\n",
            "Epoch 563 : Loss = 0.958531837571751\n",
            "2.8060200924490054e-05\n",
            "Epoch 564 : Loss = 0.9585977115414358\n",
            "6.87190975856811e-05\n",
            "Epoch 565 : Loss = 0.9585602608594027\n",
            "3.906972108306939e-05\n",
            "Epoch 566 : Loss = 0.9585693316026166\n",
            "9.462793055056341e-06\n",
            "Epoch 567 : Loss = 0.958568441596898\n",
            "9.284738365527879e-07\n",
            "Epoch 568 : Loss = 0.9585900103504007\n",
            "2.2500498930499303e-05\n",
            "Epoch 569 : Loss = 0.9585574919527226\n",
            "3.392430600266324e-05\n",
            "Epoch 570 : Loss = 0.958571900020946\n",
            "1.5030764226646823e-05\n",
            "Epoch 571 : Loss = 0.9585324647751722\n",
            "4.1141272959521e-05\n",
            "Epoch 572 : Loss = 0.9585253894329071\n",
            "7.381486544929873e-06\n",
            "Epoch 573 : Loss = 0.9585466845469041\n",
            "2.2216042619792975e-05\n",
            "Epoch 574 : Loss = 0.9585215693170376\n",
            "2.6202049771685573e-05\n",
            "Epoch 575 : Loss = 0.9585569419644098\n",
            "3.690197819620268e-05\n",
            "Epoch 576 : Loss = 0.9585599519989705\n",
            "3.140163069024576e-06\n",
            "Epoch 577 : Loss = 0.9585424377159638\n",
            "1.827178674363477e-05\n",
            "Epoch 578 : Loss = 0.9585320827635851\n",
            "1.0802927272722388e-05\n",
            "Epoch 579 : Loss = 0.9585753868926654\n",
            "4.517550697879243e-05\n",
            "Epoch 580 : Loss = 0.9585616724057631\n",
            "1.430735997187292e-05\n",
            "Epoch 581 : Loss = 0.9585755846717139\n",
            "1.451347830394231e-05\n",
            "Epoch 582 : Loss = 0.9585947665301234\n",
            "2.001039342096399e-05\n",
            "Epoch 583 : Loss = 0.9585343897342684\n",
            "6.298865904201906e-05\n",
            "Epoch 584 : Loss = 0.9585716331546954\n",
            "3.8853038352931056e-05\n",
            "Epoch 585 : Loss = 0.9585419486869465\n",
            "3.09683554168209e-05\n",
            "Epoch 586 : Loss = 0.9585564326156267\n",
            "1.5110147078847901e-05\n",
            "Epoch 587 : Loss = 0.9585690051317214\n",
            "1.311592178272845e-05\n",
            "Epoch 588 : Loss = 0.958589885722507\n",
            "2.1782611204900662e-05\n",
            "Epoch 589 : Loss = 0.9585219581018793\n",
            "7.086704697114893e-05\n",
            "Epoch 590 : Loss = 0.9585504193197596\n",
            "2.9691936184688834e-05\n",
            "Epoch 591 : Loss = 0.9585480554537339\n",
            "2.466090262508408e-06\n",
            "Epoch 592 : Loss = 0.9585346742109819\n",
            "1.3960102969648904e-05\n",
            "Epoch 593 : Loss = 0.9585383507338442\n",
            "3.8355511383001035e-06\n",
            "Epoch 594 : Loss = 0.9585567184469919\n",
            "1.9161842793642568e-05\n",
            "Epoch 595 : Loss = 0.9585541324181991\n",
            "2.6978432467331458e-06\n",
            "Epoch 596 : Loss = 0.9585266357118434\n",
            "2.868642907903299e-05\n",
            "Epoch 597 : Loss = 0.9585347324609756\n",
            "8.447006517417821e-06\n",
            "Epoch 598 : Loss = 0.9585769826715642\n",
            "4.40759702687793e-05\n",
            "Epoch 599 : Loss = 0.9585625800219449\n",
            "1.5025257525640116e-05\n",
            "Epoch 600 : Loss = 0.9586358977989717\n",
            "7.648135981046722e-05\n",
            "Epoch 601 : Loss = 0.958539206873287\n",
            "0.0001008732089323326\n",
            "Epoch 602 : Loss = 0.9585583399642597\n",
            "1.996027802897394e-05\n",
            "Epoch 603 : Loss = 0.958525844595649\n",
            "3.390140056611183e-05\n",
            "Epoch 604 : Loss = 0.9585457525470039\n",
            "2.0768910927799688e-05\n",
            "Epoch 605 : Loss = 0.9585469189015303\n",
            "1.2167944034932938e-06\n",
            "Epoch 606 : Loss = 0.9585392786697907\n",
            "7.970702828376146e-06\n",
            "Epoch 607 : Loss = 0.9585449194366283\n",
            "5.884718309224009e-06\n",
            "Epoch 608 : Loss = 0.9585901078852739\n",
            "4.714053303265174e-05\n",
            "Epoch 609 : Loss = 0.9585441797971722\n",
            "4.79144196685685e-05\n",
            "Epoch 610 : Loss = 0.9585440131750973\n",
            "1.7382829857058319e-07\n",
            "Epoch 611 : Loss = 0.9585274430838496\n",
            "1.728702852195762e-05\n",
            "Epoch 612 : Loss = 0.9585289359092711\n",
            "1.5574129956594826e-06\n",
            "Epoch 613 : Loss = 0.9585650197484276\n",
            "3.7643601021348757e-05\n",
            "Epoch 614 : Loss = 0.9585761888460681\n",
            "1.1651757857646344e-05\n",
            "Epoch 615 : Loss = 0.9585395631465046\n",
            "3.8209898653846846e-05\n",
            "Epoch 616 : Loss = 0.9585518322207711\n",
            "1.2799593985566315e-05\n",
            "Epoch 617 : Loss = 0.9586155834523115\n",
            "6.65034374996833e-05\n",
            "Epoch 618 : Loss = 0.95855981788852\n",
            "5.8176404592399046e-05\n",
            "Epoch 619 : Loss = 0.9585464325818148\n",
            "1.3964171426818887e-05\n",
            "Epoch 620 : Loss = 0.9585367197340184\n",
            "1.0132995008348659e-05\n",
            "Epoch 621 : Loss = 0.9585306942462921\n",
            "6.286170868072537e-06\n",
            "Epoch 622 : Loss = 0.958547059785236\n",
            "1.7073276451940096e-05\n",
            "Epoch 623 : Loss = 0.9585453393784438\n",
            "1.7948100330496211e-06\n",
            "Epoch 624 : Loss = 0.9585384387861601\n",
            "7.1990772664651445e-06\n",
            "Epoch 625 : Loss = 0.9585388316349551\n",
            "4.0984129394100744e-07\n",
            "Epoch 626 : Loss = 0.9585301578044892\n",
            "9.049095007865705e-06\n",
            "Epoch 627 : Loss = 0.9585553678599271\n",
            "2.6300051393127424e-05\n",
            "Epoch 628 : Loss = 0.9585328928448938\n",
            "2.3447307026229538e-05\n",
            "Epoch 629 : Loss = 0.9585472033782436\n",
            "1.4929398676805347e-05\n",
            "Epoch 630 : Loss = 0.9585544047030538\n",
            "7.512692837050113e-06\n",
            "Epoch 631 : Loss = 0.958527147769928\n",
            "2.8436266191509854e-05\n",
            "Epoch 632 : Loss = 0.9585289846767079\n",
            "1.916381047700684e-06\n",
            "Epoch 633 : Loss = 0.9585580852898684\n",
            "3.0358737365119026e-05\n",
            "Epoch 634 : Loss = 0.9585394195534966\n",
            "1.947310250470968e-05\n",
            "Epoch 635 : Loss = 0.9585289264267143\n",
            "1.0947115410986984e-05\n",
            "Epoch 636 : Loss = 0.9585471695119683\n",
            "1.9032016195183856e-05\n",
            "Epoch 637 : Loss = 0.9585360098968851\n",
            "1.1642353514016025e-05\n",
            "Epoch 638 : Loss = 0.9585262889211826\n",
            "1.0141584862998953e-05\n",
            "Epoch 639 : Loss = 0.9586148952895941\n",
            "9.243166244009949e-05\n",
            "Epoch 640 : Loss = 0.9585635513067244\n",
            "5.3563462536900486e-05\n",
            "Epoch 641 : Loss = 0.9585423306985336\n",
            "2.21384152908621e-05\n",
            "Epoch 642 : Loss = 0.9585459245876833\n",
            "3.7493134731840377e-06\n",
            "Epoch 643 : Loss = 0.9585757323286751\n",
            "3.1095864402287866e-05\n",
            "Epoch 644 : Loss = 0.9585500102151523\n",
            "2.6834399091013086e-05\n",
            "Epoch 645 : Loss = 0.958542906425216\n",
            "7.411029687532903e-06\n",
            "Epoch 646 : Loss = 0.9585596052083104\n",
            "1.7420703943366566e-05\n",
            "Epoch 647 : Loss = 0.9585330608216198\n",
            "2.769271898439558e-05\n",
            "Epoch 648 : Loss = 0.9585673483935266\n",
            "3.5769601337124954e-05\n",
            "Epoch 649 : Loss = 0.9585425095124678\n",
            "2.5913176319637104e-05\n",
            "Epoch 650 : Loss = 0.9585350995714018\n",
            "7.730484850554171e-06\n",
            "Epoch 651 : Loss = 0.958535534414378\n",
            "4.536534750880451e-07\n",
            "Epoch 652 : Loss = 0.9585428129542959\n",
            "7.5933383668640315e-06\n",
            "Epoch 653 : Loss = 0.9585555439645593\n",
            "1.3281452852267382e-05\n",
            "Epoch 654 : Loss = 0.9585681598294865\n",
            "1.3161155832072689e-05\n",
            "Epoch 655 : Loss = 0.9585880190134047\n",
            "2.071712093654619e-05\n",
            "Epoch 656 : Loss = 0.9585905359549954\n",
            "2.6256691426592874e-06\n",
            "Epoch 657 : Loss = 0.9586364708163521\n",
            "4.7916872302495806e-05\n",
            "Epoch 658 : Loss = 0.958574989979917\n",
            "6.413774308505438e-05\n",
            "Epoch 659 : Loss = 0.9585917402397501\n",
            "1.747382032415119e-05\n",
            "Epoch 660 : Loss = 0.9585990878668699\n",
            "7.66496360442641e-06\n",
            "Epoch 661 : Loss = 0.9585397622802041\n",
            "6.189162828743268e-05\n",
            "Epoch 662 : Loss = 0.9585243206132543\n",
            "1.6109833227704316e-05\n",
            "Epoch 663 : Loss = 0.9585765559564935\n",
            "5.449261502859212e-05\n",
            "Epoch 664 : Loss = 0.9585314203392375\n",
            "4.708830226970378e-05\n",
            "Epoch 665 : Loss = 0.9585207172415473\n",
            "1.1166266412109688e-05\n",
            "Epoch 666 : Loss = 0.958583505316214\n",
            "6.55008920124593e-05\n",
            "Epoch 667 : Loss = 0.9585507146336818\n",
            "3.420860475251736e-05\n",
            "Epoch 668 : Loss = 0.9585306400602517\n",
            "2.0943069100906264e-05\n",
            "Epoch 669 : Loss = 0.9585538926449692\n",
            "2.4257983714727455e-05\n",
            "Epoch 670 : Loss = 0.9585390537977216\n",
            "1.5480691359126196e-05\n",
            "Epoch 671 : Loss = 0.9585320610891689\n",
            "7.295226562176473e-06\n",
            "Epoch 672 : Loss = 0.9585290862755342\n",
            "3.103519420790378e-06\n",
            "Epoch 673 : Loss = 0.9585376666350798\n",
            "8.95151003889224e-06\n",
            "Epoch 674 : Loss = 0.9585469879887321\n",
            "9.724461887715286e-06\n",
            "Epoch 675 : Loss = 0.9585172317244789\n",
            "3.104405770528713e-05\n",
            "Epoch 676 : Loss = 0.958585726943883\n",
            "7.145445365901797e-05\n",
            "Epoch 677 : Loss = 0.9585423916578292\n",
            "4.520956655748447e-05\n",
            "Epoch 678 : Loss = 0.9585624093359166\n",
            "2.0883020127324232e-05\n",
            "Epoch 679 : Loss = 0.9585422832857479\n",
            "2.0996517858114684e-05\n",
            "Epoch 680 : Loss = 0.958662302656607\n",
            "0.00012519462852200928\n",
            "Epoch 681 : Loss = 0.9585218659856103\n",
            "0.00014651378959656668\n",
            "Epoch 682 : Loss = 0.9585406482219696\n",
            "1.9594616455917436e-05\n",
            "Epoch 683 : Loss = 0.9585751660845496\n",
            "3.600955230356396e-05\n",
            "Epoch 684 : Loss = 0.9585694372653961\n",
            "5.976425839163602e-06\n",
            "Epoch 685 : Loss = 0.9585445143959739\n",
            "2.600074284285517e-05\n",
            "Epoch 686 : Loss = 0.9585573835806411\n",
            "1.3425575649086578e-05\n",
            "Epoch 687 : Loss = 0.9585330147634852\n",
            "2.5423033719880556e-05\n",
            "Epoch 688 : Loss = 0.9585351415655828\n",
            "2.2188045126687085e-06\n",
            "Epoch 689 : Loss = 0.9585979933088478\n",
            "6.556632050519479e-05\n",
            "Epoch 690 : Loss = 0.9585133858702398\n",
            "8.82694387529356e-05\n",
            "Epoch 691 : Loss = 0.9585145264863967\n",
            "1.1899831722315902e-06\n",
            "Epoch 692 : Loss = 0.9585351984609256\n",
            "2.1566213282643835e-05\n",
            "Epoch 693 : Loss = 0.9585448517040772\n",
            "1.007072661696218e-05\n",
            "Epoch 694 : Loss = 0.9585352851585912\n",
            "9.98037905764033e-06\n",
            "Epoch 695 : Loss = 0.9585379335013303\n",
            "2.7628982083526276e-06\n",
            "Epoch 696 : Loss = 0.9585765112530101\n",
            "4.0244833069596504e-05\n",
            "Epoch 697 : Loss = 0.9585401510650461\n",
            "3.793287941422799e-05\n",
            "Epoch 698 : Loss = 0.9585710560733623\n",
            "3.224070674829225e-05\n",
            "Epoch 699 : Loss = 0.9585299180312592\n",
            "4.2917848811276064e-05\n",
            "Epoch 700 : Loss = 0.958530226891691\n",
            "3.222229441708523e-07\n",
            "Epoch 701 : Loss = 0.9585492109710516\n",
            "1.9805012766529906e-05\n",
            "Epoch 702 : Loss = 0.9586030827327209\n",
            "5.619819364203623e-05\n",
            "Epoch 703 : Loss = 0.9585340686819768\n",
            "7.199958039989816e-05\n",
            "Epoch 704 : Loss = 0.958539838140661\n",
            "6.019007718487141e-06\n",
            "Epoch 705 : Loss = 0.9585437788204714\n",
            "4.111110934551057e-06\n",
            "Epoch 706 : Loss = 0.9585404111580416\n",
            "3.5133233722937103e-06\n",
            "Epoch 707 : Loss = 0.9585339657284995\n",
            "6.724257848485875e-06\n",
            "Epoch 708 : Loss = 0.9585783874446696\n",
            "4.634124527734982e-05\n",
            "Epoch 709 : Loss = 0.9585628482428462\n",
            "1.621093687480721e-05\n",
            "Epoch 710 : Loss = 0.9585930420593782\n",
            "3.149805517798663e-05\n",
            "Epoch 711 : Loss = 0.958524163473736\n",
            "7.185899768303874e-05\n",
            "Epoch 712 : Loss = 0.9585396959023041\n",
            "1.620426220688653e-05\n",
            "Epoch 713 : Loss = 0.9585696296258408\n",
            "3.1227490013783426e-05\n",
            "Epoch 714 : Loss = 0.9585565897551452\n",
            "1.360365244465597e-05\n",
            "Epoch 715 : Loss = 0.9585488045757466\n",
            "8.121839348634093e-06\n",
            "Epoch 716 : Loss = 0.9585408107800917\n",
            "8.33954649094665e-06\n",
            "Epoch 717 : Loss = 0.9585277316245169\n",
            "1.3645046609799808e-05\n",
            "Epoch 718 : Loss = 0.9585399600592529\n",
            "1.2757355191819087e-05\n",
            "Epoch 719 : Loss = 0.9585254896770822\n",
            "1.5096502207367576e-05\n",
            "Epoch 720 : Loss = 0.9585432613437826\n",
            "1.85402865130555e-05\n",
            "Epoch 721 : Loss = 0.9585197364742106\n",
            "2.4542916203849533e-05\n",
            "Epoch 722 : Loss = 0.9585421938787808\n",
            "2.3428707378348774e-05\n",
            "Epoch 723 : Loss = 0.958542852239175\n",
            "6.868345976011957e-07\n",
            "Epoch 724 : Loss = 0.9585353786295112\n",
            "7.796905393815592e-06\n",
            "Epoch 725 : Loss = 0.958598480983214\n",
            "6.582772136050967e-05\n",
            "Epoch 726 : Loss = 0.9585459462620997\n",
            "5.480668017969279e-05\n",
            "Epoch 727 : Loss = 0.9585310098799791\n",
            "1.5582575802580018e-05\n",
            "Epoch 728 : Loss = 0.9585447311401368\n",
            "1.4314679025390998e-05\n",
            "Epoch 729 : Loss = 0.9585320163856854\n",
            "1.3264819780729123e-05\n",
            "Epoch 730 : Loss = 0.9585377316583288\n",
            "5.962491047151376e-06\n",
            "Epoch 731 : Loss = 0.9585311751474033\n",
            "6.840164509523387e-06\n",
            "Epoch 732 : Loss = 0.9585582559758966\n",
            "2.8251625109390437e-05\n",
            "Epoch 733 : Loss = 0.9585317359729245\n",
            "2.766731864665772e-05\n",
            "Epoch 734 : Loss = 0.9585408839312468\n",
            "9.543628733684444e-06\n",
            "Epoch 735 : Loss = 0.9585596824234184\n",
            "1.9611185945189878e-05\n",
            "Epoch 736 : Loss = 0.9585325243798168\n",
            "2.8332939061311465e-05\n",
            "Epoch 737 : Loss = 0.9585233357819646\n",
            "9.586201513565587e-06\n",
            "Epoch 738 : Loss = 0.9585441242564807\n",
            "2.168755093279354e-05\n",
            "Epoch 739 : Loss = 0.9585625461556695\n",
            "1.9218254732203973e-05\n",
            "Epoch 740 : Loss = 0.9585252648050138\n",
            "3.889448929998802e-05\n",
            "Epoch 741 : Loss = 0.9585196714509616\n",
            "5.83540872320329e-06\n",
            "Epoch 742 : Loss = 0.9585845145312222\n",
            "6.764461482279147e-05\n",
            "Epoch 743 : Loss = 0.9585273509675808\n",
            "5.963686230098604e-05\n",
            "Epoch 744 : Loss = 0.9585311141881074\n",
            "3.9260285565481896e-06\n",
            "Epoch 745 : Loss = 0.9585227763110943\n",
            "8.698673854409889e-06\n",
            "Epoch 746 : Loss = 0.9585152783177115\n",
            "7.822507947804543e-06\n",
            "Epoch 747 : Loss = 0.95854276554151\n",
            "2.8676053679137186e-05\n",
            "Epoch 748 : Loss = 0.9585508216511118\n",
            "8.404467890377407e-06\n",
            "Epoch 749 : Loss = 0.9585536244240676\n",
            "2.9239605216738936e-06\n",
            "Epoch 750 : Loss = 0.9585431583903051\n",
            "1.091868808494738e-05\n",
            "Epoch 751 : Loss = 0.958533599972725\n",
            "9.971917082900604e-06\n",
            "Epoch 752 : Loss = 0.9585772617296737\n",
            "4.554850056626058e-05\n",
            "Epoch 753 : Loss = 0.9585336622866717\n",
            "4.548556270628898e-05\n",
            "Epoch 754 : Loss = 0.9585122262889689\n",
            "2.2363822927706067e-05\n",
            "Epoch 755 : Loss = 0.958565189079805\n",
            "5.525215336366565e-05\n",
            "Epoch 756 : Loss = 0.9586122713305731\n",
            "4.911500945293915e-05\n",
            "Epoch 757 : Loss = 0.9585377519780941\n",
            "7.774274130075588e-05\n",
            "Epoch 758 : Loss = 0.9585326747460801\n",
            "5.296879436461645e-06\n",
            "Epoch 759 : Loss = 0.9585532965985212\n",
            "2.1513516790661418e-05\n",
            "Epoch 760 : Loss = 0.9585426233031533\n",
            "1.1134919938226154e-05\n",
            "Epoch 761 : Loss = 0.9585113904692908\n",
            "3.2584728958969405e-05\n",
            "Epoch 762 : Loss = 0.9585207741368902\n",
            "9.789738368314186e-06\n",
            "Epoch 763 : Loss = 0.9585432044484401\n",
            "2.3400417890210215e-05\n",
            "Epoch 764 : Loss = 0.9585347270423715\n",
            "8.844130347506596e-06\n",
            "Epoch 765 : Loss = 0.9585163674571296\n",
            "1.915416978281224e-05\n",
            "Epoch 766 : Loss = 0.9585245888341555\n",
            "8.577116457523022e-06\n",
            "Epoch 767 : Loss = 0.9585111669518731\n",
            "1.4002843936658744e-05\n",
            "Epoch 768 : Loss = 0.9585313485427336\n",
            "2.1054700914228803e-05\n",
            "Epoch 769 : Loss = 0.9585148597305471\n",
            "1.720245859428479e-05\n",
            "Epoch 770 : Loss = 0.958669883283702\n",
            "0.00016170691899060165\n",
            "Epoch 771 : Loss = 0.9585236040028658\n",
            "0.00015260895008242925\n",
            "Epoch 772 : Loss = 0.9585537883368407\n",
            "3.148945248780292e-05\n",
            "Epoch 773 : Loss = 0.9585218971425835\n",
            "3.327122140061876e-05\n",
            "Epoch 774 : Loss = 0.9585369202223691\n",
            "1.5672927634483054e-05\n",
            "Epoch 775 : Loss = 0.9585493464361537\n",
            "1.296356189778971e-05\n",
            "Epoch 776 : Loss = 0.9585470665584913\n",
            "2.3784723170894255e-06\n",
            "Epoch 777 : Loss = 0.9585075283592398\n",
            "4.124975347787905e-05\n",
            "Epoch 778 : Loss = 0.9585279483686795\n",
            "2.130350969363501e-05\n",
            "Epoch 779 : Loss = 0.9585233818400988\n",
            "4.764128520216074e-06\n",
            "Epoch 780 : Loss = 0.9585660289634358\n",
            "4.449054321602795e-05\n",
            "Epoch 781 : Loss = 0.9585379660129546\n",
            "2.927682728929054e-05\n",
            "Epoch 782 : Loss = 0.9585395794023167\n",
            "1.6831744841621823e-06\n",
            "Epoch 783 : Loss = 0.958530607548627\n",
            "9.36000751473044e-06\n",
            "Epoch 784 : Loss = 0.9585232043808156\n",
            "7.723514441280113e-06\n",
            "Epoch 785 : Loss = 0.9585402147336438\n",
            "1.7746102424009262e-05\n",
            "Epoch 786 : Loss = 0.9585279117931018\n",
            "1.2835244952838471e-05\n",
            "Epoch 787 : Loss = 0.9585323577577418\n",
            "4.638304178274017e-06\n",
            "Epoch 788 : Loss = 0.9585456536574798\n",
            "1.3870909212558108e-05\n",
            "Epoch 789 : Loss = 0.9585170705210078\n",
            "2.9820164242343934e-05\n",
            "Epoch 790 : Loss = 0.9585363959724253\n",
            "2.0161416403994746e-05\n",
            "Epoch 791 : Loss = 0.9585063064640221\n",
            "3.139208182596215e-05\n",
            "Epoch 792 : Loss = 0.9585179334337062\n",
            "1.213015351981022e-05\n",
            "Epoch 793 : Loss = 0.9585170921954241\n",
            "8.776455723993543e-07\n",
            "Epoch 794 : Loss = 0.9585561156272886\n",
            "4.071063887472324e-05\n",
            "Epoch 795 : Loss = 0.9585550860925155\n",
            "1.0740486259347327e-06\n",
            "Epoch 796 : Loss = 0.9585232057354667\n",
            "3.3259869826894344e-05\n",
            "Epoch 797 : Loss = 0.9585600901733744\n",
            "3.847900437942666e-05\n",
            "Epoch 798 : Loss = 0.9585771777413106\n",
            "1.782596991974356e-05\n",
            "Epoch 799 : Loss = 0.9585273211652584\n",
            "5.201372454522817e-05\n",
            "Epoch 800 : Loss = 0.958528602665121\n",
            "1.3369448329416112e-06\n",
            "Epoch 801 : Loss = 0.9585302512754095\n",
            "1.7199355850413018e-06\n",
            "Epoch 802 : Loss = 0.9585465694015676\n",
            "1.702382198111328e-05\n",
            "Epoch 803 : Loss = 0.9585317833857102\n",
            "1.5425691785756872e-05\n",
            "Epoch 804 : Loss = 0.9585458378900182\n",
            "1.4662318433266139e-05\n",
            "Epoch 805 : Loss = 0.9585409069603137\n",
            "5.144203725416826e-06\n",
            "Epoch 806 : Loss = 0.9585693776607513\n",
            "2.9701241351078387e-05\n",
            "Epoch 807 : Loss = 0.9585300101475285\n",
            "4.107071537260098e-05\n",
            "Epoch 808 : Loss = 0.9585290957580912\n",
            "9.539506326154316e-07\n",
            "Epoch 809 : Loss = 0.9585607973012058\n",
            "3.307202130929881e-05\n",
            "Epoch 810 : Loss = 0.9585147269747476\n",
            "4.806428650669726e-05\n",
            "Epoch 811 : Loss = 0.95853407274593\n",
            "2.0182664062253927e-05\n",
            "Epoch 812 : Loss = 0.9585291106592525\n",
            "5.176772017011011e-06\n",
            "Epoch 813 : Loss = 0.9585156711665066\n",
            "1.4021150775289725e-05\n",
            "Epoch 814 : Loss = 0.9585192758928646\n",
            "3.7607239088711532e-06\n",
            "Epoch 815 : Loss = 0.9585259963165632\n",
            "7.011206502977148e-06\n",
            "Epoch 816 : Loss = 0.9585516588254407\n",
            "2.677217095312637e-05\n",
            "Epoch 817 : Loss = 0.9585256657817146\n",
            "2.7117733675792518e-05\n",
            "Epoch 818 : Loss = 0.9585341513156892\n",
            "8.852615175935043e-06\n",
            "Epoch 819 : Loss = 0.9585238329388878\n",
            "1.0764862016832517e-05\n",
            "Epoch 820 : Loss = 0.9585545374588531\n",
            "3.203210538937029e-05\n",
            "Epoch 821 : Loss = 0.9585291106592526\n",
            "2.6526893463886626e-05\n",
            "Epoch 822 : Loss = 0.9585104787891562\n",
            "1.9438358274358503e-05\n",
            "Epoch 823 : Loss = 0.9585280784151768\n",
            "1.8361095952200066e-05\n",
            "Epoch 824 : Loss = 0.9585450901226563\n",
            "1.774742539998643e-05\n",
            "Epoch 825 : Loss = 0.9585290402173995\n",
            "1.6744307770990138e-05\n",
            "Epoch 826 : Loss = 0.9585221680727873\n",
            "7.169520790493435e-06\n",
            "Epoch 827 : Loss = 0.9585246403108942\n",
            "2.5792118459227195e-06\n",
            "Epoch 828 : Loss = 0.9585418281230061\n",
            "1.7931207181186976e-05\n",
            "Epoch 829 : Loss = 0.9585172019221568\n",
            "2.5691975897694078e-05\n",
            "Epoch 830 : Loss = 0.9585357728329572\n",
            "1.9374249064788346e-05\n",
            "Epoch 831 : Loss = 0.9585457769307224\n",
            "1.0436744917103489e-05\n",
            "Epoch 832 : Loss = 0.9585087773474781\n",
            "3.860119397833189e-05\n",
            "Epoch 833 : Loss = 0.9585176611488517\n",
            "9.268270928885465e-06\n",
            "Epoch 834 : Loss = 0.9585609964349053\n",
            "4.520868908162984e-05\n",
            "Epoch 835 : Loss = 0.9585052877664566\n",
            "5.8120355891351206e-05\n",
            "Epoch 836 : Loss = 0.9585270583629607\n",
            "2.271255288429911e-05\n",
            "Epoch 837 : Loss = 0.9586346650665455\n",
            "0.00011224996080995478\n",
            "Epoch 838 : Loss = 0.9585314271124926\n",
            "0.00010770429756681788\n",
            "Epoch 839 : Loss = 0.9584946131164378\n",
            "3.8408140798123034e-05\n",
            "Epoch 840 : Loss = 0.958515713160688\n",
            "2.2013248150703972e-05\n",
            "Epoch 841 : Loss = 0.9585445699366657\n",
            "3.0104782691173885e-05\n",
            "Epoch 842 : Loss = 0.95851607485251\n",
            "2.9728332057534153e-05\n",
            "Epoch 843 : Loss = 0.9585523754358293\n",
            "3.787021371968948e-05\n",
            "Epoch 844 : Loss = 0.9585095616904176\n",
            "4.46669987685896e-05\n",
            "Epoch 845 : Loss = 0.9585456319830633\n",
            "3.763023005082919e-05\n",
            "Epoch 846 : Loss = 0.9585014500401235\n",
            "4.609481074640921e-05\n",
            "Epoch 847 : Loss = 0.9585319500077852\n",
            "3.1819458559980645e-05\n",
            "Epoch 848 : Loss = 0.9585010856389996\n",
            "3.220066127004569e-05\n",
            "Epoch 849 : Loss = 0.9585225026715887\n",
            "2.2343797385426733e-05\n",
            "Epoch 850 : Loss = 0.9585438777099956\n",
            "2.2299488739107458e-05\n",
            "Epoch 851 : Loss = 0.9585218375379388\n",
            "2.2993917502569486e-05\n",
            "Epoch 852 : Loss = 0.9585448273203591\n",
            "2.3984045153612294e-05\n",
            "Epoch 853 : Loss = 0.9586251852187243\n",
            "8.382619151291294e-05\n",
            "Epoch 854 : Loss = 0.9584857211871578\n",
            "0.00014550454793814597\n",
            "Epoch 855 : Loss = 0.9585176340558312\n",
            "3.329398181064131e-05\n",
            "Epoch 856 : Loss = 0.9585263254967603\n",
            "9.06750362288878e-06\n",
            "Epoch 857 : Loss = 0.9585288139906796\n",
            "2.5961597428679213e-06\n",
            "Epoch 858 : Loss = 0.9585246172818269\n",
            "4.378300543345549e-06\n",
            "Epoch 859 : Loss = 0.9585363675247538\n",
            "1.225852594119172e-05\n",
            "Epoch 860 : Loss = 0.9585070921616123\n",
            "3.054266721744877e-05\n",
            "Epoch 861 : Loss = 0.9585176936604759\n",
            "1.1060305859430262e-05\n",
            "Epoch 862 : Loss = 0.958572887561538\n",
            "5.757924282891783e-05\n",
            "Epoch 863 : Loss = 0.9584958038546824\n",
            "8.042153814932044e-05\n",
            "Epoch 864 : Loss = 0.9584992108019915\n",
            "3.5544602131789857e-06\n",
            "Epoch 865 : Loss = 0.9585402567278255\n",
            "4.282128533036378e-05\n",
            "Epoch 866 : Loss = 0.9585339101878079\n",
            "6.621090761816279e-06\n",
            "Epoch 867 : Loss = 0.9585227437994696\n",
            "1.1649580993822454e-05\n",
            "Epoch 868 : Loss = 0.9585231285203589\n",
            "4.0136839469071646e-07\n",
            "Epoch 869 : Loss = 0.9585175595500253\n",
            "5.809982590483218e-06\n",
            "Epoch 870 : Loss = 0.9585304734381763\n",
            "1.347259008337507e-05\n",
            "Epoch 871 : Loss = 0.9585454504598271\n",
            "1.5624738131696507e-05\n",
            "Epoch 872 : Loss = 0.9585606455802916\n",
            "1.585201785052612e-05\n",
            "Epoch 873 : Loss = 0.9585126706145027\n",
            "5.005146750761544e-05\n",
            "Epoch 874 : Loss = 0.9585243585434826\n",
            "1.2193669233023733e-05\n",
            "Epoch 875 : Loss = 0.9584993665868583\n",
            "2.6074046051072462e-05\n",
            "Epoch 876 : Loss = 0.9585419419136915\n",
            "4.441675942542568e-05\n",
            "Epoch 877 : Loss = 0.958547519011931\n",
            "5.818280397106286e-06\n",
            "Epoch 878 : Loss = 0.9585029997608879\n",
            "4.6446647589211296e-05\n",
            "Epoch 879 : Loss = 0.9585226408459923\n",
            "2.0490997569960304e-05\n",
            "Epoch 880 : Loss = 0.9585177979686041\n",
            "5.052464751697951e-06\n",
            "Epoch 881 : Loss = 0.9585583616386762\n",
            "4.231737126861833e-05\n",
            "Epoch 882 : Loss = 0.9585227031599393\n",
            "3.7201496239404656e-05\n",
            "Epoch 883 : Loss = 0.9585071260278876\n",
            "1.62514514798073e-05\n",
            "Epoch 884 : Loss = 0.9585408324545082\n",
            "3.5164309624957066e-05\n",
            "Epoch 885 : Loss = 0.958555507388982\n",
            "1.530942586079041e-05\n",
            "Epoch 886 : Loss = 0.9585838223045523\n",
            "2.9538278146863575e-05\n",
            "Epoch 887 : Loss = 0.9585194398056377\n",
            "6.716869396791874e-05\n",
            "Epoch 888 : Loss = 0.95853260836818\n",
            "1.3738252019111507e-05\n",
            "Epoch 889 : Loss = 0.9584975418719377\n",
            "3.658485777001884e-05\n",
            "Epoch 890 : Loss = 0.9584969078952614\n",
            "6.614279827565177e-07\n",
            "Epoch 891 : Loss = 0.9586444795131683\n",
            "0.00015393779556509532\n",
            "Epoch 892 : Loss = 0.9585046930746598\n",
            "0.00014583803242541833\n",
            "Epoch 893 : Loss = 0.9585044858130544\n",
            "2.162343614469556e-07\n",
            "Epoch 894 : Loss = 0.9585171761837875\n",
            "1.3239586152929824e-05\n",
            "Epoch 895 : Loss = 0.9585046957839619\n",
            "1.3020697635070763e-05\n",
            "Epoch 896 : Loss = 0.9585158066316084\n",
            "1.1591720835084454e-05\n",
            "Epoch 897 : Loss = 0.9584974849765951\n",
            "1.9114974530894103e-05\n",
            "Epoch 898 : Loss = 0.9585174362767825\n",
            "2.0814749353846743e-05\n",
            "Epoch 899 : Loss = 0.9585038288073109\n",
            "1.4196572890675782e-05\n",
            "Epoch 900 : Loss = 0.9585686786608263\n",
            "6.76527983430481e-05\n",
            "Epoch 901 : Loss = 0.9585063836791298\n",
            "6.499172332833838e-05\n",
            "Epoch 902 : Loss = 0.9585261101072485\n",
            "2.057995907545302e-05\n",
            "Epoch 903 : Loss = 0.9585290849208832\n",
            "3.103519425176459e-06\n",
            "Epoch 904 : Loss = 0.958578023043546\n",
            "5.105283188888587e-05\n",
            "Epoch 905 : Loss = 0.9585564719005064\n",
            "2.2482914331442355e-05\n",
            "Epoch 906 : Loss = 0.9585187123580413\n",
            "3.9393641436803155e-05\n",
            "Epoch 907 : Loss = 0.9585249857469036\n",
            "6.544836029901124e-06\n",
            "Epoch 908 : Loss = 0.9585013254122301\n",
            "2.4684717742373764e-05\n",
            "Epoch 909 : Loss = 0.9584986134008929\n",
            "2.829436891459487e-06\n",
            "Epoch 910 : Loss = 0.9585051319815894\n",
            "6.800778085527759e-06\n",
            "Epoch 911 : Loss = 0.9585041105747224\n",
            "1.0656259641516358e-06\n",
            "Epoch 912 : Loss = 0.9585355019027535\n",
            "3.2749259645344634e-05\n",
            "Epoch 913 : Loss = 0.9585098068822512\n",
            "2.6807258848913203e-05\n",
            "Epoch 914 : Loss = 0.9585610885511745\n",
            "5.349859235453619e-05\n",
            "Epoch 915 : Loss = 0.9585023644295608\n",
            "6.126653808373483e-05\n",
            "Epoch 916 : Loss = 0.9585350250655954\n",
            "3.407349254905001e-05\n",
            "Epoch 917 : Loss = 0.9584929468956859\n",
            "4.3900343811409664e-05\n",
            "Epoch 918 : Loss = 0.9585261737758464\n",
            "3.4664551756170963e-05\n",
            "Epoch 919 : Loss = 0.958542047576471\n",
            "1.656035920881744e-05\n",
            "Epoch 920 : Loss = 0.958507610992952\n",
            "3.592729272468463e-05\n",
            "Epoch 921 : Loss = 0.9585490741512992\n",
            "4.325616649716093e-05\n",
            "Epoch 922 : Loss = 0.9585118009285493\n",
            "3.8886555923282174e-05\n",
            "Epoch 923 : Loss = 0.9585399668325076\n",
            "2.938417273455084e-05\n",
            "Epoch 924 : Loss = 0.958516214381565\n",
            "2.4780437290761103e-05\n",
            "Epoch 925 : Loss = 0.9585135714574294\n",
            "2.757315299693065e-06\n",
            "Epoch 926 : Loss = 0.958495912226764\n",
            "1.8423897734116286e-05\n",
            "Epoch 927 : Loss = 0.9585432613437828\n",
            "4.939695361519636e-05\n",
            "Epoch 928 : Loss = 0.9584990644996814\n",
            "4.6110471818213165e-05\n",
            "Epoch 929 : Loss = 0.9585016830400988\n",
            "2.7319100881304844e-06\n",
            "Epoch 930 : Loss = 0.9585031961852852\n",
            "1.5786542940123784e-06\n",
            "Epoch 931 : Loss = 0.9585066559639844\n",
            "3.6095510424182875e-06\n",
            "Epoch 932 : Loss = 0.9584981460462915\n",
            "8.878387222833561e-06\n",
            "Epoch 933 : Loss = 0.9585213579914789\n",
            "2.421640894474688e-05\n",
            "Epoch 934 : Loss = 0.9585175934163006\n",
            "3.927497214566566e-06\n",
            "Epoch 935 : Loss = 0.9585037976503371\n",
            "1.4393021704574059e-05\n",
            "Epoch 936 : Loss = 0.9585173875093462\n",
            "1.4177999466900249e-05\n",
            "Epoch 937 : Loss = 0.9585162347013301\n",
            "1.2027005640832543e-06\n",
            "Epoch 938 : Loss = 0.9585080661556938\n",
            "8.52214595229774e-06\n",
            "Epoch 939 : Loss = 0.9585077315568923\n",
            "3.4908304913840915e-07\n",
            "Epoch 940 : Loss = 0.9585320678624241\n",
            "2.5389140695158432e-05\n",
            "Epoch 941 : Loss = 0.9585159258408978\n",
            "1.684063987988594e-05\n",
            "Epoch 942 : Loss = 0.9585113064809277\n",
            "4.8193067091219425e-06\n",
            "Epoch 943 : Loss = 0.9585284197872332\n",
            "1.7853728645096086e-05\n",
            "Epoch 944 : Loss = 0.9584912291981957\n",
            "3.88011782524256e-05\n",
            "Epoch 945 : Loss = 0.958491956645792\n",
            "7.589501312219676e-07\n",
            "Epoch 946 : Loss = 0.9585348435423591\n",
            "4.474213624678458e-05\n",
            "Epoch 947 : Loss = 0.9584946131164379\n",
            "4.197251123859417e-05\n",
            "Epoch 948 : Loss = 0.9585391553965484\n",
            "4.646892081534161e-05\n",
            "Epoch 949 : Loss = 0.9585578644817525\n",
            "1.951795076470088e-05\n",
            "Epoch 950 : Loss = 0.9585601917722009\n",
            "2.4279022520781843e-06\n",
            "Epoch 951 : Loss = 0.9585067155686291\n",
            "5.5791162130818064e-05\n",
            "Epoch 952 : Loss = 0.9584913294423707\n",
            "1.6052441775712317e-05\n",
            "Epoch 953 : Loss = 0.958523711020296\n",
            "3.37827615039596e-05\n",
            "Epoch 954 : Loss = 0.9585272100838746\n",
            "3.650458267485254e-06\n",
            "Epoch 955 : Loss = 0.95851906998591\n",
            "8.492369343054797e-06\n",
            "Epoch 956 : Loss = 0.9585289033976466\n",
            "1.0258857820357259e-05\n",
            "Epoch 957 : Loss = 0.9585356536236675\n",
            "7.042227376107837e-06\n",
            "Epoch 958 : Loss = 0.9585692652247171\n",
            "3.50643425247448e-05\n",
            "Epoch 959 : Loss = 0.9585311101241548\n",
            "3.9805803024299145e-05\n",
            "Epoch 960 : Loss = 0.9584919295527716\n",
            "4.087730963104929e-05\n",
            "Epoch 961 : Loss = 0.9585600237954746\n",
            "7.103805814194995e-05\n",
            "Epoch 962 : Loss = 0.9585451632738116\n",
            "1.5503204473163723e-05\n",
            "Epoch 963 : Loss = 0.9584897675297478\n",
            "5.779482049822656e-05\n",
            "Epoch 964 : Loss = 0.9585162157362157\n",
            "2.7592862837063506e-05\n",
            "Epoch 965 : Loss = 0.9585387869314711\n",
            "2.354750330724789e-05\n",
            "Epoch 966 : Loss = 0.9584992893717508\n",
            "4.1207708924034575e-05\n",
            "Epoch 967 : Loss = 0.9585195034742355\n",
            "2.108887968527877e-05\n",
            "Epoch 968 : Loss = 0.9584956521337683\n",
            "2.4884140490498996e-05\n",
            "Epoch 969 : Loss = 0.9585107592019166\n",
            "1.5760979209991434e-05\n",
            "Epoch 970 : Loss = 0.9585013078017669\n",
            "9.860602247289816e-06\n",
            "Epoch 971 : Loss = 0.9584908241575412\n",
            "1.0937657368758241e-05\n",
            "Epoch 972 : Loss = 0.9584969173778187\n",
            "6.357057771482585e-06\n",
            "Epoch 973 : Loss = 0.9585098935799166\n",
            "1.353789062037933e-05\n",
            "Epoch 974 : Loss = 0.958498864011331\n",
            "1.1507127446561968e-05\n",
            "Epoch 975 : Loss = 0.9585064432837745\n",
            "7.907377667260594e-06\n",
            "Epoch 976 : Loss = 0.958517933433706\n",
            "1.1987412577918355e-05\n",
            "Epoch 977 : Loss = 0.9584982950579035\n",
            "2.0488691428759243e-05\n",
            "Epoch 978 : Loss = 0.958520759235729\n",
            "2.343629765868406e-05\n",
            "Epoch 979 : Loss = 0.9585107727484272\n",
            "1.0418753326200695e-05\n",
            "Epoch 980 : Loss = 0.9586051661859861\n",
            "9.846956900354318e-05\n",
            "Epoch 981 : Loss = 0.9585058838129045\n",
            "0.0001035803480795684\n",
            "Epoch 982 : Loss = 0.9585535919124429\n",
            "4.977092563315543e-05\n",
            "Epoch 983 : Loss = 0.9585096145218068\n",
            "4.5881011488911754e-05\n",
            "Epoch 984 : Loss = 0.9585010219704024\n",
            "8.964571980040523e-06\n",
            "Epoch 985 : Loss = 0.9585518742149527\n",
            "5.305111378756281e-05\n",
            "Epoch 986 : Loss = 0.958514163439924\n",
            "3.9342950231783453e-05\n",
            "Epoch 987 : Loss = 0.9585152620618995\n",
            "1.1461705608531702e-06\n",
            "Epoch 988 : Loss = 0.9584846875884319\n",
            "3.1898760474291394e-05\n",
            "Epoch 989 : Loss = 0.9584870081056248\n",
            "2.421021018888458e-06\n",
            "Epoch 990 : Loss = 0.9584995928135783\n",
            "1.312959134032615e-05\n",
            "Epoch 991 : Loss = 0.9584960355000063\n",
            "3.711349280843803e-06\n",
            "Epoch 992 : Loss = 0.9585175798697906\n",
            "2.247676019382496e-05\n",
            "Epoch 993 : Loss = 0.9585071409290488\n",
            "1.0890832520768877e-05\n",
            "Epoch 994 : Loss = 0.9584929672154515\n",
            "1.4787498794508187e-05\n",
            "Epoch 995 : Loss = 0.9585265124386009\n",
            "3.4996656549450225e-05\n",
            "Epoch 996 : Loss = 0.95853613587943\n",
            "1.0039726692494865e-05\n",
            "Epoch 997 : Loss = 0.95851015096361\n",
            "2.710969288518348e-05\n",
            "Epoch 998 : Loss = 0.9585948356173256\n",
            "8.834248899436968e-05\n",
            "Epoch 999 : Loss = 0.9585256413979962\n",
            "7.218817769805703e-05\n",
            "Epoch 1000 : Loss = 0.958533381873911\n",
            "8.075332650025633e-06\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28vxvQv_3y9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "434659d0-e4f0-4b72-8dc5-7d064be45e73"
      },
      "source": [
        "plt.plot(losses)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Iter Number')\n",
        "plt.title('Convergence monitor plot')\n",
        "plt.show()"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uebx8Dm6iAUX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e7876376-9c51-4071-ddc0-c723db5af072"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    test_loss = 0.0\n",
        "    y_test = []\n",
        "    y_test_pred = []\n",
        "\n",
        "    for data in trainloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        Z = ae1.get_z(X)\n",
        "        y_hat = classifier(Z)      \n",
        "        test_loss += criterion(y_hat, y)*len(X)/test_size\n",
        "        \n",
        "        y_test.extend(list(y.cpu().detach().numpy()))\n",
        "        y_test_pred.extend(list(torch.argmax(y_hat, axis=1).cpu().detach().numpy()))\n",
        "\n",
        "print('Train Loss =', test_loss.item())\n",
        "pd.DataFrame(confusion_matrix(y_test, y_test_pred))"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 3.8338096141815186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>166</td>\n",
              "      <td>20</td>\n",
              "      <td>67</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>259</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62</td>\n",
              "      <td>50</td>\n",
              "      <td>149</td>\n",
              "      <td>12</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>132</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>71</td>\n",
              "      <td>24</td>\n",
              "      <td>32</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4\n",
              "0  166   20   67   11   16\n",
              "1   11  259   27    2   40\n",
              "2   62   50  149   12   27\n",
              "3   16    4    9  132   41\n",
              "4    8   71   24   32  152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2F2G4QbiAUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f7238bad-dbd8-41bc-b2f4-32b6cb3c82c5"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    test_loss = 0.0\n",
        "    y_test = []\n",
        "    y_test_pred = []\n",
        "\n",
        "    for data in testloader:\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        Z = ae1.get_z(X)\n",
        "        y_hat = classifier(Z)      \n",
        "        test_loss += criterion(y_hat, y)\n",
        "        \n",
        "        y_test.extend(list(y.cpu().detach().numpy()))\n",
        "        y_test_pred.extend(list(torch.argmax(y_hat, axis=1).cpu().detach().numpy()))\n",
        "\n",
        "print('Test Loss =', test_loss.item())\n",
        "pd.DataFrame(confusion_matrix(y_test, y_test_pred))"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss = 12.9644136428833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>45</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>26</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>31</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0   1   2   3   4\n",
              "0  37   5  27   4   3\n",
              "1   3  45  10   1  12\n",
              "2  19  16  26   8   5\n",
              "3   6   3   6  31  12\n",
              "4   6  19   4   8  36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjCtqyVJiAUf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49b8c331-de8b-4d6c-f182-1b456abf28db"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "prec = precision_score(y_test, y_test_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "print('Test Accuracy =', acc, 'Test Precision =', prec, 'Test F1 =', f1)"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy = 0.4971590909090909 Test Precision = 0.5028440782696778 Test F1 = 0.49949105090012347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iecwF67CiAUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(classifier.state_dict(), 'a2_q1_wts.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ms1L078iAUm",
        "colab_type": "text"
      },
      "source": [
        "# PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n260pNqViAUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To fit the PCA model we load all the training points in a single batch\n",
        "# train, test = train_test_loader('Data_Set_1(Colored_Images)', label_dict, train_fraction=0.8, batch_size=2000, num_workers=0)\n",
        "train, test = train_test_loader('/content/drive/My Drive/Data_Set_1(Colored_Images)', label_dict, train_fraction=0.8, batch_size=2000, num_workers=0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86fyUeEoyZB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "279e31a8-3bc4-48b7-cc0c-fc935e3db4cc"
      },
      "source": [
        "kk = 0\n",
        "for i in train:\n",
        "    temp = i[0]\n",
        "\n",
        "pca1 = PCA(n_components=temp.shape[1])\n",
        "pca1.fit(temp)\n",
        "\n",
        "print('99% Variance Explained:', np.where(np.cumsum(pca1.explained_variance_ratio_)>=0.99)[0][0]+1)\n",
        "explained_var = np.cumsum(pca1.explained_variance_ratio_)\n",
        "plt.plot(explained_var)\n",
        "plt.title('PCA: Variance Explained')\n",
        "plt.xlabel('No. of components')\n",
        "plt.ylabel('Variance Explained')\n",
        "plt.show()"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99% Variance Explained: 295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xODHGEIziAUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def return_pca(temp):\n",
        "    pca = PCA(n_components=0.99)\n",
        "    pca.fit(temp)\n",
        "    return pca\n",
        "\n",
        "PCA_model = return_pca(temp)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYPOH8V0iAUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduced_dimension = PCA_model.transform(temp).shape[1]\n",
        "pca_clf = FinalNet(reduced_dimension, [150, 75, 50], 5)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia5lUuzsiAUz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "058c14bd-817f-478c-b072-36381d665d7f"
      },
      "source": [
        "reduced_dimension"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "295"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s9qE34QiAU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(pca_clf.parameters(), lr=0.001, momentum=0.9)\n",
        "pca_clf = pca_clf.to(device)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxWdHntPiAU5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd942370-b713-4f2b-a562-90c5fd96ca83"
      },
      "source": [
        "old_loss = np.inf\n",
        "\n",
        "max_epoch = 500\n",
        "losses= []\n",
        "for epoch in range(max_epoch):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for data in trainloader:\n",
        "        \n",
        "        X, y = data[0], data[1].to(device)\n",
        "        \n",
        "        # applying PCA on the data to use as input to the MLFFNN\n",
        "        Z = torch.Tensor(PCA_model.transform(X)).to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward\n",
        "        y_hat = pca_clf(Z)\n",
        "        \n",
        "        # Calculate Loss (Cross Entropy)\n",
        "        loss = criterion(y_hat, y)\n",
        "        \n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update Parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    print('Epoch', epoch+1, ': Loss =', running_loss)\n",
        "    losses.append(running_loss)\n",
        "\n",
        "    if abs(running_loss-old_loss)/running_loss < 0.005 and running_loss<0.15:\n",
        "        print('Converged')\n",
        "        break\n",
        "    \n",
        "    old_loss = running_loss\n",
        "\n",
        "print('Finished Training')\n",
        "plt.plot(losses)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Iter Number')\n",
        "plt.title('Convergence monitor plot')\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 : Loss = 70.1593987941742\n",
            "Epoch 2 : Loss = 68.89605939388275\n",
            "Epoch 3 : Loss = 67.52734839916229\n",
            "Epoch 4 : Loss = 66.02605032920837\n",
            "Epoch 5 : Loss = 64.3612322807312\n",
            "Epoch 6 : Loss = 62.58863294124603\n",
            "Epoch 7 : Loss = 60.877670645713806\n",
            "Epoch 8 : Loss = 59.21260070800781\n",
            "Epoch 9 : Loss = 57.61559176445007\n",
            "Epoch 10 : Loss = 56.05080699920654\n",
            "Epoch 11 : Loss = 54.48280048370361\n",
            "Epoch 12 : Loss = 52.88495051860809\n",
            "Epoch 13 : Loss = 51.34216821193695\n",
            "Epoch 14 : Loss = 49.79651081562042\n",
            "Epoch 15 : Loss = 48.3210534453392\n",
            "Epoch 16 : Loss = 46.9161514043808\n",
            "Epoch 17 : Loss = 45.543405055999756\n",
            "Epoch 18 : Loss = 44.24747294187546\n",
            "Epoch 19 : Loss = 43.02239269018173\n",
            "Epoch 20 : Loss = 41.84241473674774\n",
            "Epoch 21 : Loss = 40.72730928659439\n",
            "Epoch 22 : Loss = 39.66628223657608\n",
            "Epoch 23 : Loss = 38.67802172899246\n",
            "Epoch 24 : Loss = 37.74628925323486\n",
            "Epoch 25 : Loss = 36.84521508216858\n",
            "Epoch 26 : Loss = 35.969343304634094\n",
            "Epoch 27 : Loss = 35.15179789066315\n",
            "Epoch 28 : Loss = 34.381955742836\n",
            "Epoch 29 : Loss = 33.603051483631134\n",
            "Epoch 30 : Loss = 32.870383113622665\n",
            "Epoch 31 : Loss = 32.22346544265747\n",
            "Epoch 32 : Loss = 31.525940150022507\n",
            "Epoch 33 : Loss = 30.883231669664383\n",
            "Epoch 34 : Loss = 30.177049040794373\n",
            "Epoch 35 : Loss = 29.51508292555809\n",
            "Epoch 36 : Loss = 28.93950966000557\n",
            "Epoch 37 : Loss = 28.339597940444946\n",
            "Epoch 38 : Loss = 27.73714902997017\n",
            "Epoch 39 : Loss = 27.210531502962112\n",
            "Epoch 40 : Loss = 26.63558965921402\n",
            "Epoch 41 : Loss = 26.087302416563034\n",
            "Epoch 42 : Loss = 25.613511383533478\n",
            "Epoch 43 : Loss = 24.998822182416916\n",
            "Epoch 44 : Loss = 24.459659546613693\n",
            "Epoch 45 : Loss = 24.03692427277565\n",
            "Epoch 46 : Loss = 23.51323515176773\n",
            "Epoch 47 : Loss = 22.981209307909012\n",
            "Epoch 48 : Loss = 22.494244426488876\n",
            "Epoch 49 : Loss = 22.06002587080002\n",
            "Epoch 50 : Loss = 21.47031420469284\n",
            "Epoch 51 : Loss = 20.96610176563263\n",
            "Epoch 52 : Loss = 20.63616168498993\n",
            "Epoch 53 : Loss = 20.07355770468712\n",
            "Epoch 54 : Loss = 19.612921476364136\n",
            "Epoch 55 : Loss = 19.13147908449173\n",
            "Epoch 56 : Loss = 18.659533768892288\n",
            "Epoch 57 : Loss = 18.294069156050682\n",
            "Epoch 58 : Loss = 17.83596906065941\n",
            "Epoch 59 : Loss = 17.388802632689476\n",
            "Epoch 60 : Loss = 17.073817431926727\n",
            "Epoch 61 : Loss = 16.54868473112583\n",
            "Epoch 62 : Loss = 16.220277041196823\n",
            "Epoch 63 : Loss = 15.768481567502022\n",
            "Epoch 64 : Loss = 15.304168358445168\n",
            "Epoch 65 : Loss = 14.940342962741852\n",
            "Epoch 66 : Loss = 14.58814188838005\n",
            "Epoch 67 : Loss = 14.197312578558922\n",
            "Epoch 68 : Loss = 13.7986508756876\n",
            "Epoch 69 : Loss = 13.43250484764576\n",
            "Epoch 70 : Loss = 13.082145929336548\n",
            "Epoch 71 : Loss = 12.785294279456139\n",
            "Epoch 72 : Loss = 12.30353732407093\n",
            "Epoch 73 : Loss = 12.000499218702316\n",
            "Epoch 74 : Loss = 11.689105808734894\n",
            "Epoch 75 : Loss = 11.244934998452663\n",
            "Epoch 76 : Loss = 10.954008027911186\n",
            "Epoch 77 : Loss = 10.570664420723915\n",
            "Epoch 78 : Loss = 10.257592767477036\n",
            "Epoch 79 : Loss = 10.034419775009155\n",
            "Epoch 80 : Loss = 9.682648129761219\n",
            "Epoch 81 : Loss = 9.384145848453045\n",
            "Epoch 82 : Loss = 9.027706384658813\n",
            "Epoch 83 : Loss = 8.74539928138256\n",
            "Epoch 84 : Loss = 8.387498669326305\n",
            "Epoch 85 : Loss = 8.221878290176392\n",
            "Epoch 86 : Loss = 7.875747121870518\n",
            "Epoch 87 : Loss = 7.672601588070393\n",
            "Epoch 88 : Loss = 7.366520628333092\n",
            "Epoch 89 : Loss = 7.147988624870777\n",
            "Epoch 90 : Loss = 6.913659930229187\n",
            "Epoch 91 : Loss = 6.569244302809238\n",
            "Epoch 92 : Loss = 6.40404162555933\n",
            "Epoch 93 : Loss = 6.2352540120482445\n",
            "Epoch 94 : Loss = 5.928652241826057\n",
            "Epoch 95 : Loss = 5.728920146822929\n",
            "Epoch 96 : Loss = 5.5207604393363\n",
            "Epoch 97 : Loss = 5.332936774939299\n",
            "Epoch 98 : Loss = 5.102517060935497\n",
            "Epoch 99 : Loss = 4.9564167857170105\n",
            "Epoch 100 : Loss = 4.730122070759535\n",
            "Epoch 101 : Loss = 4.558101311326027\n",
            "Epoch 102 : Loss = 4.391380451619625\n",
            "Epoch 103 : Loss = 4.257790375500917\n",
            "Epoch 104 : Loss = 4.107139937579632\n",
            "Epoch 105 : Loss = 3.947589546442032\n",
            "Epoch 106 : Loss = 3.815996788442135\n",
            "Epoch 107 : Loss = 3.6760186068713665\n",
            "Epoch 108 : Loss = 3.5118250250816345\n",
            "Epoch 109 : Loss = 3.3625694438815117\n",
            "Epoch 110 : Loss = 3.241869766265154\n",
            "Epoch 111 : Loss = 3.1515081599354744\n",
            "Epoch 112 : Loss = 3.006982669234276\n",
            "Epoch 113 : Loss = 2.906063435599208\n",
            "Epoch 114 : Loss = 2.8064437955617905\n",
            "Epoch 115 : Loss = 2.6954619623720646\n",
            "Epoch 116 : Loss = 2.609125543385744\n",
            "Epoch 117 : Loss = 2.5399307385087013\n",
            "Epoch 118 : Loss = 2.443832715973258\n",
            "Epoch 119 : Loss = 2.3632903899997473\n",
            "Epoch 120 : Loss = 2.272504633292556\n",
            "Epoch 121 : Loss = 2.2126311901956797\n",
            "Epoch 122 : Loss = 2.138819742947817\n",
            "Epoch 123 : Loss = 2.0729980673640966\n",
            "Epoch 124 : Loss = 2.000581230968237\n",
            "Epoch 125 : Loss = 1.9417316410690546\n",
            "Epoch 126 : Loss = 1.8829605486243963\n",
            "Epoch 127 : Loss = 1.8251182101666927\n",
            "Epoch 128 : Loss = 1.7696073055267334\n",
            "Epoch 129 : Loss = 1.720627499744296\n",
            "Epoch 130 : Loss = 1.6632114723324776\n",
            "Epoch 131 : Loss = 1.6266050171107054\n",
            "Epoch 132 : Loss = 1.5831461641937494\n",
            "Epoch 133 : Loss = 1.5388417541980743\n",
            "Epoch 134 : Loss = 1.50109888240695\n",
            "Epoch 135 : Loss = 1.4528286717832088\n",
            "Epoch 136 : Loss = 1.4218161087483168\n",
            "Epoch 137 : Loss = 1.3894134648144245\n",
            "Epoch 138 : Loss = 1.3505998570472002\n",
            "Epoch 139 : Loss = 1.3156740870326757\n",
            "Epoch 140 : Loss = 1.2820897195488214\n",
            "Epoch 141 : Loss = 1.2504940032958984\n",
            "Epoch 142 : Loss = 1.2232428509742022\n",
            "Epoch 143 : Loss = 1.1936113461852074\n",
            "Epoch 144 : Loss = 1.1681719170883298\n",
            "Epoch 145 : Loss = 1.1408692607656121\n",
            "Epoch 146 : Loss = 1.1126091042533517\n",
            "Epoch 147 : Loss = 1.0889975288882852\n",
            "Epoch 148 : Loss = 1.0647989055141807\n",
            "Epoch 149 : Loss = 1.0414033401757479\n",
            "Epoch 150 : Loss = 1.0169367333874106\n",
            "Epoch 151 : Loss = 0.9994962373748422\n",
            "Epoch 152 : Loss = 0.9765959130600095\n",
            "Epoch 153 : Loss = 0.9559043701738119\n",
            "Epoch 154 : Loss = 0.9357629613950849\n",
            "Epoch 155 : Loss = 0.9171365909278393\n",
            "Epoch 156 : Loss = 0.8981817709282041\n",
            "Epoch 157 : Loss = 0.8815716598182917\n",
            "Epoch 158 : Loss = 0.8661870332434773\n",
            "Epoch 159 : Loss = 0.8506828704848886\n",
            "Epoch 160 : Loss = 0.8330523753538728\n",
            "Epoch 161 : Loss = 0.8180497102439404\n",
            "Epoch 162 : Loss = 0.7993810651823878\n",
            "Epoch 163 : Loss = 0.7856863038614392\n",
            "Epoch 164 : Loss = 0.7718360312283039\n",
            "Epoch 165 : Loss = 0.7597775068134069\n",
            "Epoch 166 : Loss = 0.7455840380862355\n",
            "Epoch 167 : Loss = 0.7351146209985018\n",
            "Epoch 168 : Loss = 0.7204064885154366\n",
            "Epoch 169 : Loss = 0.7089233445003629\n",
            "Epoch 170 : Loss = 0.696011914871633\n",
            "Epoch 171 : Loss = 0.686968732625246\n",
            "Epoch 172 : Loss = 0.6734921159222722\n",
            "Epoch 173 : Loss = 0.6628031739965081\n",
            "Epoch 174 : Loss = 0.6540427207946777\n",
            "Epoch 175 : Loss = 0.642105461563915\n",
            "Epoch 176 : Loss = 0.632687215693295\n",
            "Epoch 177 : Loss = 0.6238810736685991\n",
            "Epoch 178 : Loss = 0.6122795157134533\n",
            "Epoch 179 : Loss = 0.6035546697676182\n",
            "Epoch 180 : Loss = 0.5966380136087537\n",
            "Epoch 181 : Loss = 0.5867225145921111\n",
            "Epoch 182 : Loss = 0.5768306069076061\n",
            "Epoch 183 : Loss = 0.5690628355368972\n",
            "Epoch 184 : Loss = 0.5605349405668676\n",
            "Epoch 185 : Loss = 0.5523928152397275\n",
            "Epoch 186 : Loss = 0.5451809912919998\n",
            "Epoch 187 : Loss = 0.5374749689362943\n",
            "Epoch 188 : Loss = 0.5298681948333979\n",
            "Epoch 189 : Loss = 0.5233267396688461\n",
            "Epoch 190 : Loss = 0.5161921544931829\n",
            "Epoch 191 : Loss = 0.5087607516907156\n",
            "Epoch 192 : Loss = 0.5023852246813476\n",
            "Epoch 193 : Loss = 0.4964553350582719\n",
            "Epoch 194 : Loss = 0.4890729612670839\n",
            "Epoch 195 : Loss = 0.48344142781570554\n",
            "Epoch 196 : Loss = 0.47721482068300247\n",
            "Epoch 197 : Loss = 0.47166529949754477\n",
            "Epoch 198 : Loss = 0.46517902379855514\n",
            "Epoch 199 : Loss = 0.4601849028840661\n",
            "Epoch 200 : Loss = 0.45403388794511557\n",
            "Epoch 201 : Loss = 0.4484172905795276\n",
            "Epoch 202 : Loss = 0.4434471083804965\n",
            "Epoch 203 : Loss = 0.43717969488352537\n",
            "Epoch 204 : Loss = 0.4315308937802911\n",
            "Epoch 205 : Loss = 0.42654666025191545\n",
            "Epoch 206 : Loss = 0.42200017580762506\n",
            "Epoch 207 : Loss = 0.41751083731651306\n",
            "Epoch 208 : Loss = 0.41238730819895864\n",
            "Epoch 209 : Loss = 0.4078114805743098\n",
            "Epoch 210 : Loss = 0.40307819889858365\n",
            "Epoch 211 : Loss = 0.39868392422795296\n",
            "Epoch 212 : Loss = 0.3940307735465467\n",
            "Epoch 213 : Loss = 0.3899070927873254\n",
            "Epoch 214 : Loss = 0.3859425629489124\n",
            "Epoch 215 : Loss = 0.3807813711464405\n",
            "Epoch 216 : Loss = 0.37683248799294233\n",
            "Epoch 217 : Loss = 0.3738528802059591\n",
            "Epoch 218 : Loss = 0.36954565439373255\n",
            "Epoch 219 : Loss = 0.3653967040590942\n",
            "Epoch 220 : Loss = 0.36193379713222384\n",
            "Epoch 221 : Loss = 0.3582453355193138\n",
            "Epoch 222 : Loss = 0.35415045684203506\n",
            "Epoch 223 : Loss = 0.35068089654669166\n",
            "Epoch 224 : Loss = 0.3471374227665365\n",
            "Epoch 225 : Loss = 0.3439508560113609\n",
            "Epoch 226 : Loss = 0.3402237850241363\n",
            "Epoch 227 : Loss = 0.3368875738233328\n",
            "Epoch 228 : Loss = 0.33347503282129765\n",
            "Epoch 229 : Loss = 0.33019796246662736\n",
            "Epoch 230 : Loss = 0.326996250776574\n",
            "Epoch 231 : Loss = 0.32379357842728496\n",
            "Epoch 232 : Loss = 0.3207167936488986\n",
            "Epoch 233 : Loss = 0.3180657015182078\n",
            "Epoch 234 : Loss = 0.31463021924719214\n",
            "Epoch 235 : Loss = 0.31217047525569797\n",
            "Epoch 236 : Loss = 0.3088563992641866\n",
            "Epoch 237 : Loss = 0.3060835488140583\n",
            "Epoch 238 : Loss = 0.30336101399734616\n",
            "Epoch 239 : Loss = 0.300550295971334\n",
            "Epoch 240 : Loss = 0.2977728256955743\n",
            "Epoch 241 : Loss = 0.29525576205924153\n",
            "Epoch 242 : Loss = 0.29283939697779715\n",
            "Epoch 243 : Loss = 0.29023111797869205\n",
            "Epoch 244 : Loss = 0.28742884332314134\n",
            "Epoch 245 : Loss = 0.28480121213942766\n",
            "Epoch 246 : Loss = 0.2827353314496577\n",
            "Epoch 247 : Loss = 0.28008564142510295\n",
            "Epoch 248 : Loss = 0.2776202578097582\n",
            "Epoch 249 : Loss = 0.27549067651852965\n",
            "Epoch 250 : Loss = 0.2729386421851814\n",
            "Epoch 251 : Loss = 0.2706268164329231\n",
            "Epoch 252 : Loss = 0.2687890427187085\n",
            "Epoch 253 : Loss = 0.266075098188594\n",
            "Epoch 254 : Loss = 0.2640268849208951\n",
            "Epoch 255 : Loss = 0.2617877540178597\n",
            "Epoch 256 : Loss = 0.259875773685053\n",
            "Epoch 257 : Loss = 0.25778996339067817\n",
            "Epoch 258 : Loss = 0.2555680654477328\n",
            "Epoch 259 : Loss = 0.2538701379671693\n",
            "Epoch 260 : Loss = 0.25193487713113427\n",
            "Epoch 261 : Loss = 0.24961252859793603\n",
            "Epoch 262 : Loss = 0.24787954217754304\n",
            "Epoch 263 : Loss = 0.24593015876598656\n",
            "Epoch 264 : Loss = 0.24402122478932142\n",
            "Epoch 265 : Loss = 0.24206645251251757\n",
            "Epoch 266 : Loss = 0.24016863526776433\n",
            "Epoch 267 : Loss = 0.2384860736783594\n",
            "Epoch 268 : Loss = 0.236470399890095\n",
            "Epoch 269 : Loss = 0.23474090150557458\n",
            "Epoch 270 : Loss = 0.2329910360276699\n",
            "Epoch 271 : Loss = 0.2312056904193014\n",
            "Epoch 272 : Loss = 0.2295554883312434\n",
            "Epoch 273 : Loss = 0.22789373388513923\n",
            "Epoch 274 : Loss = 0.22630419745109975\n",
            "Epoch 275 : Loss = 0.22454338613897562\n",
            "Epoch 276 : Loss = 0.22281997743993998\n",
            "Epoch 277 : Loss = 0.2216856984887272\n",
            "Epoch 278 : Loss = 0.2199585036141798\n",
            "Epoch 279 : Loss = 0.2182809670921415\n",
            "Epoch 280 : Loss = 0.21675384556874633\n",
            "Epoch 281 : Loss = 0.21504162880592048\n",
            "Epoch 282 : Loss = 0.2137196238618344\n",
            "Epoch 283 : Loss = 0.21233446639962494\n",
            "Epoch 284 : Loss = 0.21077952696941793\n",
            "Epoch 285 : Loss = 0.2093400617595762\n",
            "Epoch 286 : Loss = 0.2079642810858786\n",
            "Epoch 287 : Loss = 0.20650932472199202\n",
            "Epoch 288 : Loss = 0.20497882273048162\n",
            "Epoch 289 : Loss = 0.2037386754527688\n",
            "Epoch 290 : Loss = 0.20239760307595134\n",
            "Epoch 291 : Loss = 0.20092819491401315\n",
            "Epoch 292 : Loss = 0.19973354483954608\n",
            "Epoch 293 : Loss = 0.19838046678341925\n",
            "Epoch 294 : Loss = 0.19700857298448682\n",
            "Epoch 295 : Loss = 0.19575538858771324\n",
            "Epoch 296 : Loss = 0.19465754786506295\n",
            "Epoch 297 : Loss = 0.19328173878602684\n",
            "Epoch 298 : Loss = 0.19201773521490395\n",
            "Epoch 299 : Loss = 0.19089853554032743\n",
            "Epoch 300 : Loss = 0.18961792206391692\n",
            "Epoch 301 : Loss = 0.18833246198482811\n",
            "Epoch 302 : Loss = 0.18714777380228043\n",
            "Epoch 303 : Loss = 0.1860218837391585\n",
            "Epoch 304 : Loss = 0.1851242077536881\n",
            "Epoch 305 : Loss = 0.1838972985278815\n",
            "Epoch 306 : Loss = 0.18258229899220169\n",
            "Epoch 307 : Loss = 0.1815462438389659\n",
            "Epoch 308 : Loss = 0.18049804493784904\n",
            "Epoch 309 : Loss = 0.179263575701043\n",
            "Epoch 310 : Loss = 0.17815118236467242\n",
            "Epoch 311 : Loss = 0.1772658044937998\n",
            "Epoch 312 : Loss = 0.17607071972452104\n",
            "Epoch 313 : Loss = 0.17494924878701568\n",
            "Epoch 314 : Loss = 0.17391729122027755\n",
            "Epoch 315 : Loss = 0.17301414906978607\n",
            "Epoch 316 : Loss = 0.1720562109258026\n",
            "Epoch 317 : Loss = 0.17090572882443666\n",
            "Epoch 318 : Loss = 0.17002443480305374\n",
            "Epoch 319 : Loss = 0.1690153561066836\n",
            "Epoch 320 : Loss = 0.16817488986998796\n",
            "Epoch 321 : Loss = 0.16695750784128904\n",
            "Epoch 322 : Loss = 0.1661946044769138\n",
            "Epoch 323 : Loss = 0.16503139049746096\n",
            "Epoch 324 : Loss = 0.1643105128314346\n",
            "Epoch 325 : Loss = 0.16323169320821762\n",
            "Epoch 326 : Loss = 0.1623480694834143\n",
            "Epoch 327 : Loss = 0.1614805122371763\n",
            "Epoch 328 : Loss = 0.1605834614019841\n",
            "Epoch 329 : Loss = 0.1597001333720982\n",
            "Epoch 330 : Loss = 0.1588148318696767\n",
            "Epoch 331 : Loss = 0.15797506808303297\n",
            "Epoch 332 : Loss = 0.1571199633181095\n",
            "Epoch 333 : Loss = 0.15622736141085625\n",
            "Epoch 334 : Loss = 0.15529741323553026\n",
            "Epoch 335 : Loss = 0.1544777494855225\n",
            "Epoch 336 : Loss = 0.1536305919289589\n",
            "Epoch 337 : Loss = 0.15291586983948946\n",
            "Epoch 338 : Loss = 0.1520488744135946\n",
            "Epoch 339 : Loss = 0.15131219290196896\n",
            "Epoch 340 : Loss = 0.15046426793560386\n",
            "Epoch 341 : Loss = 0.14972602378111333\n",
            "Converged\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoXwDQ8biAU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "72896836-5fbf-4296-cfc6-5254a1d18295"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    test_loss = 0.0\n",
        "    y_test = []\n",
        "    y_test_pred = []\n",
        "\n",
        "    for data in trainloader:\n",
        "\n",
        "        X, y = data[0], data[1].to(device)\n",
        "        Z = torch.Tensor(PCA_model.transform(X)).to(device)\n",
        "        y_hat = pca_clf(Z)      \n",
        "        test_loss += criterion(y_hat, y)\n",
        "        \n",
        "        y_test.extend(list(y.cpu().detach().numpy()))\n",
        "        y_test_pred.extend(list(torch.argmax(y_hat, axis=1).cpu().detach().numpy()))\n",
        "\n",
        "print('Train Loss =', test_loss.item())\n",
        "pd.DataFrame(confusion_matrix(y_test, y_test_pred))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Loss = 0.1481517255306244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>283</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>326</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>300</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>198</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4\n",
              "0  283    0    0    0    0\n",
              "1    0  326    0    0    0\n",
              "2    0    0  300    0    0\n",
              "3    0    0    0  198    0\n",
              "4    0    0    0    0  301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV0KYYroiAVB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "820b73ea-eb7b-4c61-c165-356c8b80cd02"
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    test_loss = 0.0\n",
        "    y_test = []\n",
        "    y_test_pred = []\n",
        "\n",
        "    for data in testloader:\n",
        "\n",
        "        X, y = data[0], data[1].to(device)\n",
        "        Z = torch.Tensor(PCA_model.transform(X)).to(device)\n",
        "        y_hat = pca_clf(Z)      \n",
        "        test_loss += criterion(y_hat, y)\n",
        "        \n",
        "        y_test.extend(list(y.cpu().detach().numpy()))\n",
        "        y_test_pred.extend(list(torch.argmax(y_hat, axis=1).cpu().detach().numpy()))\n",
        "\n",
        "print('Test Loss =', test_loss.item())\n",
        "pd.DataFrame(confusion_matrix(y_test, y_test_pred))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-2855acd32378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPCA_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2648\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (32) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lku7GRBriAVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfa41e11-57cb-4e68-c849-3534395566be"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "prec = precision_score(y_test, y_test_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "print('Test Accuracy =', acc, 'Test Precision =', prec, 'Test F1 =', f1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy = 0.6079545454545454 Test Precision = 0.6152641469080431 Test F1 = 0.6019215164445282\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}