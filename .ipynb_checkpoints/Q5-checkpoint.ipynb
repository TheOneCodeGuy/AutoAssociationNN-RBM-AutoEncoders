{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rN9XtcSDLQJs"
   },
   "source": [
    "## Group 3:\n",
    "Classes: 3, 1, 4, 6, 8\n",
    "    \n",
    "    Open Country - 3\n",
    "    Tall Building - 1\n",
    "    Mountain - 4\n",
    "    Highway - 6\n",
    "    Coast - 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kC9BSjni-wIc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ZLxugJ7LQJt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from io import StringIO\n",
    "import pdb\n",
    "from math import sqrt, log\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lmaPR3JkLQJx",
    "outputId": "a351baec-92a3-4d0f-e7cc-24ebda828ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4t_ogzkSLQJ1"
   },
   "outputs": [],
   "source": [
    "class DatasetClass(Dataset):\n",
    "    \n",
    "    def __init__(self, folder, filename, label_dict):\n",
    "        \n",
    "        self.data = []\n",
    "        self.filename = filename\n",
    "        tar = tarfile.open(folder + '/' + filename)\n",
    "        for file in tar.getmembers():\n",
    "            f = tar.extractfile(file)\n",
    "            if f != None:\n",
    "                content = pd.read_csv(StringIO(f.read().decode()), sep=' ', header=None).values.ravel()\n",
    "                self.data.append(content)\n",
    "            \n",
    "        self.y = torch.tensor(label_dict[self.filename[:-7]], dtype=torch.long)\n",
    "    \n",
    "    def __getitem__(self, idx):     \n",
    "        \n",
    "        return torch.tensor(self.data[idx], dtype=torch.float), self.y\n",
    "      \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5kQMX5vLQJ4"
   },
   "outputs": [],
   "source": [
    "def train_test_loader(directory, label_dict, train_fraction=0.8, num_workers=2, bs_fraction = 0.2):\n",
    "\n",
    "    all_files = list(filter(lambda x: x.endswith('.tar.gz'), os.listdir(directory)))\n",
    "    files = [file for file in all_files if file[:-7] in label_dict.keys()]\n",
    "    \n",
    "    datasets = list(map(lambda x : DatasetClass(directory, x, label_dict), files))\n",
    "    dataset = ConcatDataset(datasets)\n",
    "    N = dataset.cumulative_sizes[-1]\n",
    "    \n",
    "    train_size = int(N*train_fraction)\n",
    "    test_size = N - train_size\n",
    "\n",
    "    train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    trainloader = DataLoader(train_data, batch_size=int(bs_fraction*N), shuffle=True, num_workers=num_workers)\n",
    "    testloader = DataLoader(test_data, batch_size=int(bs_fraction*N), shuffle=True, num_workers=num_workers)\n",
    "    \n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "afya0RZFLQJ6"
   },
   "outputs": [],
   "source": [
    "class GBRBM:\n",
    "    \n",
    "    def __init__(self, visible_nodes, h_len, lr_W=0.1, lr_bias=0.001):  \n",
    "        # set lower lr for bias than for the weights\n",
    "        self.N = visible_nodes.shape[0]\n",
    "        v_len = visible_nodes.shape[1]\n",
    "        self.V = visible_nodes.to(device)\n",
    "        self.sigma2 = torch.var(self.V, 0)[0].to(device)  \n",
    "        self.lr_W = lr_W\n",
    "        self.lr_bias = lr_bias\n",
    "        \n",
    "        # Initialisation done based on the methods mentioned in the paper\n",
    "        self.W = torch.empty(v_len, h_len).uniform_(-sqrt(6/(v_len+h_len)), sqrt(6/(v_len+h_len))).to(device)\n",
    "        self.b = torch.mean(visible_nodes, axis=0).view(1,-1).to(device)\n",
    "        self.c = torch.tensor([((torch.norm(self.b + self.W[:, i])**2 - torch.norm(self.b)**2)/(2*self.sigma2) +  log(0.01)).item() for i in range(h_len)]).view(1,-1).to(device)\n",
    "\n",
    "    def get_h(self, v):\n",
    "        \n",
    "        a = torch.mm((v/self.sigma2).view(1,-1), self.W) + self.c\n",
    "        f = torch.nn.Sigmoid()\n",
    "        p_h_v = f(a)\n",
    "        return p_h_v, torch.bernoulli(p_h_v)\n",
    "    \n",
    "    def get_v(self, h):\n",
    "        a = torch.mm(h.view(1,-1), self.W.T) + self.b # mean of normal dist\n",
    "        if (torch.isnan(a)).any().item():\n",
    "            pdb.set_trace()\n",
    "        else:\n",
    "            pass\n",
    "        v_h = torch.normal(mean=a, std=torch.sqrt(self.sigma2)).to(device)\n",
    "        return v_h\n",
    "    \n",
    "    def params_update(self, p_h_v0, p_h_vk, v0, vk):\n",
    "        self.W += self.lr_W*(torch.mm((v0/self.sigma2).view(-1,1), p_h_v0) - torch.mm((vk/self.sigma2).view(-1,1), p_h_vk))/self.N\n",
    "        self.b += self.lr_bias*(v0 - vk)/self.N\n",
    "        self.c += self.lr_bias*(p_h_v0 - p_h_vk)/self.N\n",
    "\n",
    "        \n",
    "    def one_epoch(self, k):\n",
    "        for v0 in self.V:\n",
    "            v_t = v0\n",
    "            for t in range(k):  \n",
    "                p_h_vt, h_t = self.get_h(v_t)\n",
    "                if t==0:\n",
    "                    p_h_v0 = p_h_vt                    \n",
    "                v_t1 = self.get_v(h_t)\n",
    "                v_t = v_t1\n",
    "\n",
    "            try:\n",
    "                V_k = torch.cat((V_k, v_t.view(1,-1)), dim=0)\n",
    "                H_k = torch.cat((H_k, h_t.view(1,-1)), dim=0)\n",
    "            except:\n",
    "                V_k = v_t.view(1,-1)\n",
    "                H_k = h_t.view(1,-1)\n",
    "            self.params_update(p_h_v0, p_h_vt, v0, v_t)\n",
    "        return V_k, H_k\n",
    "        \n",
    "    def train(self, k):\n",
    "        ep = 0\n",
    "        error_old = np.inf\n",
    "        max_ep = 100\n",
    "        while True: #ep<=max_ep:\n",
    "            ep += 1\n",
    "            ## Check if error should be SSE?\n",
    "            V_k, H_k = self.one_epoch(k)\n",
    "\n",
    "            error_new = torch.sum((V_k - self.V)**2) \n",
    "            error_new = error_new/V_k.shape[0]\n",
    "            print('Epoch: {0}, Error: {1}, Error diff :{2}'.format(ep, error_new, abs((error_old-error_new)/error_new)))\n",
    "            \n",
    "            if abs(error_new - error_old)/error_new <= 1e-3:\n",
    "                print('Converged!')\n",
    "                break\n",
    "            error_old = error_new\n",
    "\n",
    "        self.V_train = V_k\n",
    "        self.H_train = H_k      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VC96PFW5LQJ9"
   },
   "outputs": [],
   "source": [
    "class BBRBM:\n",
    "    \n",
    "    def __init__(self, visible_nodes, h_len, lr_W=0.01, lr_bias=0.001):\n",
    "        \n",
    "        # set lower lr for bias than for the weights\n",
    "        \n",
    "        self.N = visible_nodes.shape[0]        \n",
    "        v_len = visible_nodes.shape[1]\n",
    "        self.W = torch.randn(v_len, h_len).to(device)\n",
    "        self.b = torch.randn(1, v_len).to(device)\n",
    "        self.c = torch.randn(1, h_len).to(device)\n",
    "        self.V = visible_nodes.to(device)\n",
    "        self.lr_W = lr_W\n",
    "        self.lr_bias = lr_bias        \n",
    "        \n",
    "    def get_h(self, v):\n",
    "        \n",
    "        a = torch.mm(v.view(1,-1), self.W) + self.c\n",
    "        f = torch.nn.Sigmoid()\n",
    "        p_h_v = f(a)\n",
    "        return p_h_v, torch.bernoulli(p_h_v)\n",
    "    \n",
    "    def get_v(self, h):\n",
    "        a = torch.mm(h.view(1,-1), self.W.T) + self.b\n",
    "        f = torch.nn.Sigmoid()\n",
    "        p_v_h = f(a)\n",
    "        return p_v_h, torch.bernoulli(p_v_h)\n",
    "    \n",
    "    def params_update(self, p_h_v0, p_h_vk, v0, vk):\n",
    "        self.W += self.lr_W*(torch.mm(v0.view(-1,1), p_h_v0) - torch.mm(vk.view(-1,1), p_h_vk))/self.N\n",
    "        self.b += self.lr_bias*(v0 - vk)/self.N\n",
    "        self.c += self.lr_bias*(p_h_v0 - p_h_vk)/self.N\n",
    "        \n",
    "    def one_epoch(self, k):\n",
    "\n",
    "        for v0 in self.V:\n",
    "            v_t = v0\n",
    "            for t in range(k):  \n",
    "                p_h_vt, h_t = self.get_h(v_t)\n",
    "                if t==0:\n",
    "                    p_h_v0 = p_h_vt                    \n",
    "                p_v_ht, v_t1 = self.get_v(h_t)\n",
    "                v_t = v_t1\n",
    "\n",
    "            try:\n",
    "                V_k = torch.cat((V_k, v_t.view(1,-1)), dim=0)\n",
    "                H_k = torch.cat((H_k, h_t.view(1,-1)), dim=0)\n",
    "            except:\n",
    "                V_k = v_t.view(1,-1)\n",
    "                H_k = h_t.view(1,-1)\n",
    "\n",
    "            self.params_update(p_h_v0, p_h_vt, v0, v_t)\n",
    "\n",
    "        return V_k, H_k\n",
    "        \n",
    "    def train(self, k):\n",
    "        ep = 0\n",
    "        error_old = np.inf\n",
    "\n",
    "        max_ep = 100\n",
    "        while True: #ep <= max_ep:\n",
    "            ep += 1\n",
    "            ## Check if error should be SSE?\n",
    "            V_k, H_k = self.one_epoch(k)\n",
    "            error_new = torch.sum((V_k - self.V)**2) \n",
    "            error_new = error_new/V_k.shape[0]\n",
    "            print('Epoch: {0}, Error: {1}, Error diff :{2}'.format(ep, error_new, abs((error_old-error_new)/error_new)))\n",
    "            \n",
    "            if abs(error_new - error_old)/error_new <= 1e-3:\n",
    "                print('Converged!')               \n",
    "                break\n",
    "            error_old = error_new\n",
    "        self.V_train = V_k\n",
    "        self.H_train = H_k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0gjstgMLQKA"
   },
   "outputs": [],
   "source": [
    "class FinalNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, num_classes):\n",
    "        super(FinalNet, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.out = nn.Linear(hidden_sizes[2], num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_score = self.forward(X)\n",
    "            y_pred = torch.argmax(y_score, axis=1)\n",
    "            \n",
    "        return y_pred   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPghIPVKLQKD"
   },
   "outputs": [],
   "source": [
    "def Gaussian_stacked_RBM(v, n_stacks, h_layers_len, learning_rates, k_list):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ------------\n",
    "    v              - Input to RBM (visible nodes). Must be continuous valued, whitened.\n",
    "    n_stacks       - No. of RMBs to be stacked\n",
    "    h_layers_len   - List of no. of nodes in the hidden layer of each RMB\n",
    "    learning_rates - List of list of learning rates (for Weights, bias) for each RBM\n",
    "    k_list         - List of k values for each RBM\n",
    "     '''\n",
    "    \n",
    "    weights = []\n",
    "    biases = []\n",
    "    \n",
    "    print('------Gaussian Binary RBM------')\n",
    "    gaussain = GBRBM(v_whitened.to(device), h_layers_len[0], learning_rates[0][0], learning_rates[0][1])\n",
    "    gaussain.train(k_list[0])\n",
    "    weights.append(gaussain.W)\n",
    "    biases.append(gaussain.c)\n",
    "    v_new = gaussain.H_train\n",
    "    \n",
    "    for i in range(1, n_stacks):\n",
    "        print('------Binary Binary RBM {0}------'.format(i))\n",
    "        binary = BBRBM(v_new.to(device), h_layers_len[i], learning_rates[i][0], learning_rates[i][1])\n",
    "        binary.train(k_list[i])\n",
    "        weights.append(binary.W)\n",
    "        biases.append(binary.c)\n",
    "        v_new = binary.H_train\n",
    "        \n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QvVXx3E8LQKF"
   },
   "source": [
    "1. Finding $\\sigma^{2}$ for visible nodes\n",
    "2. Whitening of data for GBRMB?\n",
    "3. Choice of initial conditions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "95qP365qLQKG"
   },
   "source": [
    "### Data pre-processing - Whitening the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8ofj9NA6Xz__",
    "outputId": "dc70206f-ce6a-4494-be05-0df8e20aee5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49DYjAOeLQKG"
   },
   "outputs": [],
   "source": [
    "# label_dict = {\n",
    "#     'tallbuilding': 1,\n",
    "#     'mountain': 4,\n",
    "#     'highway': 6,\n",
    "#     'coast': 8,\n",
    "#     'opencountry' : 3    \n",
    "# }\n",
    "\n",
    "\n",
    "label_dict = {\n",
    "    'tallbuilding': 0,\n",
    "    'mountain': 1,\n",
    "    'highway': 2,\n",
    "    'coast': 3, \n",
    "    'opencountry': 4}\n",
    "\n",
    "trainloader, testloader = train_test_loader('/content/drive/My Drive/Data_Set_1(Colored_Images)', label_dict, train_fraction=0.8, num_workers=0, bs_fraction = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4Bh2WlcLQKJ"
   },
   "outputs": [],
   "source": [
    "v = list(trainloader)[0][0]\n",
    "v_centered = v - torch.stack([torch.mean(v, 0)]*v.shape[0], dim=0)\n",
    "cov = torch.mm(v_centered.T, v_centered)/v_centered.shape[0]\n",
    "U, S, V = torch.svd(cov)\n",
    "v_whitened = torch.mm(v_centered, U)/torch.sqrt(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Zk5pvn_KXjAF",
    "outputId": "e962de47-72f7-4f67-b74f-065f288c56dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1408, 828])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bT3cfgcZGt58"
   },
   "source": [
    "PCA:\n",
    "FinalNet(reduced_dimension, [150, 75, 50], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_olJ81QeZGHe"
   },
   "outputs": [],
   "source": [
    "# gaussian = GBRBM(v_whitened.to(device), 150, 0.001, 0.01)\n",
    "# gaussian.train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "Y373tXvfLQKL",
    "outputId": "506ff887-03a3-4cab-9e06-476303537e59",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Gaussian Binary RBM------\n",
      "Epoch: 1, Error: 1402.512451171875, Error diff :inf\n",
      "Epoch: 2, Error: 1401.2623291015625, Error diff :0.0008921399130485952\n",
      "Converged!\n",
      "------Binary Binary RBM 1------\n",
      "Epoch: 1, Error: 80.1803970336914, Error diff :inf\n",
      "Epoch: 2, Error: 79.80184936523438, Error diff :0.004743595141917467\n",
      "Epoch: 3, Error: 79.79403686523438, Error diff :9.79083197307773e-05\n",
      "Converged!\n",
      "------Binary Binary RBM 2------\n",
      "Epoch: 1, Error: 34.9723014831543, Error diff :inf\n",
      "Epoch: 2, Error: 34.89986038208008, Error diff :0.0020756844896823168\n",
      "Epoch: 3, Error: 34.926849365234375, Error diff :0.000772728817537427\n",
      "Converged!\n"
     ]
    }
   ],
   "source": [
    "n_stacks = 3\n",
    "h_layers_len = [150, 75, 50]\n",
    "learning_rates = [[0.001, 0.001], [0.001, 0.001], [0.001, 0.001]]\n",
    "k_list = [1000]*3\n",
    "\n",
    "weights_pre_trained, biases_pre_trained = Gaussian_stacked_RBM(v_whitened, n_stacks, h_layers_len, learning_rates, k_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-PXOPrgLQKO"
   },
   "outputs": [],
   "source": [
    "classifier = FinalNet(v.shape[1], h_layers_len, len(np.unique(np.array(list(trainloader)[0][1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_sjnB7v_LQKR"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    classifier.fc1.weight.data = nn.Parameter(weights_pre_trained[0].t())\n",
    "    classifier.fc1.bias.data = nn.Parameter(biases_pre_trained[0].squeeze(0))\n",
    "    \n",
    "    classifier.fc2.weight = nn.Parameter(weights_pre_trained[1].t())\n",
    "    classifier.fc2.bias = nn.Parameter(biases_pre_trained[1].squeeze(0))\n",
    "    \n",
    "    classifier.fc3.weight = nn.Parameter(weights_pre_trained[2].t())\n",
    "    classifier.fc3.bias = nn.Parameter(biases_pre_trained[2].squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4urK_3bWLQKT"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "classifier = classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yEVCDLfwLQKV"
   },
   "outputs": [],
   "source": [
    "trainloader, testloader = train_test_loader('/content/drive/My Drive/Data_Set_1(Colored_Images)', label_dict, train_fraction=0.8, num_workers=0, bs_fraction = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "4MdBkNmCLQKX",
    "outputId": "bd376e6d-dc21-43a2-9a2d-b06e1169ae46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Loss = 3.5513205528259277\n",
      "Epoch 2 : Loss = 3.462965965270996\n",
      "Epoch 3 : Loss = 3.4384297728538513\n",
      "Epoch 4 : Loss = 3.4453404545783997\n",
      "Epoch 5 : Loss = 3.4550176858901978\n",
      "Epoch 6 : Loss = 3.4283592104911804\n",
      "Epoch 7 : Loss = 3.39444237947464\n",
      "Epoch 8 : Loss = 3.325530230998993\n",
      "Epoch 9 : Loss = 3.325425922870636\n",
      "Converged\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "old_loss = np.inf\n",
    "\n",
    "max_epoch = 500\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for data in trainloader:\n",
    "\n",
    "        X, y = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        y_hat = classifier(X)\n",
    "\n",
    "        # Calculate Loss (Cross Entropy)\n",
    "        loss = criterion(y_hat, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print('Epoch', epoch+1, ': Loss =', running_loss)\n",
    "    \n",
    "    if abs(running_loss-old_loss)/running_loss < 1e-3:\n",
    "        print('Converged')\n",
    "        break\n",
    "    \n",
    "    old_loss = running_loss\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "NcTlhXV9QUtq",
    "outputId": "bc873fd8-1751-40d6-ad8f-d939fe822897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 3.278090000152588\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>196</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>153</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>220</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4\n",
       "0  230   30   16    4    7\n",
       "1   49  196    9    8   34\n",
       "2   20    7  153   20    2\n",
       "3    6   20   17  220   30\n",
       "4    7   30    1   16  276"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    y_train = []\n",
    "    y_train_pred = []\n",
    "\n",
    "    for data in trainloader:\n",
    "\n",
    "        X, y = data[0].to(device), data[1].to(device)\n",
    "        y_hat = classifier(X)      \n",
    "        train_loss += criterion(y_hat, y)\n",
    "        \n",
    "        y_train.extend(list(y.cpu().detach().numpy()))\n",
    "        y_train_pred.extend(list(torch.argmax(y_hat, axis=1).cpu().detach().numpy()))\n",
    "\n",
    "print('Train Loss =', train_loss.item())\n",
    "pd.DataFrame(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bXJSHlD2pgbl",
    "outputId": "b6af76e6-2aa7-4e0e-dd04-337800698e52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy = 0.7634943181818182 Train Precision = 0.7644195410649198 Train F1 = 0.7622188241665878\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_train, y_train_pred)\n",
    "prec = precision_score(y_train, y_train_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "\n",
    "print('Train Accuracy =', acc, 'Train Precision =', prec, 'Train F1 =', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "0C_sLteiQQIC",
    "outputId": "cae3d158-bdae-45e6-a928-e5f70fac10a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 1.1823941469192505\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4\n",
       "0  40  14   5   2   8\n",
       "1  22  27   8   5  16\n",
       "2  11   4  32   8   3\n",
       "3   2  11  12  32  10\n",
       "4   2  11   2  10  55"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    y_test = []\n",
    "    y_test_pred = []\n",
    "\n",
    "    for data in testloader:\n",
    "\n",
    "        X, y = data[0].to(device), data[1].to(device)\n",
    "        y_hat = classifier(X)      \n",
    "        test_loss += criterion(y_hat, y)\n",
    "        \n",
    "        y_test.extend(list(y.cpu().detach().numpy()))\n",
    "        y_test_pred.extend(list(torch.argmax(y_hat, axis=1).cpu().detach().numpy()))\n",
    "\n",
    "print('Test Loss =', test_loss.item())\n",
    "pd.DataFrame(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WqN0D-Mipi_K",
    "outputId": "3e86a8b6-a1d4-496c-db6f-a248f879400e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.5284090909090909 Test Precision = 0.5248136142383538 Test F1 = 0.5246062923140883\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "prec = precision_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "print('Test Accuracy =', acc, 'Test Precision =', prec, 'Test F1 =', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dl99XPXGpjik"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "\n",
    "model_state = {'state_dict': classifier.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "model_path = '/content/drive/My Drive/Q5model.pt'\n",
    "torch.save(model_state, model_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Q5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
