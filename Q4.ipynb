{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetClass(Dataset):\n",
    "    \n",
    "    def __init__(self, folder, filename, k, label_dict):\n",
    "        \n",
    "        self.filename = filename\n",
    "        self.data = pd.read_csv(folder + '\\\\' + filename, header=None)\n",
    "        self.y = torch.tensor(label_dict[self.filename.rstrip('.csv')], dtype=torch.long)\n",
    "    \n",
    "    def __getitem__(self, idx):     \n",
    "        \n",
    "        return torch.tensor(self.data.iloc[idx], dtype=torch.float), self.y\n",
    "      \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_loader(directory, train_fraction=0.8, num_workers=2, batch_size=32):\n",
    "\n",
    "    files = list(filter(lambda x: x.endswith('.csv') and x[0].isupper(), os.listdir(directory)))\n",
    "    label_dict = {}\n",
    "\n",
    "    i = 0\n",
    "    for file in files:\n",
    "        label_dict[file.rstrip('.csv')] = i\n",
    "        i += 1\n",
    "\n",
    "    datasets = list(map(lambda x : DatasetClass(directory, x, len(files), label_dict), files))\n",
    "    dataset = ConcatDataset(datasets)\n",
    "    N = dataset.cumulative_sizes[-1]\n",
    "    \n",
    "    train_size = int(N*train_fraction)\n",
    "    test_size = N - train_size\n",
    "\n",
    "    train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    \n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader = train_test_loader('Data_Set_2(Black_and_white_images)', train_fraction=0.8, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RBM(nn.Module):\n",
    "#     def __init__(self, num_v, num_h, k, device, lr_w=0.01, lr_bias=0.001):\n",
    "        \n",
    "#         super(RBM, self).__init__()\n",
    "#         self.W = torch.randn(num_h,num_v).to(device)\n",
    "#         self.b = torch.zeros(num_v).to(device)  # biases of visible nodes\n",
    "#         self.c = torch.zeros(num_h).to(device)  # biases of hidden nodes\n",
    "#         self.k = k                                 # k-step divergence\n",
    "#         self.device = device\n",
    "#         self.lr_w = lr_w\n",
    "#         self.lr_bias = lr_bias\n",
    "    \n",
    "#     def get_h(self, v):\n",
    "#         # activation of the i'th hidden node\n",
    "#         a_i = F.linear(v, self.W, self.c).to(self.device) \n",
    "#         P_h_given_v = torch.sigmoid(a_i)\n",
    "#         return P_h_given_v, torch.bernoulli(P_h_given_v)\n",
    "    \n",
    "#     def get_v(self, h):\n",
    "#         # activation of the j'th visible node\n",
    "#         a_j = F.linear(h, self.W.t(), self.b).to(self.device)\n",
    "#         P_v_given_h = torch.sigmoid(a_j)\n",
    "#         return P_v_given_h, torch.bernoulli(P_v_given_h)\n",
    "    \n",
    "#     def update_step(self, x):\n",
    "        \n",
    "#         v0 = x\n",
    "#         _, h = self.get_h(v0)\n",
    "        \n",
    "#         for i in range(self.k):\n",
    "#             _, v = self.get_v(h)\n",
    "#             _, h = self.get_h(v)\n",
    "            \n",
    "#         p_h_given_v0, _ = self.get_h(v0)\n",
    "#         p_h_given_vk, _ = self.get_h(v)\n",
    "        \n",
    "#         self.W = self.W + self.lr*(torch.matmul(p_h_given_v0.t(), v0) + torch.matmul(p_h_given_vk.t(), v))\n",
    "#         self.b = self.b + self.lr*(v0 - v) \n",
    "#         self.c = self.c + self.lr*(p_h_given_v0 - p_h_given_vk)\n",
    "        \n",
    "#         return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBRBM:\n",
    "    \n",
    "    def __init__(self, visible_nodes, h_len, lr_W=0.01, lr_bias=0.001):\n",
    "        \n",
    "        # set lower lr for bias than for the weights\n",
    "        \n",
    "        self.N = visible_nodes.shape[0]        \n",
    "        v_len = visible_nodes.shape[1]\n",
    "        self.W = torch.randn(v_len, h_len).to(device)\n",
    "        self.b = torch.randn(1, v_len).to(device)\n",
    "        self.c = torch.randn(1, h_len).to(device)\n",
    "        self.V = visible_nodes.to(device)\n",
    "        self.lr_W = lr_W\n",
    "        self.lr_bias = lr_bias        \n",
    "        \n",
    "    def get_h(self, v):\n",
    "        \n",
    "        a = torch.mm(v.view(1,-1), self.W) + self.c\n",
    "        f = torch.nn.Sigmoid()\n",
    "        p_h_v = f(a)\n",
    "        return p_h_v, torch.bernoulli(p_h_v)\n",
    "    \n",
    "    def get_v(self, h):\n",
    "        a = torch.mm(h.view(1,-1), self.W.T) + self.b\n",
    "        f = torch.nn.Sigmoid()\n",
    "        p_v_h = f(a)\n",
    "        return p_v_h, torch.bernoulli(p_v_h)\n",
    "    \n",
    "    def params_update(self, p_h_v0, p_h_vk, v0, vk):\n",
    "        self.W += self.lr_W*(torch.mm(v0.view(-1,1), p_h_v0) - torch.mm(vk.view(-1,1), p_h_vk))/self.N\n",
    "        self.b += self.lr_bias*(v0 - vk)/self.N\n",
    "        self.c += self.lr_bias*(p_h_v0 - p_h_vk)/self.N\n",
    "        \n",
    "    def one_epoch(self, k):\n",
    "\n",
    "        for v0 in self.V:\n",
    "            v_t = v0\n",
    "            for t in range(k):  \n",
    "                p_h_vt, h_t = self.get_h(v_t)\n",
    "                if t==0:\n",
    "                    p_h_v0 = p_h_vt                    \n",
    "                p_v_ht, v_t1 = self.get_v(h_t)\n",
    "                v_t = v_t1\n",
    "\n",
    "            try:\n",
    "                V_k = torch.cat((V_k, v_t.view(1,-1)), dim=0)\n",
    "                H_k = torch.cat((H_k, h_t.view(1,-1)), dim=0)\n",
    "            except:\n",
    "                V_k = v_t.view(1,-1)\n",
    "                H_k = h_t.view(1,-1)\n",
    "\n",
    "            self.params_update(p_h_v0, p_h_vt, v0, v_t)\n",
    "\n",
    "        return V_k, H_k\n",
    "        \n",
    "    def train(self, k, eps=1e-3):\n",
    "        ep = 0\n",
    "        error_old = np.inf\n",
    "        while True:\n",
    "            ep += 1\n",
    "            ## Check if error should be SSE?\n",
    "            V_k, H_k = self.one_epoch(k)\n",
    "            error_new = torch.sum((V_k - self.V)**2) \n",
    "            print('Epoch: {0}, Error: {1}'.format(ep, error_new))\n",
    "            \n",
    "            if abs(error_new - error_old)/error_old <= eps:\n",
    "                print('Converged!')\n",
    "                self.V_train = V_k\n",
    "                self.H_train = H_k                \n",
    "                break\n",
    "            error_old = error_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = list(trainloader)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Error: 292489280.0\n",
      "Epoch: 2, Error: 292347232.0\n",
      "Epoch: 3, Error: 292344960.0\n",
      "Converged!\n"
     ]
    }
   ],
   "source": [
    "rbm = BBRBM(v, h_len=500)\n",
    "rbm.train(k=50, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_new = rbm.H_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Error: 5862.0\n",
      "Epoch: 2, Error: 5462.0\n",
      "Epoch: 3, Error: 4926.0\n",
      "Epoch: 4, Error: 4250.0\n",
      "Epoch: 5, Error: 3591.0\n",
      "Epoch: 6, Error: 2831.0\n",
      "Epoch: 7, Error: 2344.0\n",
      "Epoch: 8, Error: 1721.0\n",
      "Epoch: 9, Error: 1351.0\n",
      "Epoch: 10, Error: 1000.0\n",
      "Epoch: 11, Error: 756.0\n",
      "Epoch: 12, Error: 684.0\n",
      "Epoch: 13, Error: 554.0\n",
      "Epoch: 14, Error: 415.0\n",
      "Epoch: 15, Error: 371.0\n",
      "Epoch: 16, Error: 357.0\n",
      "Epoch: 17, Error: 351.0\n",
      "Epoch: 18, Error: 288.0\n",
      "Epoch: 19, Error: 265.0\n",
      "Epoch: 20, Error: 230.0\n",
      "Epoch: 21, Error: 197.0\n",
      "Epoch: 22, Error: 200.0\n",
      "Epoch: 23, Error: 189.0\n",
      "Epoch: 24, Error: 197.0\n",
      "Epoch: 25, Error: 184.0\n",
      "Epoch: 26, Error: 171.0\n",
      "Epoch: 27, Error: 151.0\n",
      "Epoch: 28, Error: 149.0\n",
      "Epoch: 29, Error: 128.0\n",
      "Epoch: 30, Error: 143.0\n",
      "Epoch: 31, Error: 152.0\n",
      "Epoch: 32, Error: 131.0\n",
      "Epoch: 33, Error: 131.0\n",
      "Converged!\n"
     ]
    }
   ],
   "source": [
    "rbm2 = BBRBM(v_new, h_len=350)\n",
    "rbm2.train(k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Error: 4762.0\n",
      "Epoch: 2, Error: 4473.0\n",
      "Epoch: 3, Error: 4066.0\n",
      "Epoch: 4, Error: 3749.0\n",
      "Epoch: 5, Error: 3436.0\n",
      "Epoch: 6, Error: 3034.0\n",
      "Epoch: 7, Error: 2705.0\n",
      "Epoch: 8, Error: 2472.0\n",
      "Epoch: 9, Error: 2058.0\n",
      "Epoch: 10, Error: 1892.0\n",
      "Epoch: 11, Error: 1676.0\n",
      "Epoch: 12, Error: 1451.0\n",
      "Epoch: 13, Error: 1285.0\n",
      "Epoch: 14, Error: 1015.0\n",
      "Epoch: 15, Error: 876.0\n",
      "Epoch: 16, Error: 808.0\n",
      "Epoch: 17, Error: 591.0\n",
      "Epoch: 18, Error: 518.0\n",
      "Epoch: 19, Error: 444.0\n",
      "Epoch: 20, Error: 439.0\n",
      "Epoch: 21, Error: 371.0\n",
      "Epoch: 22, Error: 345.0\n",
      "Epoch: 23, Error: 338.0\n",
      "Epoch: 24, Error: 280.0\n",
      "Epoch: 25, Error: 255.0\n",
      "Epoch: 26, Error: 251.0\n",
      "Epoch: 27, Error: 202.0\n",
      "Epoch: 28, Error: 201.0\n",
      "Epoch: 29, Error: 176.0\n",
      "Epoch: 30, Error: 176.0\n",
      "Converged!\n"
     ]
    }
   ],
   "source": [
    "v_new2 = rbm2.H_train\n",
    "rbm3 = BBRBM(v_new2, h_len=200)\n",
    "rbm3.train(k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, num_classes):\n",
    "        super(FinalNet, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.out = nn.Linear(hidden_sizes[2], num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_score = self.forward(X)\n",
    "            y_pred = torch.argmax(y_score, axis=1)\n",
    "            \n",
    "        return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = FinalNet(v.shape[1], [500,350,200], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    classifier.fc1.weight.data = nn.Parameter(rbm.W)\n",
    "    classifier.fc1.bias.data = nn.Parameter(rbm.b)\n",
    "    \n",
    "    classifier.fc2.weight = nn.Parameter(rbm2.W)\n",
    "    classifier.fc2.bias = nn.Parameter(rbm2.b)\n",
    "    \n",
    "    classifier.fc3.weight = nn.Parameter(rbm3.W)\n",
    "    classifier.fc3.bias = nn.Parameter(rbm3.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "classifier = classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader = train_test_loader('Data_Set_2(Black_and_white_images)', train_fraction=0.8, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [32 x 784], m2: [500 x 784] at C:/w/b/windows/pytorch/aten/src\\THC/generic/THCTensorMathBlas.cu:283",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-05d372f17449>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Calculate Loss (Cross Entropy)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasistha singhal\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-1f451499c99e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasistha singhal\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasistha singhal\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vasistha singhal\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1608\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1609\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1610\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1611\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [32 x 784], m2: [500 x 784] at C:/w/b/windows/pytorch/aten/src\\THC/generic/THCTensorMathBlas.cu:283"
     ]
    }
   ],
   "source": [
    "old_loss = np.inf\n",
    "\n",
    "max_epoch = 500\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for data in trainloader:\n",
    "        \n",
    "        X, y = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        y_hat = classifier(X)\n",
    "        \n",
    "        # Calculate Loss (Cross Entropy)\n",
    "        loss = criterion(y_hat, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print('Epoch', epoch+1, ': Loss =', running_loss)\n",
    "    \n",
    "    if abs(running_loss-old_loss)/running_loss < 1e-3:\n",
    "        print('Converged')\n",
    "        break\n",
    "    \n",
    "    old_loss = running_loss\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 500])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 350])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm2.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([350, 200])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm3.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
